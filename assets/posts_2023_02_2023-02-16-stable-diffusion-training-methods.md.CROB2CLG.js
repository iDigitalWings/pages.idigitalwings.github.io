import{_ as i,a as r,af as t,o}from"./chunks/framework.C87LdZyP.js";const a="/assets/training-methods.Bej_uKmj.png",p=JSON.parse('{"title":"Stable Diffusion 训练方法","description":"","frontmatter":{"title":"Stable Diffusion 训练方法","date":"2023-02-16T00:00:00.000Z","tags":["ai","stable-diffusion"],"category":["AI"]},"headers":[],"relativePath":"posts/2023/02/2023-02-16-stable-diffusion-training-methods.md","filePath":"posts/2023/02/2023-02-16-stable-diffusion-training-methods.md","lastUpdated":1718173059000}'),l={name:"posts/2023/02/2023-02-16-stable-diffusion-training-methods.md"};function n(s,e,d,h,m,u){return o(),r("div",null,e[0]||(e[0]=[t('<p>Stable Diffusion 多种模型训练方法。 它们都可以用来训练 Stable Diffusion 模型，但它们之间存在一些差异。</p><p>常见有如下四种：</p><ul><li>Textual Inversion、</li><li>Hypernetwork、</li><li>Dreambooth</li><li>和 LoRA。</li></ul><p><img src="'+a+'" alt="training-methods.png"></p><h2 id="textual-inversion" tabindex="-1">Textual Inversion <a class="header-anchor" href="#textual-inversion" aria-label="Permalink to &quot;Textual Inversion&quot;">​</a></h2><p>Textual Inversion（也称为 Embedding）是一种使用文本提示来训练模型的方法。 它根据模型引用给定的图像并选择最匹配的图像。你做的迭代越多越好， 能够在保持图像质量的同时，快速生成大量图像。这种方法对计算资源要求较低， 适用于需要快速生成大量高质量图像的场景。</p><ul><li>生成的模型文件小，大约几十KB</li><li>通常适用于转换图像风格</li><li>使用时不需要加载模型，只需要在提词中embeddings中的关键tag</li><li>本地训练时对计算资源要求不高</li><li>可以通过生成的PT文件覆盖在原有基础上继续训练</li><li>模型关键字尽量是不常见的词语</li><li>推荐训练人物</li></ul><p>训练时关键参数设定：</p><ul><li><code>learning_rate</code>： 0.05:10, 0.02:20, 0.01:60, 0.005:200, 0.002:500, 0.001:3000, 0.0005</li><li><code>number of vectors per token</code>：按图片数量设置（图片数量小于10设置为2，10-30张设置范围2~3,40-60张设置范围5~6,60-100张设置范围8-12,大于100张设置范围12~16）</li><li><code>max_train_steps</code>： 3000(起步3000步)</li></ul><h2 id="hypernetwork" tabindex="-1">Hypernetwork <a class="header-anchor" href="#hypernetwork" aria-label="Permalink to &quot;Hypernetwork&quot;">​</a></h2><p>Hypernetwork 是一种使用神经网络来生成模型参数的方法。 它可以用来从模型内部找到更多相似的东西，使得生成为近似内容图像， 如果你想训练人脸或特定的风格，并且如果你用 Hypernetwork 生成的一切看起来都像你的训练数据， 那么Hypernetwork是一个不错的选择。你不能生成混合训练的图像，比如一组非常不同风格各异的猫。 不过，你可以使用 Hypernetwork 进行绘画，将不同的训练数据纳入一个图像，改变图像的整个输出。</p><p>特点：</p><ul><li>生成的模型文件比Embedding大，大约几十MB</li><li>通常训练艺术风格</li><li>推荐训练画风</li></ul><p>训练时关键参数设定：</p><ul><li><code>learning_rate</code>： 0.000005:1000,0.0000025:10000,0.00000075:20000,0.0000005:30000,0.00000025:-1</li><li><code>prompt template file</code>: 对应风格类型文件可以编辑只留下一个 [fileword]，[name] 在那里，删除多余的描述</li></ul><h2 id="dreambooth" tabindex="-1">Dreambooth <a class="header-anchor" href="#dreambooth" aria-label="Permalink to &quot;Dreambooth&quot;">​</a></h2><p>Dreambooth 是一种使用少量图像来训练模型的方法， 是一种基于深度学习的图像风格转换技术。 它可以将一张图片的风格应用到另一张图片上，以生成新的图像。 Dreambooth 的一个优点是它可以生成高质量的艺术作品，而无需用户具备专业艺术技能。</p><p>特点：</p><ul><li>模型文件很大，2-4GB</li><li>适于训练人脸，宠物和物件</li><li>使用时需要 加载模型</li><li>可以进行模型融合，跟其他模型文件融合成新的模型</li><li>本地训练时需要高显存，&gt;=12GB</li><li>推荐训练人物*画风</li></ul><p>训练时关键参数：</p><p>高学习率和过多的训练步骤将导致过度拟合（换句话说，无论提示如何，模型只能从训练数据生成图像）。 低学习率和过少的步骤会导致学习不足，这是因为模型无法生成训练过的概念。</p><ul><li>物件：400步，2e-6</li><li>人脸：1500步，1e-6或2e-6</li><li><code>Training Steps Per Image (Epochs)</code>：（根据你图片的数量设定，大概值为你想训练的总步数/图片数量）</li><li><code>Sanity Sample Prompt</code>: 是否过度训练参数设定，我们可以加上一些特征从而去判断训练过程中是否出现过度拟合如填入 person of XX red hair （说明：XX替换为你的关键字，我们在这里加入了红头发的特征，如果出训练输出图像出现了非红头发此时我们就知道过度拟合了，训练过度了）</li></ul><h2 id="lora" tabindex="-1">Lora <a class="header-anchor" href="#lora" aria-label="Permalink to &quot;Lora&quot;">​</a></h2><p>Lora是一种使用少量图像来训练模型的方法。 与 Dreambooth 不同，LoRA 训练速度更快： 当 Dreambooth 需要大约二十分钟才能运行并产生几个 GB 的模型时， LoRA 只需八分钟就能完成训练，并产生约 5MB 的模型，推荐使用 <code>kohya_ss GUI</code> 进行 LoRA 训练。</p><p>特点：</p><ul><li>模型大小适中，8~140MB</li><li>使用时只需要加载对应的lora模型，可以多个不同的（lora模型+权重）叠加使用</li><li>可以进行lora模型其他模型的融合</li><li>本地训练时需要显存适中，&gt;=7GB</li><li>推荐训练人物</li></ul><hr><ul><li><a href="https://www.reddit.com/r/StableDiffusion/comments/10cgxrx/wellresearched_comparison_of_training_techniques/" target="_blank" rel="noreferrer">Well-Researched Comparison of Training Techniques</a></li><li><a href="https://www.reddit.com/r/StableDiffusion/comments/xqi1t4/textual_inversion_versus_dreambooth/" target="_blank" rel="noreferrer">reddit: Textual Inversion versus Dreambooth</a></li><li><a href="https://www.reddit.com/r/StableDiffusion/comments/z8w5z2/the_difference_between_dreambooth_models_and/" target="_blank" rel="noreferrer">reddit: The difference between DreamBooth models, and Textual inversion embeddings</a></li><li><a href="https://www.reddit.com/r/StableDiffusion/comments/xjlv19/comparison_of_dreambooth_and_textual_inversion/" target="_blank" rel="noreferrer">reddit: Comparison of DreamBooth and Textual Inversion</a></li><li><a href="https://wandb.ai/psuraj/dreambooth/reports/Dreambooth-training-analysis--VmlldzoyNzk0NDc3#textual-inversion-and-dreambooth" target="_blank" rel="noreferrer">Training Stable Diffusion with Dreambooth</a></li><li><a href="https://ericri.medium.com/ai-art-of-me-textual-inversion-vs-dreambooth-in-stable-diffusion-5e54bb2b881" target="_blank" rel="noreferrer">AI Art of Me — Textual Inversion vs. Dreambooth in Stable Diffusion</a></li><li><a href="https://www.youtube.com/watch?v=dVjMiJsuR5o" target="_blank" rel="noreferrer">YouTube: LoRA vs Dreambooth vs Textual Inversion vs Hypernetworks</a></li><li><a href="https://github.com/civitai/civitai/wiki/How-to-use-models" target="_blank" rel="noreferrer">How-to-use-models</a></li><li><a href="https://stable-diffusion-ui.github.io/" target="_blank" rel="noreferrer">Cmdr2&#39;s Stable Diffusion UI v2</a></li></ul>',28)]))}const b=i(l,[["render",n]]);export{p as __pageData,b as default};
