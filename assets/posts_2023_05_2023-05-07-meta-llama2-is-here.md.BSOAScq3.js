import{_ as e,a as t,af as l,o as r}from"./chunks/framework.C87LdZyP.js";const o="/assets/818883556662083.CUtz0Dqr.png",s="/assets/816829245109666.dKM15-FB.png",i="/assets/817695458803958.O52Q2qtp.png",n="/assets/817497842102833.CmK1D3kS.png",p="/assets/817558243759875.Djm40oDk.png",m="/assets/818213560408500.CMFv-EKH.png",c="/assets/818369273033833.BaT--J9F.png",h="/assets/818922286372291.DN8z8sRY.png",g="/assets/818446214497250.Dtrlyr_1.png",d="/assets/817648579789250.BXXqC-cq.png",u="/assets/819107457852333.BBJ9GGts.png",f="/assets/819326645449833.ROW3IQzQ.png",b="/assets/819743950629458.CrFrFQcE.png",_="/assets/819826040106416.DL03iRvX.png",L="/assets/819002752984833.D5_qiNiO.png",D=JSON.parse('{"title":"Meta 发布 Llama 2 支持商用，引发 Llama2 热潮，或讲改变大语言模型格局","description":"","frontmatter":{"title":"Meta 发布 Llama 2 支持商用，引发 Llama2 热潮，或讲改变大语言模型格局","date":"2023-05-07T00:00:00.000Z","tags":["ai","ml","midjourney-style"],"category":["AI"]},"headers":[],"relativePath":"posts/2023/05/2023-05-07-meta-llama2-is-here.md","filePath":"posts/2023/05/2023-05-07-meta-llama2-is-here.md","lastUpdated":1718173059000}'),k={name:"posts/2023/05/2023-05-07-meta-llama2-is-here.md"};function q(M,a,x,P,C,F){return r(),t("div",null,a[0]||(a[0]=[l('<blockquote><p>MetaAI 刚刚开源了 Llama2 模型，不仅开源了预训练模型，而且还开源了利用对话数据微调后的 Llama2-Chat 模型。 随着 Llama2 系列模型的发布，Meta 也在开源世界越走越远。</p></blockquote><h2 id="llama2-简介" tabindex="-1">Llama2 简介 <a class="header-anchor" href="#llama2-简介" aria-label="Permalink to &quot;Llama2 简介&quot;">​</a></h2><p><code>Llama 2</code> 是预训练和微调的生成文本模型的集合， 其规模从 7 亿到 70 亿个参数不等。</p><p><img src="'+o+'" alt=""></p><p>Meta 还发布了微调的LLM， 称为 <code>Llama-2-Chat</code>，针对对话用例进行了优化。在我们测试的大多数基准测试中， <code>Llama-2-Chat</code> 模型的性能优于开源聊天模型，并且在我们对有用性和安全性的人工评估中， 与一些流行的闭源模型（如 ChatGPT 和 PaLM）相当。</p><p><img src="'+s+'" alt="HuggingFace Llama 2"></p><p>开源模型目前有7B、13B、70B三种尺寸， 预训练阶段使用了2万亿Token， SFT阶段使用了超过10w数据， 人类偏好数据超过100w。</p><p><img src="'+i+'" alt="Family of Llama Models"></p><ul><li><a href="https://huggingface.co/meta-llama" target="_blank" rel="noreferrer">https://huggingface.co/meta-llama</a></li></ul><h2 id="llama2-性能" tabindex="-1">Llama2 性能 <a class="header-anchor" href="#llama2-性能" aria-label="Permalink to &quot;Llama2 性能&quot;">​</a></h2><p>在 Meta 的论文中，首先就放了和包括 OpenAI 的 ChatGPT 3，Google PaLM 的 PK 图， 可谓是火药味十足。</p><p><img src="'+n+'" alt="Llama Wine Rate"></p><p><img src="'+p+'" alt="Hopefulness Wine Rate"></p><h3 id="上下文" tabindex="-1">上下文 <a class="header-anchor" href="#上下文" aria-label="Permalink to &quot;上下文&quot;">​</a></h3><p>上下文长度：Llama 2 的上下文窗口从 2048 个标记扩展到 4096 个字符。越长上下文窗口使模型能够处理更多信息， 这对于支持聊天应用程序中较长的历史记录、 各种摘要任务以及理解较长的文档。 多个评测结果表示较长的上下文模型在各种通用任务上保持了强大的性能。</p><p><img src="'+m+'" alt="Context length ablation on general tasks."></p><h3 id="grouped-query-attention-分组查询注意力" tabindex="-1">Grouped-Query Attention 分组查询注意力 <a class="header-anchor" href="#grouped-query-attention-分组查询注意力" aria-label="Permalink to &quot;Grouped-Query Attention 分组查询注意力&quot;">​</a></h3><p>关于 Llama 2 中的<code>分组查询注意力</code>，大家感兴趣直接去看 Meta 的论文即可，我就不瞎解释了。</p><p>给大家看下在新架构下的性能。</p><p><img src="'+c+'" alt="Attention architecture ablations"></p><h3 id="llama-2-的评估结果" tabindex="-1">Llama 2 的评估结果 <a class="header-anchor" href="#llama-2-的评估结果" aria-label="Permalink to &quot;Llama 2 的评估结果&quot;">​</a></h3><p>Llama 2 在许多外部基准测试中都优于其他开源语言模型。</p><p>这是官网的评估结果：</p><p><img src="'+h+'" alt=""></p><p>下面是论文中的：</p><p><img src="'+g+'" alt="Five-shot performance"></p><h2 id="llama-2-chat" tabindex="-1">Llama 2-Chat <a class="header-anchor" href="#llama-2-chat" aria-label="Permalink to &quot;Llama 2-Chat&quot;">​</a></h2><p>Meta 还专门微调了一个对话模型。</p><p><img src="'+d+'" alt="Training of Llama 2 Chat"></p><h2 id="商用" tabindex="-1">商用 <a class="header-anchor" href="#商用" aria-label="Permalink to &quot;商用&quot;">​</a></h2><p>Llama 2 有友好的商业许可证，也就是你小打小闹都可以免费商用。</p><h2 id="中文支持" tabindex="-1">中文支持 <a class="header-anchor" href="#中文支持" aria-label="Permalink to &quot;中文支持&quot;">​</a></h2><p>虽然 Llama 2 的训练数据只有不足 1% 的中文数据，但是可以肯定的是中文世界的 Llama 2 马上就会跟上。</p><p>不是经常有人开玩笑说，Llama 2 一开源，国内立马就会有无数企业自主研发并且赶超 ChatGPT。</p><h2 id="如何使用" tabindex="-1">如何使用 <a class="header-anchor" href="#如何使用" aria-label="Permalink to &quot;如何使用&quot;">​</a></h2><h3 id="huggingface" tabindex="-1">HuggingFace <a class="header-anchor" href="#huggingface" aria-label="Permalink to &quot;HuggingFace&quot;">​</a></h3><p>在 HuggingFace 上申请：</p><p><a href="https://huggingface.co/meta-llama/Llama-2-70b-chat-hf" target="_blank" rel="noreferrer">https://huggingface.co/meta-llama/Llama-2-70b-chat-hf</a></p><p><img src="'+u+'" alt=""></p><p>可以先试用一下在线的应用（在模型页可以照到很多）：</p><p>比如：<a href="https://huggingface.co/spaces/ysharma/Explore_llamav2_with_TGI" target="_blank" rel="noreferrer">https://huggingface.co/spaces/ysharma/Explore_llamav2_with_TGI</a></p><p>小测试了一下：</p><p><img src="'+f+'" alt=""></p><h3 id="meta" tabindex="-1">Meta <a class="header-anchor" href="#meta" aria-label="Permalink to &quot;Meta&quot;">​</a></h3><p>当然我们也可以在 Meta 自家网站上下载，当然前提是先申请。</p><p>我也申请了，</p><ul><li><a href="https://ai.meta.com/resources/models-and-libraries/llama-downloads/" target="_blank" rel="noreferrer">https://ai.meta.com/resources/models-and-libraries/llama-downloads/</a></li></ul><p><img src="'+b+'" alt=""></p><p>而且很快就得到回复，明天下载运行看看：</p><p><img src="'+_+'" alt=""></p><h3 id="其他云厂商" tabindex="-1">其他云厂商 <a class="header-anchor" href="#其他云厂商" aria-label="Permalink to &quot;其他云厂商&quot;">​</a></h3><p>当然 Meta 也和 微软、AWS 等厂商密切合作，你也可以在他们的云服务商部署 Llama 2 模型。</p><h2 id="关于-meta-的开源之路" tabindex="-1">关于 Meta 的开源之路 <a class="header-anchor" href="#关于-meta-的开源之路" aria-label="Permalink to &quot;关于 Meta 的开源之路&quot;">​</a></h2><p>最近， Meta 在开源 AI 领域的足迹不断扩大，HuggingFace 上有超过 600 个模型，例如 我们之前介绍过的 <code>MusicGen</code>、<code>Galacica</code>、<code>Wav2Vec</code> 等。</p><p>这点，Meta 倒是比微软、谷歌做的都好，但是同样的 Meta 的底子不厚，开源这条路还真的挺适合他。</p><p><img src="'+L+'" alt="Meta @ HuggingFace"></p><p>参考：</p><ul><li><a href="https://ai.meta.com/llama/" target="_blank" rel="noreferrer">https://ai.meta.com/llama/</a></li><li><a href="https://huggingface.co/meta-llama" target="_blank" rel="noreferrer">https://huggingface.co/meta-llama</a></li><li><a href="https://huggingface.co/blog/llama2" target="_blank" rel="noreferrer">https://huggingface.co/blog/llama2</a></li><li><a href="https://huggingface.co/facebook" target="_blank" rel="noreferrer">https://huggingface.co/facebook</a></li><li><a href="https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/" target="_blank" rel="noreferrer">https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/</a></li><li><a href="https://github.com/huggingface/transformers/" target="_blank" rel="noreferrer">https://github.com/huggingface/transformers/</a></li><li><a href="https://ai.meta.com/resources/models-and-libraries/llama-downloads/" target="_blank" rel="noreferrer">https://ai.meta.com/resources/models-and-libraries/llama-downloads/</a></li><li><a href="https://github.com/facebookresearch/llama/blob/main/README.md" target="_blank" rel="noreferrer">https://github.com/facebookresearch/llama/blob/main/README.md</a></li></ul><hr><div style="text-align:center;color:#00000099;font-size:14px;">END</div>',60)]))}const G=e(k,[["render",q]]);export{D as __pageData,G as default};
