import{_ as t,a as d,o as a,aj as r}from"./chunks/framework.Ba_Ek9Jm.js";const e="/assets/811976000827083.BSFlsakH.png",o="/assets/808443128423958.Dmtwncwj.png",l="/assets/808508857454375.Dg6dXss5.png",P=JSON.parse('{"title":"LMSYS 聊天机器人竞技排行榜 2023-05-10","description":"","frontmatter":{"title":"LMSYS 聊天机器人竞技排行榜 2023-05-10","date":"2023-03-20T00:00:00.000Z","tags":["ai","ml"],"category":["AI"]},"headers":[],"relativePath":"posts/2023/03/2023-03-20-chatbot-leaderboard-20230510.md","filePath":"posts/2023/03/2023-03-20-chatbot-leaderboard-20230510.md","lastUpdated":1718173059000}'),s={name:"posts/2023/03/2023-03-20-chatbot-leaderboard-20230510.md"},n=r('<blockquote><p>为了促进LLM在聊天机器人领域的发展和创新， <strong>LMSYS Org</strong> 创建了一个名为 <strong>Chatbot Arena</strong> 的平台。 它展示了不同的聊天机器人模型在与真实用户对话中的性能和评分。 5月10号的更新中，竞技场中添加了 4 个新的但强大的玩家。</p></blockquote><p>先看下排名图。</p><table tabindex="0"><thead><tr><th>排名</th><th>模型</th><th>ELo 得分</th></tr></thead><tbody><tr><td>1</td><td>🥇 GPT-4</td><td>1274</td></tr><tr><td>2</td><td>🥈 Claude-v1</td><td>1224</td></tr><tr><td>3</td><td>🥉 GPT-3.5-turbo</td><td>1155</td></tr><tr><td>4</td><td>Vicuna-13B</td><td>1083</td></tr><tr><td>5</td><td>Koala-13B</td><td>1022</td></tr><tr><td>6</td><td>RWKV-4-Raven-14B</td><td>989</td></tr><tr><td>7</td><td>Oasst-Pythia-12B</td><td>928</td></tr><tr><td>8</td><td>ChatGLM-6B</td><td>918</td></tr><tr><td>9</td><td>StableLM-Tuned-Alpha-7B</td><td>906</td></tr><tr><td>10</td><td>Alpaca-13B</td><td>904</td></tr><tr><td>11</td><td>FastChat-T5-3B</td><td>902</td></tr><tr><td>12</td><td>Dolly-V2-12B</td><td>863</td></tr><tr><td>13</td><td>LLaMA-13B</td><td>826</td></tr></tbody></table><p>完整的截图如下：</p><p><img src="'+e+'" alt=""></p><p>在5月10号的更新中，我们在竞技场中添加了 4 个新的但强大的玩家，包括三个专有模型和一个开源模型。他们是：</p><ul><li><strong>OpenAI GPT-4</strong></li><li><strong>OpenAI GPT-3.5-turbo</strong></li><li><strong>Anthropic Claude-v1</strong></li><li><strong>RWKV-4-Raven-14B</strong></li></ul><p>下面表格展示了所有 13 个模型的 Elo 评级， 这些评级基于本笔记本共享的 <code>13K</code> 投票数据和计算。</p><table tabindex="0"><thead><tr><th>排名</th><th>模型</th><th>ELo 得分</th><th>描述</th><th>许可证</th></tr></thead><tbody><tr><td>1</td><td>🥇 GPT-4</td><td>1274</td><td>OpenAI 的 ChatGPT-4</td><td>私有</td></tr><tr><td>2</td><td>🥈 Claude-v1</td><td>1224</td><td>Anthropic的克劳德</td><td>私有</td></tr><tr><td>3</td><td>🥉 GPT-3.5-turbo</td><td>1155</td><td>OpenAI 的 ChatGPT-3.5</td><td>私有</td></tr><tr><td>4</td><td>Vicuna-13B</td><td>1083</td><td>LLaMA 对 LMSYS 的用户共享对话进行微调的聊天助手</td><td>权重可用；非商业用途</td></tr><tr><td>5</td><td>Koala-13B</td><td>1022</td><td>BAIR 的学术研究对话模型</td><td>权重可用；非商业用途</td></tr><tr><td>6</td><td>RWKV-4-Raven-14B</td><td>989</td><td>具有变压器级 LLM 性能的 RNN</td><td>Apache 2.0</td></tr><tr><td>7</td><td>Oasst-Pythia-12B</td><td>928</td><td>LAION 人人可用的开放助手</td><td>Apache 2.0</td></tr><tr><td>8</td><td>ChatGLM-6B</td><td>918</td><td>清华大学开放式双语对话语言模型</td><td>权重可用；非商业用途</td></tr><tr><td>9</td><td>StableLM-Tuned-Alpha-7B</td><td>906</td><td>稳定性 AI 语言模型</td><td>CC-BY-NC-SA-4.0</td></tr><tr><td>10</td><td>Alpaca-13B</td><td>904</td><td>LLaMA 在斯坦福的指令遵循演示中微调的模型</td><td>权重可用；非商业用途</td></tr><tr><td>11</td><td>FastChat-T5-3B</td><td>902</td><td>LMSYS 从 FLAN-T5 微调的聊天助手</td><td>Apache 2.0</td></tr><tr><td>12</td><td>Dolly-V2-12B</td><td>863</td><td>Databricks 的指令调优开放大型语言模型</td><td>MIT</td></tr><tr><td>13</td><td>LLaMA-13B</td><td>826</td><td>Meta 开放高效的基础语言模型</td><td>权重可用；非商业用途</td></tr></tbody></table><p><img src="'+o+'" alt="每个模型的战斗计数"></p><h2 id="结果分析" tabindex="-1">结果分析 <a class="header-anchor" href="#结果分析" aria-label="Permalink to &quot;结果分析&quot;">​</a></h2><h3 id="专有模型与开源模型之间的差距" tabindex="-1">专有模型与开源模型之间的差距 <a class="header-anchor" href="#专有模型与开源模型之间的差距" aria-label="Permalink to &quot;专有模型与开源模型之间的差距&quot;">​</a></h3><p>结果可以观察到三种专有模型与所有其他开源模型之间存在巨大差距。 特别是，GPT-4 在董事会中处于领先地位，获得了 1274 的 Elo 分数。 它比该董事会上最好的开源替代品——我们的 Vicuna-13B 高出近 200 分。 在打平后，GPT-4 在对抗 Vicuna-13B 时赢得了 82% 的比赛， 在对抗上一代 GPT-3.5-turbo 时甚至赢得了 79% 的比赛。</p><p>然而，值得注意的是，排行榜上的这些开源模型通常比专有模型具有更少的参数，在 3B - 14B 范围内。事实上，最近在 LLM 和数据管理方面的进步已经允许使用更小的模型显着提高性能。 <a href="https://ai.google/discover/palm2" target="_blank" rel="noreferrer">谷歌最新的 PaLM 2</a>就是一个很好的例子：我们知道 PaLM 2 使用更小的模型尺寸实现了比上一代更好的性能，我们对开源语言模型赶超的潜力仍然非常乐观。通过我们<a href="https://github.com/lm-sys/FastChat" target="_blank" rel="noreferrer">基于 FastChat 的 Chatbot Arena</a>和这个排行榜的努力，我们希望为评估 LLM 贡献一个值得信赖的评估平台，并帮助推进这一领域并为每个人创建更好的语言模型。</p><h3 id="比较专有模型" tabindex="-1">比较专有模型 <a class="header-anchor" href="#比较专有模型" aria-label="Permalink to &quot;比较专有模型&quot;">​</a></h3><p>然而，在三个专有模型中，根据我们收集的投票结果，我们确实观察到 Anthropic 的 Claude 模型比 GPT-3.5-turbo 更受我们用户的青睐，GPT-3.5-turbo 经常被讨论为它的对手。事实上，即使在与最强大的模型——OpenAI 的 GPT-4 竞争时，克劳德也具有很强的竞争力。查看胜率图（下图 3），在 GPT-4 和克劳德之间的 66 场非平局比赛中，克劳德确实在 32 场（48%）比赛中战胜了 GPT-4。人类团队干得好！</p><h3 id="比较开源聊天机器人" tabindex="-1">比较开源聊天机器人 <a class="header-anchor" href="#比较开源聊天机器人" aria-label="Permalink to &quot;比较开源聊天机器人&quot;">​</a></h3><p>在此更新中，由于社区贡献，我们将 RWKV-4-Raven-14B 模型添加到竞技场<a href="https://github.com/lm-sys/FastChat/issues/633" target="_blank" rel="noreferrer">中</a>。与所有其他模型不同，RWKV 模型是一个 RNN 而不是基于 transformer 的模型；但它的表现出奇的好！它很快在排行榜上呈上升趋势，并在整体排行榜上排名第 6。它在与除 Vicuna 之外的所有其他开源模型的非平局比赛中获胜超过 50%。欢迎您查看其<a href="https://github.com/BlinkDL/RWKV-LM" target="_blank" rel="noreferrer">存储库</a>，以了解更多有关内存节省和快速推理等其他功能的信息。感谢 RWKV 开发人员。</p><h3 id="elo分数的波动" tabindex="-1">Elo分数的波动 <a class="header-anchor" href="#elo分数的波动" aria-label="Permalink to &quot;Elo分数的波动&quot;">​</a></h3><p>现有模型的Elo分数可能会根据新游戏的结果上下波动。 这类似于国际象棋选手的 Elo 分数随时间变化的方式 （参见<a href="https://en.chessbase.com/post/historical-chess-ratings-dynamically-presented" target="_blank" rel="noreferrer">此处</a>）。 自从三大专属模式强者的加入，聊天机器人竞技场的竞争空前激烈！ 因此，我们观察到所有开源模型的 Elo 分数都有所下降。这是因为开源模型在对抗专有模型时会失去很多成对匹配。</p><h3 id="gpt-4-什么时候失效" tabindex="-1">GPT-4 什么时候失效？ <a class="header-anchor" href="#gpt-4-什么时候失效" aria-label="Permalink to &quot;GPT-4 什么时候失效？&quot;">​</a></h3><p>我们举了一些用户不喜欢 GPT-4 的例子。</p><p><img src="https://lmsys.org/images/blog/leaderboard_week2/claude_vs_gpt4.png" alt="Claude 优于 GPT-4 的一个示例"></p><p>上图中用户提出了一个需要仔细推理和规划的棘手问题。 尽管 Claude 和 GPT-4 都提供了相似的答案，但对于 Top 的回答，Claude 的反应稍微好一些。 然而，我们观察到由于抽样的随机性，这个例子的结果不能总是被复制。 有时 GPT-4 也可以给出与 Claude 相同的命令，但在这一代试验中失败了。</p><p>此外，我们注意到 GPT-4 的行为在使用 OpenAI API 与 ChatGPT 界面时略有不同， 这可能是由于不同的提示、采样参数或其他未知因素造成的。</p><p><img src="https://lmsys.org/images/blog/leaderboard_week2/claude_vs_gpt4_fail.png" alt="一个用户认为 Claude 和 GPT-4 都错了的例子"></p><p>上图中，尽管 Claude 和 GPT-4 具有惊人的能力，但它们仍在努力解决这种棘手的推理问题。</p><p>除了这些棘手的案例，还有很多不需要复杂推理或知识的简单问题。 在这种情况下，像 Vicuna 这样的开源模型的性能可以与 GPT-4 相媲美， 因此我们可以使用稍微弱一点（但更小或更便宜）的 LLM 来代替更强大的 GPT-4。</p><h3 id="获胜分数矩阵" tabindex="-1">获胜分数矩阵 <a class="header-anchor" href="#获胜分数矩阵" aria-label="Permalink to &quot;获胜分数矩阵&quot;">​</a></h3><p>我们在下图中展示了所有模型对的获胜分数。</p><p><img src="https://lmsys.org/images/blog/leaderboard_week2/win_fraction_matrix.png" alt="模型在所有非平局战斗中获胜的比例"></p><h3 id="每个模型组合的战斗次数" tabindex="-1">每个模型组合的战斗次数 <a class="header-anchor" href="#每个模型组合的战斗次数" aria-label="Permalink to &quot;每个模型组合的战斗次数&quot;">​</a></h3><p><img src="'+l+'" alt="每个模型组合的战斗次数"></p><h3 id="特定语言排行榜" tabindex="-1">特定语言排行榜 <a class="header-anchor" href="#特定语言排行榜" aria-label="Permalink to &quot;特定语言排行榜&quot;">​</a></h3><p><img src="https://lmsys.org/images/blog/leaderboard_week2/english_vs_non_english.png" alt="仅英语和非英语排行榜"></p><p>最后，我们通过将对话数据根据语言分为两个子集，展示了两个特定语言排行榜：(1) 纯英语和 (2) 非英语。 从图中，我们可以看出 <strong>Koala</strong> 在非英语语言方面更差，而 <strong>ChatGLM-6B</strong> 在非英语语言方面更好。 这是因为他们的训练数据的组成不同。</p><hr><div style="text-align:center;color:#00000099;font-size:14px;">END</div>',38),h=[n];function i(p,c,b,g,u,_){return a(),d("div",null,h)}const T=t(s,[["render",i]]);export{P as __pageData,T as default};
