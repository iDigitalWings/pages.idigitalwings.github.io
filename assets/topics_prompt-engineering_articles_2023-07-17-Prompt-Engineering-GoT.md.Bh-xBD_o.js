import{_ as i,a,af as n,o as t}from"./chunks/framework.C87LdZyP.js";const p="/assets/2959231184295291.D9Ztr22J.png",h="/assets/2960644052451125.BtXBSGZP.png",l="/assets/2961902855898625.nrkex4Si.png",e="/assets/2962114344522041.CVx77DL_.png",k="/assets/2962212049461541.CleLfvBw.png",o="/assets/2962810672411500.Bxv_Fbst.png",D=JSON.parse('{"title":"PromptEngineering：模拟人类大脑进行思维回溯和聚合的提示技术（GoT）？","description":"","frontmatter":{"title":"PromptEngineering：模拟人类大脑进行思维回溯和聚合的提示技术（GoT）？","date":"2023-07-17T00:00:00.000Z","tags":["ai","ml"],"category":["AI"]},"headers":[],"relativePath":"topics/prompt-engineering/articles/2023-07-17-Prompt-Engineering-GoT.md","filePath":"topics/prompt-engineering/articles/2023-07-17-Prompt-Engineering-GoT.md","lastUpdated":1718173059000}'),r={name:"topics/prompt-engineering/articles/2023-07-17-Prompt-Engineering-GoT.md"};function g(d,s,c,C,u,y){return t(),a("div",null,s[0]||(s[0]=[n('<div class="admonition abstract"><p class="admonition-title">abstract</p><p>思维树又进化成思维图了，和思维链到思维树不同，其实现复杂程度上升了不止一点点。让其思考过程更加接近人的思维， 多次的进行思维回溯和聚合（意识到前一个推理链中的某个想法可以与当前探索的想法相结合）。 今天带大家看看思维图技术如何来提升复杂问题的推理。</p></div><p>首先还是一张图给出 GoT（思维图）的大致原理，后面在管中窥豹的讲一下其复杂实现：</p><p><img src="'+p+'" alt="思维图原理"></p><h2 id="got-摘要" tabindex="-1">GoT 摘要 <a class="header-anchor" href="#got-摘要" aria-label="Permalink to &quot;GoT 摘要&quot;">​</a></h2><p>论文 PDF：<a href="https://arxiv.org/pdf/2308.09687v2.pdf" target="_blank" rel="noreferrer">https://arxiv.org/pdf/2308.09687v2.pdf</a> 网站和代码： <a href="https://github.com/spcl/graph-of-thoughts" target="_blank" rel="noreferrer">https://github.com/spcl/graph-of-thoughts</a></p><p>思维图（GoT）框架，可以提高大型语言模型（LLM）中的提示能力， 使其超越思维链或思维树（ToT）等范式所提供的能力。 GoT 的关键思维和主要优点是能够将 LLM 生成的信息建模为任意图， 其中<strong>信息单位</strong>（「LLM 思维」）是<strong>顶点</strong>，边对应于这些顶点之间的依赖关系。</p><p>这种方法可以将任意的 LLM 思维组合成协同结果，提炼整个思维网络的本质，或使用反馈循环增强思维。</p><p>GoT 在不同任务上比现有技术具有优势，例如，与 ToT 相比，排序质量提高了 62%，同时降低了 31% 的成本。</p><p>GoT 可通过新的思维转变进行扩展，从而可用于引领新的提示方案，使 LLM 的<strong>推理更接近人类思维或递归等大脑机制</strong>，两者都形成了复杂的网络。</p><h2 id="思维图和思维树的对比" tabindex="-1">思维图和思维树的对比 <a class="header-anchor" href="#思维图和思维树的对比" aria-label="Permalink to &quot;思维图和思维树的对比&quot;">​</a></h2><p>我们先看一下下面的对比图，ToT 和 GoT 的区别主要如下：</p><ul><li>思维图的思维可以回溯</li><li>图的思维链条可以交叉，而树不会</li></ul><p><img src="'+h+'" alt="思维图和思维树对比"></p><h2 id="背景" tabindex="-1">背景 <a class="header-anchor" href="#背景" aria-label="Permalink to &quot;背景&quot;">​</a></h2><p>大型语言模型 (LLM) 正在接管人工智能世界。 近年来，主要基于仅解码器的 Transformer 变体的模型得到了快速发展，例如GPT、 PaLM 或LLaMA。</p><p>提示工程是解决不同 LLM 任务的一种资源高效的方法。简而言之，在发送给 LLM 的输入中包含任务描述。 如果这个描述被适当地表述，LLM 将使用其基于自回归标记的机制来生成文本来解决该任务。</p><h2 id="原理" tabindex="-1">原理 <a class="header-anchor" href="#原理" aria-label="Permalink to &quot;原理&quot;">​</a></h2><p>通过使 LLM 思维形成任意图形结构，可以从根本上实现更强大的提示。 这是由人类推理、大脑结构或算法执行等多种现象推动的。 当研究一个新想法时，人类不仅会遵循一系列思维（如 CoT）或尝试不同的独立思维（如 ToT），而且实际上会<strong>形成一个更复杂的思维网络</strong>。</p><h3 id="模仿大脑的思考过程" tabindex="-1">模仿大脑的思考过程 <a class="header-anchor" href="#模仿大脑的思考过程" aria-label="Permalink to &quot;模仿大脑的思考过程&quot;">​</a></h3><p>人们可以探索某个推理链，<strong>回溯</strong>并开始一个新的推理链， 然后<strong>意识到前一个推理链中的某个想法可以与当前探索的想法相结合</strong>，并将它们合并成一个新的解决方案，利用他们的优点并消除他们的缺点。 同样，大脑形成复杂的网络，具有<strong>类似图形的模式</strong>，例如<strong>循环</strong>。</p><p>上面这个类似人类的思维模式不能够由 CoT、ToT 来完成。</p><h3 id="got-的想法" tabindex="-1">GoT 的想法 <a class="header-anchor" href="#got-的想法" aria-label="Permalink to &quot;GoT 的想法&quot;">​</a></h3><p>在GoT中，LLM思维被建模为顶点，而边是这些思维之间的依赖关系。 使用 GoT，人们可以通过构造具有多个传入边的顶点来聚合任意想法。 总体而言，GoT 利用的图形抽象无缝地将 CoT 和 ToT 概括为更复杂的思维模式， 而无需诉诸任何模型更新。</p><h3 id="设计挑战" tabindex="-1">设计挑战 <a class="header-anchor" href="#设计挑战" aria-label="Permalink to &quot;设计挑战&quot;">​</a></h3><p>将 GoT 付诸实践需要解决一些设计挑战，比如：</p><ul><li>针对不同任务的最佳图结构是什么？</li><li>如何最好地聚合想法以最大限度地提高准确性并最大限度地降低成本？</li></ul><h3 id="实现" tabindex="-1">实现 <a class="header-anchor" href="#实现" aria-label="Permalink to &quot;实现&quot;">​</a></h3><p>作者如何设计了一个用于实现 GoT 的模块化架构？</p><p>首先，对个人想法进行细粒度的控制。 这使我们能够完全控制与 LLM 正在进行的对话，并应用先进的思维转变，例如将正在进行的推理中<strong>最有前途的想法结合到新的想法中</strong>。</p><p>例如，在写作中，人们可以将几篇输入文章合并成一个连贯的摘要。在排序时，可以将多个已排序的数字子数组合并为最终的已排序数组。</p><p><img src="'+l+'" alt="聚合和生成思维转变的示例"></p><p>其次，确保我们的架构可以通过新颖的思维转换、推理模式（即思维图）和 LLM 模型无缝扩展。 这使得能够使用 GoT 快速构建新颖的提示想法原型，同时尝试不同的模型，例如 GPT-3.5、GPT-4 或 Llama-2 。</p><h3 id="架构" tabindex="-1">架构 <a class="header-anchor" href="#架构" aria-label="Permalink to &quot;架构&quot;">​</a></h3><p><img src="'+e+'" alt="GoT的系统架构，以及各个模块的API"></p><p>用户可以直接将设计扩展到新的提示方案，尝试新颖的思维转变，并插入不同的 LLM 。图中的<strong>蓝色部分包含架构概述</strong>，<strong>绿色部分列出了 API</strong> 。</p><p>GoT架构由一组交互的模块组成，上图（蓝色部分）。 这些模块是<strong>提示器</strong>（为 LLM 准备消息）、<strong>解析器</strong>（从 LLM 回复中提取信息）、 <strong>评分模块</strong>（验证 LLM 回复并对其进行评分）和<strong>控制器</strong>（协调整个推理过程，并决定如何进展）。</p><p>控制器包含两个更重要的元素：<strong>操作图</strong>（GoO）和<strong>图推理状态</strong>（GRS）。</p><p><strong>GoO 是一个静态结构</strong>，指定给定任务的图分解，即它规定了应用于 LLM 思维的转换，以及它们的顺序和依赖性。 <strong>GRS 是一个动态结构</strong>，可维持正在进行的 LLM 推理过程的状态（其思维及其状态的历史）。</p><h3 id="示例" tabindex="-1">示例 <a class="header-anchor" href="#示例" aria-label="Permalink to &quot;示例&quot;">​</a></h3><p>下图展示了一个示例提示以及 GRS(Graph Reasoning State) 和所涉及的操作。</p><p><img src="'+k+'" alt=""></p><h3 id="性能" tabindex="-1">性能 <a class="header-anchor" href="#性能" aria-label="Permalink to &quot;性能&quot;">​</a></h3><p><img src="'+o+`" alt="GoT 和其他技术的对比"></p><p>GoT 与 ToT 在所有考虑的问题实例中，GoT 比 ToT 和 ToT2 有了很大的改进。 ToT 通常比 ToT2 具有更高的质量，但同时成本也更高。 GoT 的成本始终低于 ToT，并且与 ToT2 相当（在某些情况下较低，在其他情况下较高）。</p><h2 id="安装运行" tabindex="-1">安装运行 <a class="header-anchor" href="#安装运行" aria-label="Permalink to &quot;安装运行&quot;">​</a></h2><p>我们可以在 Github 上下载 GoT 的代码安装：</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">git</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> clone</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> https://github.com/spcl/graph-of-thoughts.git</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">cd</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> graph-of-thoughts</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> install</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;"> -e</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> .</span></span></code></pre></div><p>也可以直接使用 pip 安装：</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> install</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> graph_of_thoughts</span></span></code></pre></div><p>然后拷贝 <code>config_template.json</code> 重命名为 <code>config.json</code>，进行配置，比如 ChatGPT：</p><div class="language-json vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">json</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">{</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#8DDB8C;">    &quot;chatgpt&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> : {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#8DDB8C;">        &quot;model_id&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;gpt-3.5-turbo&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#8DDB8C;">        &quot;prompt_token_cost&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">0.0015</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#8DDB8C;">        &quot;response_token_cost&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">0.002</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#8DDB8C;">        &quot;temperature&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">1.0</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#8DDB8C;">        &quot;max_tokens&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">1536</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#8DDB8C;">        &quot;stop&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">null</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#8DDB8C;">        &quot;organization&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#8DDB8C;">        &quot;api_key&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">    },</span></span></code></pre></div><p>或者 Llama 本地模型：</p><div class="language-json vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">json</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">    &quot;llama7b-hf&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> : {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#8DDB8C;">        &quot;model_id&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;Llama-2-7b-chat-hf&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#8DDB8C;">        &quot;cache_dir&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;/llama&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#8DDB8C;">        &quot;prompt_token_cost&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">0.0</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#8DDB8C;">        &quot;response_token_cost&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">0.0</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#8DDB8C;">        &quot;temperature&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">0.6</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#8DDB8C;">        &quot;top_k&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#8DDB8C;">        &quot;max_tokens&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">4096</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">    },</span></span></code></pre></div><p>指定使用对应的模型：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">lm </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> controller.ChatGPT(</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;config.json&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">model_name</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;chatgpt&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span></code></pre></div><p>完整的代码示例：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> examples.sorting.sorting_032 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> SortingPrompter, SortingParser, got, utils</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> graph_of_thoughts </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> controller, operations</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#768390;"># Problem input</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">to_be_sorted </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &quot;[0, 2, 6, 3, 8, 7, 1, 1, 6, 7, 7, 7, 7, 9, 3, 0, 1, 7, 9, 1, 3, 5, 1, 3, 6, 4, 5, 4, 7, 3, 5, 7]&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#768390;"># Retrieve the Graph of Operations</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">gop </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> got()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#768390;"># Configure the Language Model (Assumes config.json is in the current directory with OpenAI API key)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">lm </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> controller.ChatGPT(</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;config.json&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">model_name</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;chatgpt&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#768390;"># Create the Controller</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">ctrl </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> controller.Controller(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">  lm, </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">  gop, </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">  SortingPrompter(), </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">  SortingParser(),</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#768390;">  # The following dictionary is used to configure the initial thought state</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">  {</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">    &quot;original&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">: to_be_sorted,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">    &quot;current&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">    &quot;phase&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">    &quot;method&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;got&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">  }</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#768390;"># Run the Controller and generate the output graph</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">ctrl.run()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">ctrl.output_graph(</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;output_got.json&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span></code></pre></div><h2 id="结语" tabindex="-1">结语 <a class="header-anchor" href="#结语" aria-label="Permalink to &quot;结语&quot;">​</a></h2><p>图抽象是过去几十年来计算和人工智能领域一些成功设计的基础， 在提示工程里使用「<strong>图</strong>」也必然是一个趋势。</p>`,59)]))}const F=i(r,[["render",g]]);export{D as __pageData,F as default};
