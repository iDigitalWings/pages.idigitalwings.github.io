import{_ as s,a as e,af as i,o as r}from"./chunks/framework.C87LdZyP.js";const l="/assets/337250352283541.DviLWhzc.png",a="/assets/337430832608666.DdPGJ9x8.png",h="/assets/339665769849708.BCmf-tcC.png",o="/assets/339876857631583.DWe5Gy8Y.png",n="/assets/339971697774416.eYVi8Xwz.png",p="/assets/340474020597208.0clGSuq6.png",C=JSON.parse('{"title":"ChatGLM-6B: 清华大学开源中英双语对话语言模型","description":"","frontmatter":{"title":"ChatGLM-6B: 清华大学开源中英双语对话语言模型","date":"2023-03-07T00:00:00.000Z","tags":["ai","ml"],"category":["AI"]},"headers":[],"relativePath":"posts/2023/03/2023-03-07-chatglm6b.md","filePath":"posts/2023/03/2023-03-07-chatglm6b.md","lastUpdated":1718173059000}'),d={name:"posts/2023/03/2023-03-07-chatglm6b.md"};function c(g,t,b,m,u,k){return r(),e("div",null,t[0]||(t[0]=[i('<blockquote><p>ChatGLM-6B 是清华大学开源的大语言模型，支持中英双语对话。 它具有 62 亿参数，他基于通用语言框架（General Language Model (GLM)）， 并在大量中英文文本数据集上进行训练。ChatGLM-6B针对用户设备进行了优化， 可以在本地部署在消费级显卡上。</p></blockquote><h2 id="界面" tabindex="-1">界面 <a class="header-anchor" href="#界面" aria-label="Permalink to &quot;界面&quot;">​</a></h2><p>ChatGLM-6B 提供了一个 Web UI，使用 Gradio 编写。</p><p><img src="'+l+'" alt=""></p><p>前端时间还发布 VisualGLM-6B，多模态对话语言模型，支持图像理解。</p><p><img src="'+a+`" alt=""></p><h2 id="使用方式" tabindex="-1">使用方式 <a class="header-anchor" href="#使用方式" aria-label="Permalink to &quot;使用方式&quot;">​</a></h2><h3 id="硬件需求" tabindex="-1">硬件需求 <a class="header-anchor" href="#硬件需求" aria-label="Permalink to &quot;硬件需求&quot;">​</a></h3><p>我在笔记本上（Mac M1）和 Google Colab 上运行过，加上低内存的参数，是可以运行 FP16 的。 当然 INT4 也 OK。</p><p>注意 M1 不支持 GPU。</p><table tabindex="0"><thead><tr><th><strong>量化等级</strong></th><th><strong>最低 GPU 显存</strong><br>（推理）</th><th><strong>最低 GPU 显存</strong><br>（高效参数微调）</th></tr></thead><tbody><tr><td>FP16（无量化）</td><td>13 GB</td><td>14 GB</td></tr><tr><td>INT8</td><td>8 GB</td><td>9 GB</td></tr><tr><td>INT4</td><td>6 GB</td><td>7 GB</td></tr></tbody></table><h3 id="安装" tabindex="-1">安装 <a class="header-anchor" href="#安装" aria-label="Permalink to &quot;安装&quot;">​</a></h3><p>项目官网是：</p><ul><li><strong><a href="https://github.com/THUDM/ChatGLM-6B" target="_blank" rel="noreferrer">https://github.com/THUDM/ChatGLM-6B</a></strong></li></ul><p>下载代码并安装依赖：</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">git</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> clone</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> https://github.com/THUDM/ChatGLM-6B</span></span></code></pre></div><p>进入 ChatGLM-6B 目录，使用 pip 安装依赖：</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">cd</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> ChatGLM-6B</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> install</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;"> -r</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> requirements.txt</span></span></code></pre></div><h2 id="对话示例" tabindex="-1">对话示例 <a class="header-anchor" href="#对话示例" aria-label="Permalink to &quot;对话示例&quot;">​</a></h2><p>截图是我自己运行截图的，跟官方截图内容有一定出入。</p><h3 id="自我认知" tabindex="-1">自我认知 <a class="header-anchor" href="#自我认知" aria-label="Permalink to &quot;自我认知&quot;">​</a></h3><p><img src="`+h+'" alt=""></p><h3 id="提纲协作" tabindex="-1">提纲协作 <a class="header-anchor" href="#提纲协作" aria-label="Permalink to &quot;提纲协作&quot;">​</a></h3><p><img src="'+o+'" alt=""></p><h3 id="文案写作" tabindex="-1">文案写作 <a class="header-anchor" href="#文案写作" aria-label="Permalink to &quot;文案写作&quot;">​</a></h3><p><img src="'+n+'" alt=""></p><h3 id="信息抽取" tabindex="-1">信息抽取 <a class="header-anchor" href="#信息抽取" aria-label="Permalink to &quot;信息抽取&quot;">​</a></h3><p><img src="'+p+'" alt=""></p><h2 id="多模态对话" tabindex="-1">多模态对话 <a class="header-anchor" href="#多模态对话" aria-label="Permalink to &quot;多模态对话&quot;">​</a></h2><p>运行 <code>web_demo_vision.py</code> 来进行多模态对话：</p><p><img src="'+a+'" alt=""></p><p>更多信息可以参考 <strong>VisualGLM-6B</strong> 。</p><p>参考：</p><ul><li><a href="https://github.com/THUDM/ChatGLM-6B" target="_blank" rel="noreferrer">https://github.com/THUDM/ChatGLM-6B</a></li><li><a href="https://github.com/THUDM/VisualGLM-6B" target="_blank" rel="noreferrer">https://github.com/THUDM/VisualGLM-6B</a></li></ul><hr><div style="text-align:center;color:#00000099;font-size:14px;">END</div>',36)]))}const M=s(d,[["render",c]]);export{C as __pageData,M as default};
