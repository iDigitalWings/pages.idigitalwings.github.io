import{_ as t,a as e,af as i,o as d}from"./chunks/framework.C87LdZyP.js";const p="/assets/416561346091041.CNjAo9Jg.gif",o="/assets/417906144893083.K079guWk.gif",r="/assets/418189727790208.CZYUE0Ud.png",s="/assets/418325221983833.CmJqywE0.png",l="/assets/418363120584375.DvF6w4-U.png",n="/assets/418404595314541.CloO7-TD.png",c="/assets/418691965924083.CKvoZBRW.png",h="/assets/418731088826625.CYtUe7J-.png",m="/assets/419067245069041.BgTWIfd1.png",M=JSON.parse('{"title":"Google MediaPipe 扩散插件和多端设备机器学习解决方案 MediaPipe","description":"","frontmatter":{"title":"Google MediaPipe 扩散插件和多端设备机器学习解决方案 MediaPipe","date":"2023-04-24T00:00:00.000Z","tags":["ai","ml"],"category":["AI"]},"headers":[],"relativePath":"posts/2023/04/2023-04-24-google-mediapipe.md","filePath":"posts/2023/04/2023-04-24-google-mediapipe.md","lastUpdated":1718173059000}'),g={name:"posts/2023/04/2023-04-24-google-mediapipe.md"};function b(f,a,u,P,k,q){return d(),e("div",null,a[0]||(a[0]=[i('<blockquote><p>前几天看到谷歌更新了 MediaPipe 新插件，今天顺便介绍一下这个平台。</p></blockquote><h2 id="mediapipe-扩散插件" tabindex="-1">MediaPipe 扩散插件 <a class="header-anchor" href="#mediapipe-扩散插件" aria-label="Permalink to &quot;MediaPipe 扩散插件&quot;">​</a></h2><p>首先看下新东西， Google 发布的 MediaPipe 扩散插件：</p><p>它可以在设备（手机也行哦）上运行<strong>可控的文本到图像生成</strong>。 扩展了之前在设备上大型生成模型的 GPU 推理方面的工作。</p><p>这个新的低成本解决方案可以插入现有的扩散模型及其低秩适应 (LoRA) 变体中。</p><p>看下官方的示例</p><p><img src="'+p+'" alt=""></p><table tabindex="0"><thead><tr><th><strong>方法</strong></th><th><strong>参数</strong></th><th><strong>可拔插</strong></th><th><strong>从头构建</strong></th><th></th><th><strong>可移植</strong></th></tr></thead><tbody><tr><td>Plug-and-Play</td><td>860M*</td><td>✔️</td><td>❌</td><td></td><td>❌</td></tr><tr><td>ControlNet</td><td>430M*</td><td>✔️</td><td>❌</td><td></td><td>❌</td></tr><tr><td>T2I Adapter</td><td>77M</td><td>✔️</td><td>✔️</td><td></td><td>❌</td></tr><tr><td>MediaPipe Plugin</td><td>6M</td><td>✔️</td><td>✔️</td><td></td><td>✔️</td></tr></tbody></table><p><img src="'+o+'" alt="使用 MediaPipe 扩散插件的生成过程的图示"></p><p>谷歌还为基于扩散的文本到图像生成模型开发了插件， 其中包含 MediaPipe Face Landmark、 MediaPipe Holistic Landmark、depth maps 和 Canny edge。 对于每个任务，都从网络规模的图像文本数据集中选择大约 100K 图像， 并使用相应的 MediaPipe 解决方案计算控制信号。 我们使用PaLI的精致字幕来训练插件</p><h3 id="mediapipe-face-landmark" tabindex="-1">MediaPipe Face Landmark <a class="header-anchor" href="#mediapipe-face-landmark" aria-label="Permalink to &quot;MediaPipe Face Landmark&quot;">​</a></h3><p>该插件对人脸的 478 个坐标进行计算。</p><p>下表显示了通过调整面部网格和提示而随机生成的样本。 作为比较，给出了 ControlNet 和 Plugin 在给定条件下控制文本到图像的生成。</p><p><img src="'+r+'" alt="与 ControlNet 相比，用于生成文本到图像的人脸地标插件"></p><h3 id="mediapipe-holistic-landmark" tabindex="-1">MediaPipe Holistic Landmark <a class="header-anchor" href="#mediapipe-holistic-landmark" aria-label="Permalink to &quot;MediaPipe Holistic Landmark&quot;">​</a></h3><p>MediaPipe Holistic Landmarker任务包括身体姿势、手部和面部网格。 <img src="'+s+'" alt="用于生成文本到图像的整体地标插件"></p><h2 id="depth-maps" tabindex="-1">depth maps <a class="header-anchor" href="#depth-maps" aria-label="Permalink to &quot;depth maps&quot;">​</a></h2><p>直接看插件效果： <img src="'+l+'" alt="用于生成文本到图像的深度插件"></p><h2 id="canny-edge" tabindex="-1">Canny edge <a class="header-anchor" href="#canny-edge" aria-label="Permalink to &quot;Canny edge&quot;">​</a></h2><p>直接看效果： <img src="'+n+'" alt="用于生成文本到图像的 Canny-edge 插件"></p><p>插件详情可以去下面地址查看：</p><ul><li><a href="https://ai.googleblog.com/2023/06/on-device-diffusion-plugins-for.html" target="_blank" rel="noreferrer">https://ai.googleblog.com/2023/06/on-device-diffusion-plugins-for.html</a></li></ul><h2 id="mediapipe-是什么" tabindex="-1">MediaPipe 是什么 <a class="header-anchor" href="#mediapipe-是什么" aria-label="Permalink to &quot;MediaPipe 是什么&quot;">​</a></h2><p>MediaPipe 是机器学习开创性的解决方案。 它针对各种平台上的端到端性能进行了优化。 可以轻松自定义和部署到移动设备（Android、iOS）、 Web、桌面、边缘设备和物联网等你需要的一切地方。</p><p>下面给大家看一下 mediaPipe 能做什么？</p><h3 id="物体检测" tabindex="-1">物体检测 <a class="header-anchor" href="#物体检测" aria-label="Permalink to &quot;物体检测&quot;">​</a></h3><p>跟踪和标记图像中的对象。</p><p><img src="'+c+'" alt="物体检测"></p><h3 id="图像分类" tabindex="-1">图像分类 <a class="header-anchor" href="#图像分类" aria-label="Permalink to &quot;图像分类&quot;">​</a></h3><p>识别图像中的内容。</p><p><img src="'+h+'" alt="图像分类卡图像"></p><h3 id="图像分割" tabindex="-1">图像分割 <a class="header-anchor" href="#图像分割" aria-label="Permalink to &quot;图像分割&quot;">​</a></h3><p>定位对象并创建带有标签的图像蒙版。</p><p><img src="'+m+'" alt="图像分割卡图像"></p><h3 id="交互式细分" tabindex="-1">交互式细分 <a class="header-anchor" href="#交互式细分" aria-label="Permalink to &quot;交互式细分&quot;">​</a></h3><p>分割图像中感兴趣的对象。</p><p><img src="https://www.gstatic.com/alkali/0ad6686334e1990efb3ddb77455665236c83612c.png" alt="交互式分割卡图像"></p><h3 id="手势识别" tabindex="-1">手势识别 <a class="header-anchor" href="#手势识别" aria-label="Permalink to &quot;手势识别&quot;">​</a></h3><p>识别并识别手势。</p><p><img src="https://www.gstatic.com/alkali/ddc10b3ff2318f233f34585084625b0c2b3b495e.png" alt="手势识别卡图片"></p><h3 id="手部标志检测" tabindex="-1">手部标志检测 <a class="header-anchor" href="#手部标志检测" aria-label="Permalink to &quot;手部标志检测&quot;">​</a></h3><p>检测手部标志。</p><p><img src="https://www.gstatic.com/alkali/09930285836a2b9a743f45da5d8e217fd4ead17e.png" alt="手部地标检测卡图像"></p><h3 id="图像嵌入" tabindex="-1">图像嵌入 <a class="header-anchor" href="#图像嵌入" aria-label="Permalink to &quot;图像嵌入&quot;">​</a></h3><p>将图像转换为嵌入向量。</p><p><img src="https://www.gstatic.com/alkali/fd5acf857197d7eb0630c9660131d1a710dcbfe3.png" alt="图像嵌入卡图像"></p><h3 id="人脸检测" tabindex="-1">人脸检测 <a class="header-anchor" href="#人脸检测" aria-label="Permalink to &quot;人脸检测&quot;">​</a></h3><p>实时检测人脸。</p><p><img src="https://www.gstatic.com/alkali/261f067d178d3bc27e6bb65b9e61aa3e1288df1e.png" alt="人脸检测卡图像"></p><h3 id="人脸特征点检测" tabindex="-1">人脸特征点检测 <a class="header-anchor" href="#人脸特征点检测" aria-label="Permalink to &quot;人脸特征点检测&quot;">​</a></h3><p>实时检测面部标志和混合形状分数。</p><p><img src="https://www.gstatic.com/alkali/bad5d8fb225db11f18301f0c7e80b87eac6abe90.png" alt="人脸特征点检测卡图像"></p><h3 id="姿势检测" tabindex="-1">姿势检测 <a class="header-anchor" href="#姿势检测" aria-label="Permalink to &quot;姿势检测&quot;">​</a></h3><p>实时识别身体关键点。 <img src="https://www.gstatic.com/alkali/ac43bed27c8ef9c4ce0e7a23838fa0b8c60fe2d8.png" alt="姿势地标检测卡图像"></p><hr><div style="text-align:center;color:#00000099;font-size:14px;">END</div>',56)]))}const w=t(g,[["render",b]]);export{M as __pageData,w as default};
