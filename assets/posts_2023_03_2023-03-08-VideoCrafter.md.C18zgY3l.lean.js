import{_ as a,a as t,af as i,e as p,o as n}from"./chunks/framework.C87LdZyP.js";const e="/assets/let-dance-64.BtIlv31I.gif",l="/assets/intro.-ecd-94h.gif",h="/assets/001.DRykLCmt.gif",r="/assets/002.Cwo7Cd9f.gif",k="/assets/003.qKNMudc6.gif",o="/assets/004.DStkG_Rx.gif",d="/assets/001_loving_vincent.CYnI9e0d.gif",g="/assets/002_frozen.DoW-KiW-.gif",F="/assets/003_your_name.OftaP3Qi.gif",c="/assets/004_coco.Dam3lhbO.gif",m="/assets/input_5_randk1.DExmZK6r.gif",_="/assets/depth_5_randk1.DO0gzVfg.gif",f="/assets/0001.CnWOZaFM.gif",D="/assets/0002.CE_VpPd9.gif",y="/assets/0003.yWskPdLG.gif",q=JSON.parse('{"title":"VideoCrafter: 文生图可能过时了，试试这个文本生成和控制视频的工具","description":"","frontmatter":{"title":"VideoCrafter: 文生图可能过时了，试试这个文本生成和控制视频的工具","date":"2023-03-08T00:00:00.000Z","tags":["ai","ml"],"category":["AI"]},"headers":[],"relativePath":"posts/2023/03/2023-03-08-VideoCrafter.md","filePath":"posts/2023/03/2023-03-08-VideoCrafter.md","lastUpdated":1718173059000}'),u={name:"posts/2023/03/2023-03-08-VideoCrafter.md"};function C(A,s,b,v,V,L){return n(),t("div",null,s[0]||(s[0]=[i('<blockquote><p>LVDM全称Latent Video Diffusion Models，是由香港科技大学与腾讯AI实验室发布的一个视频扩散模型，可以用来做文本生成视频以及视频编辑。 而 VideoCrafter 是一个开源视频生成和编辑工具箱，用于制作视频内容。支持通用文本到视频的生成，LoRA 生成个性化的文本到视频 以及具有更多条件控制的视频生成。</p></blockquote><h2 id="预览" tabindex="-1">预览 <a class="header-anchor" href="#预览" aria-label="Permalink to &quot;预览&quot;">​</a></h2><p>视频控制支持不同的分辨率和8秒的文本到视频生成</p><p><img src="'+e+'" alt="let-dance-64.gif"></p><h2 id="功能" tabindex="-1">功能 <a class="header-anchor" href="#功能" aria-label="Permalink to &quot;功能&quot;">​</a></h2><p>🤗🤗🤗VideoCrafter是一个开源视频生成和编辑工具箱，用于制作视频内容。 它目前包括以下三种类型的模型：</p><p><img src="'+l+'" alt="intro.gif"></p><h3 id="_1-基本-t2v-通用文本到视频生成" tabindex="-1">1. 基本 T2V：通用文本到视频生成 <a class="header-anchor" href="#_1-基本-t2v-通用文本到视频生成" aria-label="Permalink to &quot;1. 基本 T2V：通用文本到视频生成&quot;">​</a></h3><p>我们提供了一个基于潜在视频扩散模型（LVDM）的基本文本到视频（T2V）生成模型。 它可以根据输入的文本描述合成逼真的视频。</p><p>“晚上在白雪皑皑的森林里篝火，背景是星空。”</p><p><img src="'+h+'" alt="001.gif"></p><p>“汽车在夜间在高速公路上行驶。</p><p><img src="'+r+'" alt="002.gif"></p><p>“小丑鱼游泳的特写。4K”</p><p><img src="'+k+'" alt="003.gif"></p><p>《骑马的宇航员》</p><p><img src="'+o+'" alt="004.gif"></p><h3 id="_2-视频lora-使用-lora-生成个性化的文本到视频" tabindex="-1">2. 视频LoRA： 使用 LoRA 生成个性化的文本到视频 <a class="header-anchor" href="#_2-视频lora-使用-lora-生成个性化的文本到视频" aria-label="Permalink to &quot;2. 视频LoRA： 使用 LoRA 生成个性化的文本到视频&quot;">​</a></h3><p>基于预训练的LVDM，我们可以通过在一组描述特定概念的视频剪辑或图像上进行微调来创建自己的视频生成模型。</p><p>我们采用 LoRA 来实现微调，因为它易于训练并且需要更少的计算资源.</p><p>以下是我们的四个 VideoLoRA 模型的生成结果，这些模型在四种不同风格的视频剪辑上进行了训练。</p><p>通过提供描述视频内容的句子以及 LoRA 触发词 （在 LoRA 训练期间指定）， 它可以生成具有所需样式的视频 （或主题/概念）.</p>',22),p("p",{trigger_word:""},"输入到四个 VideoLoRA 模型的结果：A monkey is playing a piano, $",-1),i('<p>“爱文森特风格”</p><p><img src="'+d+'" alt="001_loving_vincent.gif"></p><p>《冰雪奇缘》风格</p><p><img src="'+g+'" alt="002_frozen.gif"></p><p>“诚新海诚你的名字风格”</p><p><img src="'+F+'" alt="003_your_name.gif"></p><p>“可可风格”</p><p><img src="'+c+'" alt="004_coco.gif"></p><h3 id="_3-视频控制-具有更多条件控制的视频生成" tabindex="-1">3. 视频控制：具有更多条件控制的视频生成 <a class="header-anchor" href="#_3-视频控制-具有更多条件控制的视频生成" aria-label="Permalink to &quot;3. 视频控制：具有更多条件控制的视频生成&quot;">​</a></h3><p>为了增强T2V模型的可控能力，我们开发了受T2I适配器启发的条件适配器。 通过将轻量级适配器模块插入 T2V 模型，我们可以获得具有更详细控制信号（例如深度）的生成结果。</p><p>输入文本：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span>Ironman is fighting against the enemy, big fire in the background, photorealistic, 4k</span></span></code></pre></div><p><img src="'+m+'" alt="input_5_randk1.gif"></p><p><img src="'+_+'" alt="depth_5_randk1.gif"></p><p><img src="'+f+'" alt="0001.gif"></p><p><img src="'+D+'" alt="0002.gif"></p><p><img src="'+y+`" alt="0003.gif"></p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">DDIM</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> Sampler:</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">  96%</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 48/50</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [01:43&lt;00:04,  </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">2.25s/it]</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">DDIM</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> Sampler:</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">  98%</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 49/50</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [01:46&lt;00:02,  </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">2.26s/it]</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">DDIM</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> Sampler:</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 100%</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 50/50</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [01:48&lt;00:00,  </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">2.17s/it]</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">Sampling</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> Batches</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> (text-to-video): 100% 1/1 [01:50</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">&lt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">00:00, 110.80s/it]</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">Adding</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> empty</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> frames:</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 100%</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 1/1</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [00:00&lt;00:00, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">16980.99it/s]</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">Making</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> grids:</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 100%</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 16/16</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [00:00&lt;00:00, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">52428.80it/s]</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">Successfully</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> saved</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> videos</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> in</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> results/videolora/videos</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">Finish</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> sampling!</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">Run</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> time</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;"> 113.79</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> seconds</span></span></code></pre></div><ul><li>The cat Is catching the butterfly</li></ul><hr><div style="text-align:center;color:#00000099;font-size:14px;">END</div>`,21)]))}const B=a(u,[["render",C]]);export{q as __pageData,B as default};
