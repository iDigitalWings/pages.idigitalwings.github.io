import{_ as a,a as o,af as t,o as r}from"./chunks/framework.C87LdZyP.js";const m="/assets/367440629770583.svHUmLqN.png",s="/assets/367920398150041.DpP8yakH.png",n="/assets/367806005192500.Ba4MSR8A.png",l="/assets/369431071110375.D_GGIa92.png",p="/assets/363867336585458.LRQI9jk-.png",g="/assets/368314834632875.C1NXHNKD.png",i="/assets/369269413411250.BA4DTVCD.png",d="/assets/369338784479625._RtEz04v.png",q=JSON.parse('{"title":"『开放』而不『开源』，谷歌发布最先进的开放模型 Gemma，意欲何为？","description":"","frontmatter":{"title":"『开放』而不『开源』，谷歌发布最先进的开放模型 Gemma，意欲何为？","date":"2024-02-23T00:00:00.000Z","tags":["ai","llm","google"],"category":["ai"]},"headers":[],"relativePath":"posts/2024/02/2024-02-23-google-gemma-open-model.md","filePath":"posts/2024/02/2024-02-23-google-gemma-open-model.md","lastUpdated":1718173059000}'),c={name:"posts/2024/02/2024-02-23-google-gemma-open-model.md"};function h(G,e,u,b,_,f){return r(),o("div",null,e[0]||(e[0]=[t('<div class="admonition abstract"><p class="admonition-title">abstract</p><p>2月21日，谷歌宣布可免费商用的 Gemma 大模型在全球开放使用，并强调其为开放模型，而非开源模型。 今天先聊一下开放模型这个概念的意义，在看看 Gemma 模型为何物。</p></div><h2 id="何为开放" tabindex="-1">何为开放 <a class="header-anchor" href="#何为开放" aria-label="Permalink to &quot;何为开放&quot;">​</a></h2><p>谷歌强调 Gemma 是开放模型，首先说明模型<strong>免费</strong>以及<strong>可商用</strong>(允许所有组织负责任地进行商用和分发)， 同时强调其<strong>开放</strong>而<strong>不开源</strong>，意味着模型虽然先进，但是谷歌并不会分享关于模型的过多技术细节。 包括 Gemma的源码、训练数据等等。 这无疑和 OpenAI 的做法如出一辙。</p><p><img src="'+m+'" alt=""></p><p>!!! explain 和 OpenAI 的核心产品 ChatGPT 以及前段时间爆火的 Sora 类似， 谷歌开放模型的发布想必未来也不会公布特别详细的技术细节。这也是其保证 技术领先性的必要手段。 !!!</p><h3 id="重新划分大模型阵营" tabindex="-1">重新划分大模型阵营 <a class="header-anchor" href="#重新划分大模型阵营" aria-label="Permalink to &quot;重新划分大模型阵营&quot;">​</a></h3><p>在此之前，我们再谈及大模型（包括其他软件的时候），都是两个评判标准：</p><ul><li>是否<strong>开源</strong></li><li>是否可<strong>免费商用</strong></li></ul><p>自此之后，<strong>开放模型</strong>这个概念可能会慢慢被大众接受，相信更多的厂商也会推出自己的开放模型。</p><p><img src="'+s+'" alt="Gemma开放模型"></p><h3 id="如何让开放模型有竞争力" tabindex="-1">如何让开放模型有竞争力 <a class="header-anchor" href="#如何让开放模型有竞争力" aria-label="Permalink to &quot;如何让开放模型有竞争力&quot;">​</a></h3><p>这个问题谷歌给出了很好的答案和范例，看 Gemma 发布文章就能看出，那就是：<strong>给出优秀的模型以及开发者需要的一切东西</strong>。</p><p>包括：</p><ul><li>各个主流框架的集成以及实例</li><li>微调工具链</li><li>宽松的使用条款（免费商用）</li></ul><p>这点我们后面详细介绍。</p><h3 id="对谷歌的意义" tabindex="-1">对谷歌的意义 <a class="header-anchor" href="#对谷歌的意义" aria-label="Permalink to &quot;对谷歌的意义&quot;">​</a></h3><p>众所周知，Meta 公司因其在AI领域的开源策略备受业界好评，而谷歌和OpenAI却 因坚持技术封闭而常遭受到外界的批评，两者都在各自最新和最先进的模型上选择了闭源的策略， 被很多人认为是不利于人工智能的技术进步。</p><p><img src="'+n+'" alt="开放模型必然会吸引更多开发者进入谷歌云生态"></p><p>而此次Gemma开放模型也标志着谷歌大模型策略的转变。兼顾开源和闭源的的策略， 不仅能够同时和Meta、OpenAI的开源和闭源公司同时竞争。其Gemma开放模型也必然会 吸引更多的开发者进入谷歌云生态，推动相关业务的发展。</p><h2 id="关于-gemma" tabindex="-1">关于 Gemma <a class="header-anchor" href="#关于-gemma" aria-label="Permalink to &quot;关于 Gemma&quot;">​</a></h2><p>Gemma 得名于拉丁语『宝石』，发音是<code>ˈdʒemə</code> (杰玛)。</p><p>它由 Google DeepMind 和 Google 的其他团队开发，其灵感来自 Gemini， 采用与创建 Gemini 模型相同的研究和技术而构建。我们可以认为 Gemma 是 <strong>Gemini 的青春版</strong>。</p><blockquote><p>大家可以访问 <a href="https://ai.google.dev/gemma" target="_blank" rel="noreferrer">https://ai.google.dev/gemma</a> 使用 Gemma。</p></blockquote><h3 id="轻量级模型" tabindex="-1">轻量级模型 <a class="header-anchor" href="#轻量级模型" aria-label="Permalink to &quot;轻量级模型&quot;">​</a></h3><p>谷歌在介绍 Gemma 时候，强调了它是<code>最先进的</code>、<code>轻量级</code>开放模型。有 2B 和 7B 两种尺寸的模型权重。</p><p>!!! explain 此前最流行的开源模型 Llama-2 包含了 7B、13B 以及 70B 三个型号的模型。 !!!</p><p>在此之前所有排的上号的模型都至少会发布 10B 以上尺寸的模型，甚至有更大的 100B 以上模型。 我觉得这次谷歌这次似乎看对了方向，不去卷大模型的<strong>大</strong>，开始卷大模型的小了。 当然让模型小且好用，没有牛逼的技术实力是办不到的。</p><p>根据我的经验 6B（7B）的模型是一般开发人员笔记本电脑运行的极限，当然也只是<strong>仅仅运行</strong>， 其推理速度并不快，只能做一个技术验证，并不能作为日常开发很流畅的使用。而 1B（2B）的 模型就可以在开发人员的电脑上很流畅的运行起来，丢在后台作为一个定制本地AI助手一直运行着也不会 对你日常工作有什么影响。</p><p><img src="'+l+'" alt="轻量级的开放模型"></p><p>而 10B 以上的模型，无一例外都是那些有卡玩家的专属， 这也无疑是给很多想尝鲜或者做技术调研用户树起了一个逞强， 让哪些潜在用户变成看客。</p><p>个人觉得，谷歌反其道而行的<strong>小模型策略</strong>，反而能让其受到开发者的拥护，更受市场的欢迎。</p><h3 id="gemma-性能" tabindex="-1">Gemma 性能 <a class="header-anchor" href="#gemma-性能" aria-label="Permalink to &quot;Gemma 性能&quot;">​</a></h3><p>首先谷歌宣称 Gemma 是<strong>同尺寸拥有最先进新能</strong>，甚至在关键测试上超越了更大的模型， 这里谷歌拿当前开源模型的王者 Lamma-2 做了对比：</p><p><img src="'+p+'" alt="Gemma 和 Llama-2 性能对比"></p><p>数据集、性能和建模方法等更详细的信息可以参考它的<a href="https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf" target="_blank" rel="noreferrer">技术报告</a>。</p><blockquote><p><a href="https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf" target="_blank" rel="noreferrer">https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf</a></p></blockquote><h3 id="gemma-开放了什么" tabindex="-1">Gemma 开放了什么？ <a class="header-anchor" href="#gemma-开放了什么" aria-label="Permalink to &quot;Gemma 开放了什么？&quot;">​</a></h3><p>我们前面提到了谷歌定义Gemma为开放模型，那么它到底开放了什么？</p><ul><li>发布了两种尺寸的模型配重：Gemma 2B 和 Gemma 7B。每个尺寸都发布了经过预训练和指令调整的变体。</li><li>新的Responsible Generative AI 工具包为使用 Gemma 创建更安全的 AI 应用程序提供了指导和基本工具。</li><li>通过原生<strong>Keras 3.0</strong>提供跨所有主要框架的<strong>推理和监督微调 (SFT) 工具链</strong>：<code>JAX</code>、<code>PyTorch</code> 和 <code>TensorFlow</code> 。</li><li>即用型<strong>Colab</strong>和<strong>Kaggle</strong> 笔记本，以及与<code>Hugging Face</code>、<code>MaxText</code>、<code>NVIDIA NeMo</code>和 <code>TensorRT-LLM</code>等流行工具的集成。</li><li>预训练和指令调整的 Gemma 模型可以在您的笔记本电脑、工作站或 Google Cloud 上运行，并可轻松部署在Vertex AI和Google Kubernetes Engine (GKE) 上。</li><li><a href="https://www.kaggle.com/models/google/gemma/license/consent" target="_blank" rel="noreferrer">使用条款</a>允许所有组织（无论规模大小）负责任地进行商业使用和分发。</li></ul><p><img src="'+g+'" alt="Gemma多个框架的集成"></p><p>更详细的内容可以参考谷歌<a href="https://blog.google/technology/developers/gemma-open-models/" target="_blank" rel="noreferrer">发布 Gemma 的文章</a>。</p><h3 id="安全性" tabindex="-1">安全性 <a class="header-anchor" href="#安全性" aria-label="Permalink to &quot;安全性&quot;">​</a></h3><p>安全性一直是AI大厂重视并投入大量人力物力，而小厂不太关心的领域。 我们上篇文章也提到了 Gemini 1.5 未对公众开发的主要原因就是安全问题。</p><p><img src="'+i+'" alt="负责任的AI开发"></p><p>Gemma 的安全性主要体现在以下方面：</p><ul><li>以<a href="https://ai.google.dev/responsible?utm_source=agd&amp;utm_medium=referral&amp;utm_campaign=explore-responsible&amp;utm_content&amp;hl=zh-cn" target="_blank" rel="noreferrer"><strong>谷歌人工智能原则</strong></a>为核心进行设计。</li><li>使用自动化技术从训练集中<strong>过滤掉某些个人信息和其他敏感数据</strong>。</li><li>利<strong>用人类反馈 (RLHF)</strong> 进行广泛的微调和强化学习，使指令调整模型与负责任的行为保持一致。</li><li>为了了解和降低 Gemma 模型的风险状况，我们进行了稳健的<strong>评估</strong>，包括<strong>手动红队</strong>、<strong>自动对抗测试</strong>以及<strong>危险活动模型能力评估</strong>。</li><li>与 Gemma 一起发布了新的 <strong>负责任的生成式AI工具包</strong>，以帮助开发人员和研究人员优先构建安全且负责任的 AI 应用程序。</li></ul><h3 id="下载使用" tabindex="-1">下载使用 <a class="header-anchor" href="#下载使用" aria-label="Permalink to &quot;下载使用&quot;">​</a></h3><p>最后，大家可以通过 HuggingFace，Kaggle，Vertex AI 等多个平台下载使用过 Gemma 模型。</p><p><img src="'+d+'" alt="多个平台都可以下载使用 Gemma 模型"></p>',49)]))}const x=a(c,[["render",h]]);export{q as __pageData,x as default};
