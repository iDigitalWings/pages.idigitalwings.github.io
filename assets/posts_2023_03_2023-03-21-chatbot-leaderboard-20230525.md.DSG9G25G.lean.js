import{_ as d,a,af as e,o as r}from"./chunks/framework.C87LdZyP.js";const l="/assets/810011745997791.BvmxnX1T.png",o="/assets/809740266086375.CoJL4raw.png",u=JSON.parse('{"title":"LMSYS 聊天机器人竞技排行榜 2023-05-25","description":"","frontmatter":{"title":"LMSYS 聊天机器人竞技排行榜 2023-05-25","date":"2023-03-25T00:00:00.000Z","tags":["ai","ml"],"category":["AI"]},"headers":[],"relativePath":"posts/2023/03/2023-03-21-chatbot-leaderboard-20230525.md","filePath":"posts/2023/03/2023-03-21-chatbot-leaderboard-20230525.md","lastUpdated":1718173059000}'),s={name:"posts/2023/03/2023-03-21-chatbot-leaderboard-20230525.md"};function n(i,t,p,h,c,P){return r(),a("div",null,t[0]||(t[0]=[e('<blockquote><p>为了促进LLM在聊天机器人领域的发展和创新， <strong>LMSYS Org</strong> 创建了一个名为 <strong>Chatbot Arena</strong> 的平台。 它展示了不同的聊天机器人模型在与真实用户对话中的性能和评分。 5月25号的更新中，竞技场中添加了 4 个新玩家， 针对 27K 匿名投票数据出炉了新 Elo 评级排行榜。</p></blockquote><p>先看下排名：</p><table tabindex="0"><thead><tr><th>排名</th><th>模型</th><th>Elo 分数</th></tr></thead><tbody><tr><td>1</td><td>🥇 GPT-4</td><td>1225</td></tr><tr><td>2</td><td>🥈 Claude-v1</td><td>1195</td></tr><tr><td>3</td><td>🥉 Claude-instant-v1</td><td>1153</td></tr><tr><td>4</td><td>GPT-3.5-turbo</td><td>1143</td></tr><tr><td>5</td><td>Vicuna-13B</td><td>1054</td></tr><tr><td>6</td><td>PaLM 2</td><td>1042</td></tr><tr><td>7</td><td>Vicuna-7B</td><td>1007</td></tr><tr><td>8</td><td>Koala-13B</td><td>980</td></tr><tr><td>9</td><td>mpt-7b-chat</td><td>952</td></tr><tr><td>10</td><td>FastChat-T5-3B</td><td>941</td></tr><tr><td>11</td><td>Alpaca-13B</td><td>937</td></tr><tr><td>12</td><td>RWKV-4-Raven-14B</td><td>928</td></tr><tr><td>13</td><td>Oasst-Pythia-12B</td><td>921</td></tr><tr><td>14</td><td>ChatGLM-6B</td><td>921</td></tr><tr><td>15</td><td>StableLM-Tuned-Alpha-7B</td><td>882</td></tr><tr><td>16</td><td>Dolly-V2-12B</td><td>866</td></tr><tr><td>17</td><td>LLaMA-13B</td><td>854</td></tr></tbody></table><p>截图如下：</p><p><img src="'+l+'" alt=""></p><blockquote><p>顺便提一句，个人最喜欢的是 Claude 和 Bard。</p></blockquote><p>PC页面 可以看如下完整表格。</p><table tabindex="0"><thead><tr><th>排名</th><th>模型</th><th>Elo 分数</th><th>描述</th><th>执照</th></tr></thead><tbody><tr><td>1</td><td>🥇 GPT-4</td><td>1225</td><td>OpenAI 的 ChatGPT-4</td><td>私有</td></tr><tr><td>2</td><td>🥈 Claude-v1</td><td>1195</td><td>Anthropic的克劳德</td><td>私有</td></tr><tr><td>3</td><td>🥉 Claude-instant-v1</td><td>1153</td><td>更轻、更便宜、更快的 Claude 版本</td><td>私有</td></tr><tr><td>4</td><td>GPT-3.5-turbo</td><td>1143</td><td>OpenAI 的 ChatGPT-3.5</td><td>私有</td></tr><tr><td>5</td><td>Vicuna-13B</td><td>1054</td><td>LLaMA 对 LMSYS 的用户共享对话进行微调的聊天助手</td><td>权重可用；非商业用途</td></tr><tr><td>6</td><td>PaLM 2</td><td>1042</td><td>PaLM 2 已针对聊天进行调整。<br>PaLM 2 型号系列为 Bard 提供动力。</td><td>私有</td></tr><tr><td>7</td><td>Vicuna-7B</td><td>1007</td><td>LLaMA 对 LMSYS 的用户共享对话进行微调的聊天助手</td><td>权重可用；非商业用途</td></tr><tr><td>8</td><td>Koala-13B</td><td>980</td><td>BAIR 的学术研究对话模型</td><td>权重可用；非商业用途</td></tr><tr><td>9</td><td>mpt-7b-chat</td><td>952</td><td>MosaicML 从 MPT-7B 微调的聊天机器人</td><td>CC-By-NC-SA-4.0</td></tr><tr><td>10</td><td>FastChat-T5-3B</td><td>941</td><td>LMSYS 从 FLAN-T5 微调的聊天助手</td><td>Apache 2.0</td></tr><tr><td>11</td><td>Alpaca-13B</td><td>937</td><td>LLaMA 在斯坦福的指令遵循演示中微调的模型</td><td>权重可用；非商业用途</td></tr><tr><td>12</td><td>RWKV-4-Raven-14B</td><td>928</td><td>具有变压器级 LLM 性能的 RNN</td><td>Apache 2.0</td></tr><tr><td>13</td><td>Oasst-Pythia-12B</td><td>921</td><td>LAION 人人可用的开放助手</td><td>Apache 2.0</td></tr><tr><td>14</td><td>ChatGLM-6B</td><td>921</td><td>清华大学开放式双语对话语言模型</td><td>权重可用；非商业用途</td></tr><tr><td>15</td><td>StableLM-Tuned-Alpha-7B</td><td>882</td><td>稳定性 AI 语言模型</td><td>CC-BY-NC-SA-4.0</td></tr><tr><td>16</td><td>Dolly-V2-12B</td><td>866</td><td>Databricks 的指令调优开放大型语言模型</td><td>MIT</td></tr><tr><td>17</td><td>LLaMA-13B</td><td>854</td><td>Meta 开放高效的基础语言模型</td><td>权重可用；非商业用途</td></tr></tbody></table><h3 id="获胜分数矩阵" tabindex="-1">获胜分数矩阵 <a class="header-anchor" href="#获胜分数矩阵" aria-label="Permalink to &quot;获胜分数矩阵&quot;">​</a></h3><p>所有模型对的获胜分数矩阵如图所示。</p><p><img src="'+o+'" alt="所有模型对的获胜分数矩阵"></p><h2 id="结果分析" tabindex="-1">结果分析 <a class="header-anchor" href="#结果分析" aria-label="Permalink to &quot;结果分析&quot;">​</a></h2><h3 id="谷歌-palm-2" tabindex="-1">谷歌 PaLM 2 <a class="header-anchor" href="#谷歌-palm-2" aria-label="Permalink to &quot;谷歌 PaLM 2&quot;">​</a></h3><p>Google 的 PaLM 2 是自上次排行榜更新以来发布的最重要的模型之一。 <a href="https://cloud.google.com/vertex-ai/docs/release-notes#May_10_2023" target="_blank" rel="noreferrer">我们通过Google Cloud Vertex AI API</a>将 PaLM 2 Chat 添加到 Chatbot Arena 。该模型以代号<em>chat-bison@001</em>进行聊天调优。</p><p>在过去的两周内，PaLM 2 与其他 16 个聊天机器人进行了约 1.8k 的匿名战斗， 目前在排行榜上排名第 6 位。它的排名高于所有其他开源聊天机器人， 但 Vicuna-13B 除外，其 Elo 比 PaLM 2 高 12 分（Vicuna 1054 vs. PaLM 2 1042）， 就 ELO 评级而言几乎是平手。我们从 PaLM 2 的 Arena 数据中注意到以下有趣的结果。</p><p>PaLM 2 在与前 4 名玩家（即 GPT-4、Claude-v1、ChatGPT、Claude-instant-v1）对战时表现更好， 并且它还赢得了 53% 的 Vicuna 比赛，但在与较弱的玩家对战时更差。这可以在显示获胜分数矩阵的图中看到。 在 PaLM 2 参加的所有战斗中，21.6% 输给了不是 GPT-4、Claude-v1、GPT-3.5-turbo、Claude-instant-v1 之一的聊天机器人。 作为参考，另一个专有模型 GPT-3.5-turbo 只输给了这些聊天机器人 12.8% 的战斗。</p><p>简而言之，我们发现与我们评估过的其他模型相比，Google Cloud Vertex API 当前可用的 PaLM 2 版本存在以下缺陷：</p><ol><li>PaLM 2 似乎比其他模型受到更严格的监管，这影响了它回答某些问题的能力。</li><li>当前提供的 PaLM 2 具有有限的多语言能力。</li><li>当前提供的 PaLM 2 具有不令人满意的推理能力。</li></ol><h3 id="palm-2-受到更严格的监管" tabindex="-1">PaLM 2 受到更严格的监管 <a class="header-anchor" href="#palm-2-受到更严格的监管" aria-label="Permalink to &quot;PaLM 2 受到更严格的监管&quot;">​</a></h3><p>PaLM 2 似乎比其他型号受到更严格的监管。在许多用户对话中， 当用户提出 PaLM 2 不确定或不愿意回答的问题时，PaLM 2 比其他模型更有可能放弃回应。</p><p>根据粗略估计，在所有成对的战斗中，PaLM 2 因拒绝回答而输掉了 20.9% 的战斗， 而 30.8% 的战斗输给了不属于前四名之一的聊天机器人（GPT-4， Claude-v1、ChatGPT、Claude-instant-v1) 由于拒绝回答。</p><p>这部分解释了为什么 PaLM 2 经常输给排行榜上较弱的聊天机器人。 这也凸显了聊天机器人竞技场方法论中的一个缺陷，因为临时用户更有可能因微妙的不准确反应而惩罚弃权。 下面我们提供了几个失败案例，说明 PaLM 是如何因为拒绝回答问题而输给较弱的聊天机器人的。</p><p>我们还注意到，有时很难明确规定 LLM 监管的边界。在提供的 PaLM 2 版本中，我们看到了几个不受欢迎的趋势：</p><ul><li>PaLM 2 拒绝了许多角色扮演问题，即使用户要求它模拟 Linux 终端或编程语言解释器。</li><li>有时 PaLM 2 拒绝回答简单且无争议的事实问题。</li></ul><p>下面显示了几个示例：</p><p><img src="https://lmsys.org/images/blog/leaderboard_week4/PaLM2_refusal_1.png" alt="PaLM 2 拒绝回答的示例问题"><img src="https://lmsys.org/images/blog/leaderboard_week4/PaLM2_refusal_2.png" alt=""></p><h3 id="有限的多语言能力" tabindex="-1">有限的多语言能力 <a class="header-anchor" href="#有限的多语言能力" aria-label="Permalink to &quot;有限的多语言能力&quot;">​</a></h3><p>我们没有看到 PaLM 2 具有强大的多语言能力，目前在 <code>Google Vertex API</code> 提供的公共 <code>API chat-bison@001</code>。 PaLM 2 倾向于不回答非英语问题，包括用流行语言（如中文、西班牙语和希伯来语）编写的问题。 我们无法使用当前的 PaLM 2 版本重现 PaLM 2 技术报告中演示的几个多语言示例。我们正在等待谷歌逐步发布最新版本的 PaLM 2。</p><p>我们还分别计算了仅考虑英语和仅考虑非英语对话时所有模型的 Elo 评分，如图所示。 结果证实了观察结果——在非英语排行榜上，PaLM 2 排名第 16 位。</p><p><img src="https://lmsys.org/images/blog/leaderboard_week4/language_leaderboard.png" alt="仅英语和非英语排行榜"></p><h3 id="palm-2的推理能力不令人满意" tabindex="-1">PaLM 2的推理能力不令人满意 <a class="header-anchor" href="#palm-2的推理能力不令人满意" aria-label="Permalink to &quot;PaLM 2的推理能力不令人满意&quot;">​</a></h3><p>我们还观察到提供的 PaLM 2 版本没有表现出强大的推理能力。 一方面，它似乎会检测问题是否是纯文本，并且倾向于拒绝许多非纯文本的问题， 例如编程语言、调试和代码解释方面的问题。 另一方面，我们发现与其他聊天机器人相比，PaLM 2 在某些入门级推理任务上表现不佳。 请参见图中的几个示例。</p><p><img src="https://lmsys.org/images/blog/leaderboard_week4/PaLM2_reasoning_1.png" alt="PaLM 2 在简单推理任务上失败的示例"><img src="https://lmsys.org/images/blog/leaderboard_week4/PaLM2_reasoning_2.png" alt=""></p><h3 id="去除非英语和拒绝对话后的-elo-评分" tabindex="-1">去除非英语和拒绝对话后的 Elo 评分 <a class="header-anchor" href="#去除非英语和拒绝对话后的-elo-评分" aria-label="Permalink to &quot;去除非英语和拒绝对话后的 Elo 评分&quot;">​</a></h3><p>我们删除所有非英语对话和 PaLM 2 未提供答案的所有对话，并使用过滤后的数据计算每个模型的 Elo 评分。 该评级代表了竞技场中 PaLM 2 的 Elo 的假设上限。请参见下面的图。</p><p><img src="https://lmsys.org/images/blog/leaderboard_week4/english_non_refusal_leaderboard.png" alt="删除 PaLM 2 的非英语和拒绝对话后的排行榜"></p><h3 id="较小的模型具有竞争力" tabindex="-1">较小的模型具有竞争力 <a class="header-anchor" href="#较小的模型具有竞争力" aria-label="Permalink to &quot;较小的模型具有竞争力&quot;">​</a></h3><p>我们观察到几个较小的模型，包括 <code>vicuna-7B</code> 和 <code>mpt-7b-chat</code>，在排行榜上取得了很高的评价。 与具有双倍参数的较大模型相比，这些较小的模型表现出色。</p><p>我们推测高质量的预训练和微调数据集比模型大小更重要。 然而，更大的模型可能在更复杂的推理任务或回答更微妙的问题（例如，琐事）时表现更好。 因此，在预训练和微调阶段管理高质量数据集似乎是减少模型大小同时保持模型质量高的关键方法。</p><h3 id="claude-v1-和-claude-instant-v1" tabindex="-1">Claude-v1 和 Claude-instant-v1 <a class="header-anchor" href="#claude-v1-和-claude-instant-v1" aria-label="Permalink to &quot;Claude-v1 和 Claude-instant-v1&quot;">​</a></h3><p>Claude-instant-v1 是 Anthropic 提供的一种低成本、更快的 Claude-v1 替代品。 如果在竞技场中进行野外基准测试，我们会观察到 Claude-instant 接近 GPT-3.5-turbo（1153 对 1143）。 Claude 和 Claude-instant 之间的评级差距似乎小于 GPT-4 和 GPT-3.5-turbo 之间的评级差距。 Claude-instant 的上下文长度为 9K，以 0.00163/1K 提示令牌和 0.00551/1K 完成令牌的价格收费， 与其 OpenAI 对手产品 - GPT-3.5-turbo - 具有 4K 的上下文长度和统一0.002/1K 代币的价格（无论提示或完成）。</p><hr><div style="text-align:center;color:#00000099;font-size:14px;">END</div>',43)]))}const b=d(s,[["render",n]]);export{u as __pageData,b as default};
