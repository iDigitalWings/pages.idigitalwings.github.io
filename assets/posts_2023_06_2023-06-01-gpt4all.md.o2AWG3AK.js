import{_ as h}from"./chunks/ArticleMetadata.DFebsEEb.js";import{_ as e,m as k,a as r,u as o,B as d,aj as l,o as t,p as g,q as A}from"./chunks/framework.Ba_Ek9Jm.js";import"./chunks/theme.DmmjVCNk.js";const c="/assets/1480822352590708.CHyCzZPA.png",y="/assets/1475230659332750.8I2v7cmk.png",C="/assets/1475244253316125.CBuo8_YH.png",m="/assets/1475283390630833.BcoiNinA.png",F="/assets/1475326513859000.BRgOJgHL.png",D="/assets/1475524131686166.RsBQzPf8.png",_="/assets/1482167550056291.DJC65qaJ.png",B="/assets/1483968550278458.Bz5R7QYl.png",M=JSON.parse('{"title":"GPT4All","description":"","frontmatter":{"title":"GPT4All","date":"2023-06-17T00:00:00.000Z","tags":["ai","ml"],"category":["AI"]},"headers":[],"relativePath":"posts/2023/06/2023-06-01-gpt4all.md","filePath":"posts/2023/06/2023-06-01-gpt4all.md","lastUpdated":1718193786000}'),u={name:"posts/2023/06/2023-06-01-gpt4all.md"},P=l('<blockquote><p>最近发现 GPT4All 的生态越来越好了，很多平台和框架在支持 OpenAI ChatGPT 的同时， 也对 GPT4All 做了支持，今天就和大家介绍下 GPT4All 平台。</p></blockquote><p>GPT4All 是一个开源平台，提供了一种在计算机上运行大型语言模型 (LLM) 的免费方法。GPT4All 非常适合在安全的环境中试验不同的法学硕士。</p><p>GPT4All 为 CPU 和 GPU 接口提供 Python 绑定，因此用户可以通过 Python 脚本与模型进行交互。这使得可以轻松地将模型集成到各种应用程序中。</p><p>GPT4All 已完全授权用于商业用途。不过，GPT4All-J 模型允许商业用途，而基于 LLAMA 的 GPT4All 模型则需要非商业许可。</p><h2 id="什么是-gpt4all" tabindex="-1">什么是 GPT4All？ <a class="header-anchor" href="#什么是-gpt4all" aria-label="Permalink to &quot;什么是 GPT4All？&quot;">​</a></h2><p>“GPT”一词源自 Radford 等人 2018 年发表的论文《通过生成预训练提高语言理解》的标题。本文描述了如何证明 Transformer 模型能够理解人类语言。</p><p>从那时起，许多人尝试使用 Transformer 架构来开发语言模型，并且发现足够大的模型可以给出出色的结果。然而，许多开发的模型都是专有的。 它们要么作为付费订阅的服务提供，要么根据带有某些限制性条款的许可证提供。由于尺寸原因，有些甚至无法在商用硬件上运行。</p><p>GPT4All 项目试图<strong>让公众可以在通用硬件上获得LLM</strong>。它允许您训练和部署模型。预训练模型也可用，其尺寸较小，可以合理地在 CPU 上运行。</p><h2 id="" tabindex="-1"><a class="header-anchor" href="#" aria-label="Permalink to &quot;&quot;">​</a></h2><p>GPT4All 可从 <a href="https://gpt4all.io/index.html" target="_blank" rel="noreferrer">https://gpt4all.io/index.htmlopen in new window</a> 获取，您可以将其作为桌面应用程序运行或使用 Python 库运行。 您可以下载适合您操作系统的安装程序来运行桌面客户端。客户端只有几百MB。</p><p><img src="'+c+'" alt=""></p><p>您应该看到如下安装屏幕。</p><p><img src="'+y+'" alt=""></p><p><img src="'+C+'" alt=""></p><p>选择隐私数据 <img src="'+m+'" alt=""></p><p>安装客户端后，第一次启动会提示您安装一个模型，该模型可以大到GB。首先，您可以选择“ gpt4all-j-v1.3-groovy”（GPT4All-J 型号）。 这是一种相对较小但很受欢迎的型号。</p><p><img src="'+F+'" alt=""></p><p>我们选择 llama 2 chat 7b， <img src="'+D+'" alt=""></p><p>你也可以从网站上下载模型：</p><p>客户端和模型准备就绪后，您可以在输入框中键入消息。该模型可能期望特定形式的输入，例如特定的语言或风格。 该模型需要一种对话风格（如 ChatGPT）并且通常可以很好地处理英语。例如，下面是它如何响应输入“给我 10 种颜色及其 RGB 代码的列表”：</p><h1 id="颜色" tabindex="-1">颜色 <a class="header-anchor" href="#颜色" aria-label="Permalink to &quot;颜色&quot;">​</a></h1>',21),T=l('<p><img src="'+_+`" alt=""></p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">!</span><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">wget</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/resolve/main/llama-2-7b-chat.ggmlv3.q4_0.bin</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">!</span><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">  install</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> gpt4all</span></span></code></pre></div><p>自动下载：</p><p><img src="`+B+`" alt=""></p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> gpt4all </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> GPT4All</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> GPT4All(</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;llama-2-7b-chat.ggmlv3.q4_0.bin&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">output </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> model.generate(</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;The capital of France is &quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">max_tokens</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(output)</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">100</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">%|</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">██████████</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">|</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;"> 3.</span><span style="--shiki-light:#B31D28;--shiki-dark:#FF938A;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;">79G</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">/</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">3.</span><span style="--shiki-light:#B31D28;--shiki-dark:#FF938A;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;">79G</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">00</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">:</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">29</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">&lt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">00</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">:</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">00</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">, </span><span style="--shiki-light:#B31D28;--shiki-dark:#FF938A;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;">131MiB</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">/</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">s]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">Model downloaded at:  </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">/</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">root</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">/</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">.cache</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">/</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">gpt4all</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">/</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">llama</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">2</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">-</span><span style="--shiki-light:#B31D28;--shiki-dark:#FF938A;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;">7b</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">-</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">chat.ggmlv3.q4_0.bin</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> Paris, which</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> gpt4all </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> GPT4All</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> GPT4All(</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;llama-2-7b-chat.ggmlv3.q4_0.bin&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">output </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> model.generate(</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;中国的首都是 &quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">max_tokens</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(output)</span></span></code></pre></div><p><a href="https://gpt4all.io/index.html" target="_blank" rel="noreferrer">https://gpt4all.io/index.htmlopen in new window</a></p><hr><div style="text-align:center;color:#00000099;font-size:14px;">END</div>`,10);function b(s,E,f,v,G,q){const n=h,p=k("ClientOnly");return t(),r("div",null,[P,o(p,null,{default:d(()=>{var i,a;return[(((i=s.$frontmatter)==null?void 0:i.aside)??!0)&&(((a=s.$frontmatter)==null?void 0:a.showArticleMetadata)??!0)?(t(),g(n,{key:0,article:s.$frontmatter},null,8,["article"])):A("",!0)]}),_:1}),T])}const N=e(u,[["render",b]]);export{M as __pageData,N as default};
