import{_ as t,a as r,af as a,o as l}from"./chunks/framework.C87LdZyP.js";const o="/assets/26715557286666.BSz3L7Le.png",n="/assets/27400610268708.vclmHmPx.png",i="/assets/26910464709166.jg-T6SXP.png",s="/assets/27024290358250.CsVC_xT6.png",p="/assets/28401940744916.CCb6YJvM.png",h="/assets/58524732076833.Cms953kr.png",g="/assets/59046965984500.BSVfyOlL.png",c="/assets/58891618057541.D9C9i4W_.png",m="/assets/58961008213791.Am3lR1hC.png",L="/assets/59029427344083.TUr-y48G.png",u="/assets/59411611195375.CvQKtmyv.png",f="/assets/59612058777708.DfvKsIFE.png",d="/assets/59941482768500.DhAjrOqV.png",b="/assets/60151792719875.CTXotCp6.png",_="/assets/60239037554208.CEte-ooQ.png",M="/assets/60430973987541.zCMjFT2l.png",w="/assets/60612501820833.D6DyIzNw.png",k="/assets/60760388847458.ChXzo3-q.png",y="/assets/60880548801208.DEEbVKrX.png",I="/assets/61012830762416._lYilEd4.png",P="/assets/61003209310458.Bar-Z9PK.png",A="/assets/61155597011500.C7DjFXOE.png",x="/assets/61317024913166.CVvdoqXk.png",z=JSON.parse('{"title":"14 种 LLM 大模型追踪和监控工具","description":"","frontmatter":{"title":"14 种 LLM 大模型追踪和监控工具","date":"2024-08-08 10:00:00","tags":["llm"],"category":["Python"]},"headers":[],"relativePath":"posts/2024/08/2024-08-08-llm-monitors.md","filePath":"posts/2024/08/2024-08-08-llm-monitors.md","lastUpdated":1726313048000}'),v={name:"posts/2024/08/2024-08-08-llm-monitors.md"};function O(q,e,T,D,C,E){return l(),r("div",null,e[0]||(e[0]=[a('<p>介绍一些大模型程序的监控工具，下面工具一般都有开源版本，也都有托管服务，我们可以根据需要来选择。</p><h2 id="phoenix" tabindex="-1">Phoenix <a class="header-anchor" href="#phoenix" aria-label="Permalink to &quot;Phoenix&quot;">​</a></h2><p>Phoenix 是一个开源可观察性库，专为实验、评估和故障排除而设计。 它允许 AI 工程师和数据科学家快速可视化他们的数据、评估性能、追踪问题并导出数据以进行改进。 Phoenix 由业界领先的 AI 可观察性平台背后的公司Arize AI和一组核心贡献者构建。</p><ul><li>源码： <a href="https://github.com/Arize-ai/phoenix" target="_blank" rel="noreferrer">https://github.com/Arize-ai/phoenix</a></li><li>文档： <a href="https://docs.arize.com/phoenix" target="_blank" rel="noreferrer">https://docs.arize.com/phoenix</a></li></ul><p><img src="'+o+'" alt=""></p><p>核心功能：</p><ul><li><strong>追踪</strong>： 可用于了解 LLM 应用程序的行为。无论您使用哪种框架，Phoenix 都具有一流的跟踪功能，并且为各种框架（LlamaIndex、LangChain、DSPy）、SDK（OpenAI、Bedrock、Mistral、Vertex）和语言（Python、Javascript）提供一流的检测。您还可以使用 OpenTelemetry SDK手动检测您的应用程序</li><li><strong>评估</strong>： 通过 Phoenix 评估你的 LLM。</li><li><strong>推理</strong>： Phoenix Inferences 允许您在一个交互式 UMAP 视图中可视化所有模型的推理，从而观察模型的性能。这种强大的可视化功能可以在 EDA 期间利用来了解模型漂移、查找性能低下的集群、发现检索问题以及导出数据进行再训练/微调。</li><li><strong>数据集和实验</strong>： Phoenix 可帮助您对 AI 和 LLM 应用程序进行实验，以评估并不断改进其性能。</li></ul><p><img src="'+n+'" alt=""></p><h2 id="literal-ai" tabindex="-1">Literal AI <a class="header-anchor" href="#literal-ai" aria-label="Permalink to &quot;Literal AI&quot;">​</a></h2><p>Literal AI是首选的 LLM 评估和可观察性解决方案，使工程和产品团队能够可靠、快速且大规模地交付 LLM 应用程序。 这可以通过涉及快速工程、LLM 可观察性、LLM 评估和 LLM 监控的协作开发周期来实现。对话线程和代理运行可以自动记录在 Literal AI 上。</p><ul><li>主页： <a href="https://literalai.com/" target="_blank" rel="noreferrer">https://literalai.com/</a></li><li>源码： <a href="https://github.com/Chainlit/chainlit" target="_blank" rel="noreferrer">https://github.com/Chainlit/chainlit</a></li><li>文档： <a href="https://docs.getliteral.ai/get-started/overview" target="_blank" rel="noreferrer">https://docs.getliteral.ai/get-started/overview</a></li></ul><p><img src="'+i+'" alt=""></p><p>核心功能：</p><ul><li><strong>可观察性</strong>： 使用我们的 SDK 在几分钟内监控您的多模式 LLM 应用程序（包括步骤、反馈、提示、令牌消耗）。Literal 在一个位置提供所有数据的统一视图。</li><li><strong>评估</strong>： 使用现成的和自定义的评估器实时评估您的线程和运行。创建混合生产数据和手写示例的数据集以运行非回归测试。</li><li><strong>Prompt</strong>： 直接从 Literal AI 安全地设计、试用、调试、版本控制和部署提示。</li><li><strong>监控</strong>： 监控 LLM 系统在生产中的性能。在仪表板中查看 LLM 指标、设置自动规则并收集产品和用户分析数据。</li></ul><p><img src="'+s+'" alt=""></p><h2 id="langfuse" tabindex="-1">Langfuse <a class="header-anchor" href="#langfuse" aria-label="Permalink to &quot;Langfuse&quot;">​</a></h2><p>Langfuse 是一个开源 LLM 工程平台，可帮助团队协作调试、分析和迭代其 LLM 应用程序。借助 Langfuse 集成，您可以无缝跟踪和监控 LlamaIndex 应用程序的性能、跟踪和指标。LlamaIndex 上下文增强和 LLM 查询过程的详细跟踪会被捕获，并可直接在 Langfuse UI 中检查。</p><ul><li>源码： <a href="https://github.com/langfuse/langfuse" target="_blank" rel="noreferrer">https://github.com/langfuse/langfuse</a></li><li>文档： <a href="https://langfuse.com/docs" target="_blank" rel="noreferrer">https://langfuse.com/docs</a></li></ul><p><img src="'+p+'" alt=""></p><p>核心功能：</p><ul><li><strong>可观察性</strong>：跟踪应用程序中的所有 LLM 调用和所有其他相关逻辑</li><li><strong>Langfuse UI</strong>：检查和调试复杂日志和用户会话（演示、跟踪、会话）</li><li><strong>Prompt管理</strong>：在 Langfuse 内部管理、版本控制和部署提示（提示管理）</li><li><strong>Prompt工程</strong>：使用LLM Playground测试和迭代您的提示</li><li><strong>分析</strong>：跟踪指标（LLM 成本、延迟、质量）并从仪表板和数据导出中获取见解</li><li><strong>评估</strong>：收集并计算您的大语言模型(LLM) 成绩</li></ul><h2 id="deepeval" tabindex="-1">DeepEval <a class="header-anchor" href="#deepeval" aria-label="Permalink to &quot;DeepEval&quot;">​</a></h2><p>DeepEval（由 Confident AI 开发）是 LLM 应用程序的开源评估框架。 当您使用 DeepEval 目前提供的 14 多个默认指标 （总结、幻觉、答案相关性、忠实度、RAGAS 等）对您的 LLM 应用程序进行“单元测试”时， 您可以通过与 LlamaIndex 的跟踪集成来调试失败的测试用例， 或者通过 DeepEval 的托管评估平台Confident AI来调试生产中不令人满意的评估， 该平台在生产中运行无参考评估。</p><ul><li>主页： <a href="https://docs.confident-ai.com/" target="_blank" rel="noreferrer">https://docs.confident-ai.com/</a></li><li>源码： <a href="https://github.com/confident-ai/deepeval" target="_blank" rel="noreferrer">https://github.com/confident-ai/deepeval</a></li><li>文档： <a href="https://docs.confident-ai.com/docs/getting-started" target="_blank" rel="noreferrer">https://docs.confident-ai.com/docs/getting-started</a></li></ul><p><img src="'+h+'" alt=""></p><p>核心功能：</p><ul><li>各种各样可立即使用的 LLM 评估指标（均附有解释），由您选择的任何LLM、统计方法或在您的机器上本地运行的 NLP 模型提供支持。</li><li>使用不到 20 行 Python 代码并行批量评估整个数据集。通过 CLI 以类似 Pytest 的方式执行此操作，或通过我们的evaluate() 函数执行此操作。</li><li>通过继承 DeepEval 的基指标类，创建自己的自定义指标，并自动与 DeepEval 的生态系统集成。</li><li>与任何CI/CD 环境无缝集成。</li><li>只需不到 10 行代码即可轻松在流行的 LLM 基准上对任何LLM 进行基准测试。</li></ul><h2 id="wandb" tabindex="-1">wandb <a class="header-anchor" href="#wandb" aria-label="Permalink to &quot;wandb&quot;">​</a></h2><p>Wandb Weave 是一款用于跟踪和评估 LLM 应用程序的轻量级工具包。使用 W&amp;B Weave 可以可视化和检查 LLM 的执行流程， 分析 LLM 的输入和输出，查看中间结果并安全地存储和管理提示和 LLM 链配置。</p><ul><li>主页： <a href="https://wandb.ai/" target="_blank" rel="noreferrer">https://wandb.ai/</a></li><li>源码： <a href="https://github.com/wandb/wandb" target="_blank" rel="noreferrer">https://github.com/wandb/wandb</a></li><li>文档： <a href="https://docs.wandb.ai/guides/weave" target="_blank" rel="noreferrer">https://docs.wandb.ai/guides/weave</a></li></ul><p><img src="'+g+'" alt=""></p><p>核心功能：</p><ul><li>记录和调试语言模型的输入、输出和跟踪</li><li>为语言模型用例构建严格的同类评估</li><li>整理 LLM 工作流程中生成的所有信息，从实验到评估再到生产</li></ul><p><img src="'+c+'" alt=""></p><p>Weights &amp; Biases (W&amp;B) 是 AI 开发平台，具有用于训练模型、微调模型和利用基础模型的工具。</p><p><img src="'+m+'" alt=""></p><p>我们也可以快速注册，使用起来托管服务。</p><p><img src="'+L+'" alt=""></p><h2 id="openllmetry" tabindex="-1">OpenLLMetry <a class="header-anchor" href="#openllmetry" aria-label="Permalink to &quot;OpenLLMetry&quot;">​</a></h2><p>OpenLLMetry 是一组基于OpenTelemetry构建的扩展，可让您完全观察 LLM 应用程序。 由于它在底层使用 OpenTelemetry， 因此可以连接到您现有的可观察性解决方案 - Datadog、Honeycomb 等。</p><ul><li>主页： <a href="https://www.traceloop.com/openllmetry" target="_blank" rel="noreferrer">https://www.traceloop.com/openllmetry</a></li><li>源码： <a href="https://github.com/traceloop/openllmetry" target="_blank" rel="noreferrer">https://github.com/traceloop/openllmetry</a></li><li>文档： <a href="https://www.traceloop.com/docs/openllmetry/introduction" target="_blank" rel="noreferrer">https://www.traceloop.com/docs/openllmetry/introduction</a></li></ul><p><img src="'+u+'" alt=""></p><p>OpenLLMetry 跟踪以非侵入式方式完成，建立在 OpenTelemetry 之上。您可以选择将跟踪导出到 <strong>Traceloop</strong> 或现有的可观察性堆栈。</p><p><img src="'+f+'" alt=""></p><h2 id="openinference" tabindex="-1">OpenInference <a class="header-anchor" href="#openinference" aria-label="Permalink to &quot;OpenInference&quot;">​</a></h2><p>OpenInference是用于捕获和存储 AI 模型推理的开放标准。它支持使用 LLM 可观测性解决方案（例如Phoenix）对 LLM 应用程序进行实验、可视化和评估。</p><ul><li>源码： <a href="https://github.com/Arize-ai/openinference" target="_blank" rel="noreferrer">https://github.com/Arize-ai/openinference</a></li><li>规范： <a href="https://github.com/Arize-ai/open-inference-spec?tab=readme-ov-file" target="_blank" rel="noreferrer">https://github.com/Arize-ai/open-inference-spec?tab=readme-ov-file</a></li></ul><p><img src="'+d+'" alt=""></p><p>其托管服务是 <a href="https://arize.com/" target="_blank" rel="noreferrer">https://arize.com/</a> 。</p><h2 id="truera-trulens" tabindex="-1">TruEra TruLens <a class="header-anchor" href="#truera-trulens" aria-label="Permalink to &quot;TruEra TruLens&quot;">​</a></h2><p>TruLens 允许用户通过反馈功能和跟踪等功能来检测/评估 LLM 应用程序。</p><ul><li>主页： <a href="https://www.trulens.org/" target="_blank" rel="noreferrer">https://www.trulens.org/</a></li><li>源码： <a href="https://github.com/truera/trulens/" target="_blank" rel="noreferrer">https://github.com/truera/trulens/</a></li></ul><p><img src="'+b+'" alt=""></p><h2 id="honeyhive" tabindex="-1">HoneyHive <a class="header-anchor" href="#honeyhive" aria-label="Permalink to &quot;HoneyHive&quot;">​</a></h2><p>HoneyHive 允许用户跟踪任何 LLM 工作流的执行流程。然后，用户可以调试和分析其跟踪，或自定义特定跟踪事件的反馈，以从生产中创建评估或微调数据集。</p><ul><li>主页： <a href="https://www.honeyhive.ai/" target="_blank" rel="noreferrer">https://www.honeyhive.ai/</a></li></ul><p><img src="'+_+'" alt=""></p><h2 id="promptlayer" tabindex="-1">PromptLayer <a class="header-anchor" href="#promptlayer" aria-label="Permalink to &quot;PromptLayer&quot;">​</a></h2><p>PromptLayer 允许您跟踪 LLM 调用中的分析，标记、分析和评估各种用例的提示。</p><ul><li>主页： <a href="https://promptlayer.com/" target="_blank" rel="noreferrer">https://promptlayer.com/</a></li><li>文档： <a href="https://docs.promptlayer.com/introduction" target="_blank" rel="noreferrer">https://docs.promptlayer.com/introduction</a></li></ul><p><img src="'+M+'" alt=""></p><p>核心功能：</p><ul><li><strong>监视使用情况</strong> 记录您的 LLM 请求。了解用户如何与您的生产应用程序进行交互。监控 API 使用情况、成本和延迟。</li><li><strong>版本控制和提示</strong> 使用我们的仪表板直观地组织、迭代和部署提示版本。更新提示不需要工程帮助。</li><li><strong>评估结果</strong> 以系统且高效的方式创建新的提示。在人工和人工智能评分员的帮助下测试提示。</li><li><strong>轨迹分析</strong> 了解您的 LLM 申请的使用方式、使用者以及使用频率。无需在 Mixpanel 之间来回切换。</li></ul><h2 id="langtrace" tabindex="-1">Langtrace <a class="header-anchor" href="#langtrace" aria-label="Permalink to &quot;Langtrace&quot;">​</a></h2><p>Langtrace 是一个开源的、基于开放遥测的端到端可观察性工具，适用于 LLM 应用程序， 为流行的 LLM、LLM 框架、vectorDB 等提供实时跟踪、评估和指标。使用 Typescript、Python 集成。</p><ul><li>主页： <a href="https://langtrace.ai/" target="_blank" rel="noreferrer">https://langtrace.ai/</a></li><li>源码： <a href="https://github.com/Scale3-Labs/langtrace" target="_blank" rel="noreferrer">https://github.com/Scale3-Labs/langtrace</a></li></ul><p><img src="'+w+'" alt=""></p><h2 id="agentops" tabindex="-1">AgentOps <a class="header-anchor" href="#agentops" aria-label="Permalink to &quot;AgentOps&quot;">​</a></h2><p>AgentOps 帮助开发人员构建、评估和监控 AI 代理。从原型到生产。</p><ul><li>主页： <a href="https://www.agentops.ai/" target="_blank" rel="noreferrer">https://www.agentops.ai/</a></li><li>源码： <a href="https://github.com/AgentOps-AI/agentops" target="_blank" rel="noreferrer">https://github.com/AgentOps-AI/agentops</a></li></ul><p><img src="'+k+'" alt=""></p><p>核心功能：</p><ul><li><strong>重放分析和调试</strong> 代理逐步执行图</li><li><strong>LLM 成本管理</strong> 跟踪 LLM 基础模型提供商的支出</li><li><strong>代理基准测试</strong> 根据 1,000 多个评估测试您的代理</li><li><strong>合规性和安全性</strong> 检测常见的即时注入和数据泄露漏洞</li><li><strong>框架集成</strong> 与 CrewAI、AutoGen 和 LangChain 的原生集成</li></ul><p><img src="'+y+'" alt=""></p><h2 id="openlit" tabindex="-1">OpenLIT <a class="header-anchor" href="#openlit" aria-label="Permalink to &quot;OpenLIT&quot;">​</a></h2><p>OpenLIT是一款 OpenTelemetry 原生 GenAI 和 LLM 应用程序可观察性工具。 它旨在仅用一行代码即可将可观察性集成到 GenAI 项目中。 OpenLIT 为各种 LLM、VectorDB 和框架（如 LlamaIndex）提供 OpenTelemetry Auto 检测。 OpenLIT 提供有关您的 LLM 应用程序性能的洞察、请求跟踪、使用情况指标（如成本、令牌等）等。</p><ul><li>源码： <a href="https://github.com/openlit/openlit" target="_blank" rel="noreferrer">https://github.com/openlit/openlit</a></li><li>文档： <a href="https://docs.openlit.io/latest/introduction" target="_blank" rel="noreferrer">https://docs.openlit.io/latest/introduction</a></li></ul><p><img src="'+I+'" alt=""></p><p>核心功能：</p><ul><li><strong>LLM 和 VectorDB 性能的高级监控</strong>：OpenLIT 提供自动检测功能，可生成跟踪和指标，让您深入了解 LLM 和 VectorDB 使用的性能和成本。这可以帮助您分析应用程序在不同环境（例如生产环境）中的表现，从而使您能够优化资源使用情况并有效扩展。</li><li><strong>自定义和微调模型的成本跟踪</strong>：OpenLIT 允许您使用自定义 JSON 文件定制特定模型的成本跟踪。此功能允许精确预算并确保成本估算与您的项目需求完全一致。</li><li><strong>OpenTelemetry 原生且与供应商无关的 SDK</strong>：OpenLIT 内置对 OpenTelemetry 的原生支持，使其与您的项目无缝融合。这种与供应商无关的方法减少了集成障碍，使 OpenLIT 成为软件堆栈中直观的一部分，而不是额外的复杂性。</li></ul><p><img src="'+P+'" alt=""></p><h2 id="mlflow" tabindex="-1">MLflow <a class="header-anchor" href="#mlflow" aria-label="Permalink to &quot;MLflow&quot;">​</a></h2><p>MLflow是一个开源平台， 旨在帮助机器学习从业者和团队处理机器学习过程的复杂性。MLflow 专注于机器学习项目的整个生命周期， 确保每个阶段都是可管理、可跟踪和可重现的。</p><ul><li>主页： <a href="https://mlflow.org/" target="_blank" rel="noreferrer">https://mlflow.org/</a></li><li>源码： <a href="https://github.com/mlflow/mlflow" target="_blank" rel="noreferrer">https://github.com/mlflow/mlflow</a></li><li>文档： <a href="https://mlflow.org/docs/latest/index.html" target="_blank" rel="noreferrer">https://mlflow.org/docs/latest/index.html</a></li></ul><p><img src="'+A+'" alt=""></p><p>MLflow 主要组件：</p><ul><li><strong>MLflow Tracking</strong>：一种用于记录机器学习实验中的参数、代码和结果并使用交互式 UI 进行比较的 API。</li><li><strong>MLflow Projects</strong>：一种使用 Conda 和 Docker 进行可重现运行的代码打包格式，因此您可以与他人共享您的 ML 代码。</li><li><strong>MLflow Models</strong>：一种模型打包格式和工具，可让您轻松部署相同的模型（来自任何 ML 库）以在 Docker、Apache Spark、Azure ML 和 AWS SageMaker 等平台上进行批量和实时评分。</li><li><strong>MLflow Model Registry</strong>：一个集中式模型存储、一组 API 和 UI，用于协作管理 MLflow 模型的完整生命周期。</li></ul><p><img src="'+x+'" alt=""></p>',88)]))}const B=t(v,[["render",O]]);export{z as __pageData,B as default};
