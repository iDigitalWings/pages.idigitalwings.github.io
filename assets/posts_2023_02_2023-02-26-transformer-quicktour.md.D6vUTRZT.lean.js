import{_ as i,a,af as t,o as n}from"./chunks/framework.C87LdZyP.js";const g=JSON.parse('{"title":"Transformer 快速开始","description":"","frontmatter":{"title":"Transformer 快速开始","date":"2023-02-26T00:00:00.000Z","tags":["ai","ml","gpt","transformer"],"category":["AI"],"sidebar":"transformer"},"headers":[],"relativePath":"posts/2023/02/2023-02-26-transformer-quicktour.md","filePath":"posts/2023/02/2023-02-26-transformer-quicktour.md","lastUpdated":1718173059000}'),e={name:"posts/2023/02/2023-02-26-transformer-quicktour.md"};function h(l,s,p,k,d,r){return n(),a("div",null,s[0]||(s[0]=[t(`<p>使用 Notebook 安装：</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">!</span><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> install</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> transformers</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> datasets</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">安装</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> torch</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">!</span><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> install</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> torch</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#768390;"># 或者</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">!</span><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> install</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> tensorflow</span></span></code></pre></div><h2 id="pipeline" tabindex="-1">Pipeline <a class="header-anchor" href="#pipeline" aria-label="Permalink to &quot;Pipeline&quot;">​</a></h2><p><code>pipeline()</code> 是使用预训练模型进行推理的最简单、最快的方法。 您可以将开箱即用的 <code>pipeline()</code> 用于跨不同模式的许多任务，其中一些任务如下表所示：</p><table tabindex="0"><thead><tr><th>任务</th><th>Task</th><th>描述</th><th>形态</th><th>Modality</th><th>Pipeline identifier</th></tr></thead><tbody><tr><td>文本分类</td><td>Text classification</td><td>为给定的文本序列分配标签</td><td>自然语言处理</td><td>NLP</td><td>pipeline(task=“sentiment-analysis”)</td></tr><tr><td>文本生成</td><td>Text generation</td><td>在出现提示的情况下生成文本</td><td>自然语言处理</td><td>NLP</td><td>pipeline(task=“text-generation”)</td></tr><tr><td>综述</td><td>Summarization</td><td>生成文本或文档序列的摘要</td><td>自然语言处理</td><td>NLP</td><td>pipeline(task=“summarization”)</td></tr><tr><td>图像分类</td><td>Image classification</td><td>为图像分配标签</td><td>计算机视觉</td><td>Computer vision</td><td>pipeline(task=“image-classification”)</td></tr><tr><td>图像分割</td><td>Image segmentation</td><td>为图像的每个像素分配标签（支持语义、全景和实例分割）</td><td>计算机视觉</td><td>Computer vision</td><td>pipeline(task=“image-segmentation”)</td></tr><tr><td>物体检测</td><td>Object detection</td><td>预测图像中对象的边界框和类别</td><td>计算机视觉</td><td>Computer vision</td><td>pipeline(task=“object-detection”)</td></tr><tr><td>音频分类</td><td>Audio classification</td><td>为某些音频数据分配标签</td><td>音频</td><td>Audio</td><td>pipeline(task=“audio-classification”)</td></tr><tr><td>自动语音识别</td><td>Automatic speech recognition</td><td>将语音转录为文本</td><td>音频</td><td>Audio</td><td>pipeline(task=“automatic-speech-recognition”)</td></tr><tr><td>视觉问答</td><td>Visual question answering</td><td>回答有关图像的问题，给定图像和问题</td><td>模 态</td><td>Multimodal</td><td>pipeline(task=“vqa”)</td></tr><tr><td>文档问答</td><td>Document question answering</td><td>在给定图像和问题的情况下回答有关文档的问题</td><td>模 态</td><td>Multimodal</td><td>pipeline(task=“document-question-answering”)</td></tr><tr><td>图片说明</td><td>Image captioning</td><td>为给定图像生成标题</td><td>模 态</td><td>Multimodal</td><td>pipeline(task=“image-to-text”)</td></tr></tbody></table><p>首先创建一个 <code>pipeline()</code> 的实例并指定要使用它的任务。在本指南中，您将使用 <code>pipeline()</code> 进行情绪分析作为示例：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> transformers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> pipeline</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">classifier </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> pipeline(</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;sentiment-analysis&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span></code></pre></div><p>输出</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">No</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> model</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> was</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> supplied,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> defaulted</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> to</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> distilbert-base-uncased-finetuned-sst-2-english</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> and</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> revision</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> af0f99b</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">Using</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> a</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> pipeline</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> without</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> specifying</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> a</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> model</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> name</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> and</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> revision</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> in</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> production</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> is</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> not</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> recommended.</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">Downloading</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> (…)lve/main/config.json: 100%</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">629/629</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [00:00&lt;00:00, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">26.3kB/s]</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">Downloading</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> pytorch_model.bin:</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 100%</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">268M/268M</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [00:01&lt;00:00, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">250MB/s]</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">Downloading</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> (…)okenizer_config.json: 100%</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">48.0/48.0</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [00:00&lt;00:00, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">1.81kB/s]</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">Downloading</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> (…)solve/main/vocab.txt: 100%</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">232k/232k</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [00:00&lt;00:00, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">6.74MB/s]</span></span></code></pre></div><p><code>pipeline()</code> 下载并缓存默认的预训练模型和分词器，用于情绪分析。现在，您可以在目标文本上使用：classifier</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">classifier(</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;We are very happy to show you the 🤗 Transformers library.&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span></code></pre></div><p>输出</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">[{</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&#39;label&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&#39;POSITIVE&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&#39;score&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">0.9997795224189758</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">}]</span></span></code></pre></div><p>如果您有多个输入，请将输入作为列表传递给 <code>pipeline()</code> 以返回字典列表：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">results </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> classifier([</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;We are very happy to show you the 🤗 Transformers library.&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;We hope you don&#39;t hate it.&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">])</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> result </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> results:</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;label: </span><span style="--shiki-light:#005CC5;--shiki-dark:#F47067;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">result[</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&#39;label&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">]</span><span style="--shiki-light:#005CC5;--shiki-dark:#F47067;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">, with score: </span><span style="--shiki-light:#005CC5;--shiki-dark:#F47067;">{</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">round</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(result[</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&#39;score&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">], </span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span><span style="--shiki-light:#005CC5;--shiki-dark:#F47067;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span></code></pre></div><p>输出</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">label:</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> POSITIVE,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> with</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> score:</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;"> 0.9998</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">label:</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> NEGATIVE,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> with</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> score:</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;"> 0.5309</span></span></code></pre></div><p><code>pipeline()</code> 还可以为任何你喜欢的任务迭代整个数据集。对于此示例，让我们选择自动语音识别作为我们的任务：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> torch</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> transformers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> pipeline</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">speech_recognizer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> pipeline(</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;automatic-speech-recognition&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;facebook/wav2vec2-base-960h&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span></code></pre></div><p>输出</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">Downloading</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> (…)lve/main/config.json: 100%</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">1.60k/1.60k</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [00:00&lt;00:00, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">41.2kB/s]</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">Downloading</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> pytorch_model.bin:</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 100%</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">378M/378M</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [00:04&lt;00:00, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">85.0MB/s]</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">Some</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> weights</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> of</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> Wav2Vec2ForCTC</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> were</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> not</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> initialized</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> from</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> the</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> model</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> checkpoint</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> at</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> facebook/wav2vec2-base-960h</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> and</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> are</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> newly</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> initialized:</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&#39;wav2vec2.masked_spec_embed&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">]</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">You</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> should</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> probably</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> TRAIN</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> this</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> model</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> on</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> a</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> down-stream</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> task</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> to</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> be</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> able</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> to</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> use</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> it</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> for</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> predictions</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> and</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> inference.</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">Downloading</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> (…)okenizer_config.json: 100%</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">163/163</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [00:00&lt;00:00, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">5.82kB/s]</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">Downloading</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> (…)olve/main/vocab.json: 100%</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">291/291</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [00:00&lt;00:00, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">5.48kB/s]</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">Downloading</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> (…)cial_tokens_map.json: 100%</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">85.0/85.0</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [00:00&lt;00:00, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">4.18kB/s]</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">Downloading</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> (…)rocessor_config.json: 100%</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">159/159</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [00:00&lt;00:00, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">4.96kB/s]</span></span></code></pre></div><p>加载要迭代的音频数据集（有关更多详细信息，请参阅🤗数据集快速入门）。例如，加载 MInDS-14 数据集：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> datasets </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> load_dataset, Audio</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">dataset </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> load_dataset(</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;PolyAI/minds14&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">name</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;en-US&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">split</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;train&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span></code></pre></div><p>输出</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">Downloading</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> builder</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> script:</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 100%</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">5.95k/5.95k</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [00:00&lt;00:00, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">142kB/s]</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">Downloading</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> readme:</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 100%</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">5.29k/5.29k</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [00:00&lt;00:00, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">136kB/s]</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">Downloading</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> and</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> preparing</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> dataset</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> minds14/en-US</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> to</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> /root/.cache/huggingface/datasets/PolyAI___minds14/en-US/1.0.0/65c7e0f3be79e18a6ffaf879a083daf706312d421ac90d25718459cbf3c42696</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">Downloading</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> data:</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 100%</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">471M/471M</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [00:20&lt;00:00, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">24.1MB/s]</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">Dataset</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> minds14</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> downloaded</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> and</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> prepared</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> to</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> /root/.cache/huggingface/datasets/PolyAI___minds14/en-US/1.0.0/65c7e0f3be79e18a6ffaf879a083daf706312d421ac90d25718459cbf3c42696.</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> Subsequent</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> calls</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> will</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> reuse</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> this</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> data.</span></span></code></pre></div><p>您需要确保数据集的采样率与采样匹配 Rate Facebook/WAV2Vec2-base-960H接受过以下方面的培训：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">dataset </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> dataset.cast_column(</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;audio&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">, Audio(</span><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">sampling_rate</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">speech_recognizer.feature_extractor.sampling_rate))</span></span></code></pre></div><p>调用列时，会自动加载和重新采样音频文件。 从前 4 个样本中提取原始波形数组，并将其作为列表传递给管道：&quot;audio&quot;</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">result </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> speech_recognizer(dataset[:</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">][</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;audio&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">])</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">([d[</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;text&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> d </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> result])</span></span></code></pre></div><p>输出</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">[</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&#39;I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;FONDERING HOW I&#39;D SET UP A JOIN TO HELL T WITH MY WIFE AND WHERE THE AP MIGHT BE&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;I I&#39;D LIKE TOY SET UP A JOINT ACCOUNT WITH MY PARTNER I&#39;M NOT SEEING THE OPTION TO DO IT ON THE APSO I CALLED IN TO GET SOME HELP CAN I JUST DO IT OVER THE PHONE WITH YOU AND GIVE YOU THE INFORMATION OR SHOULD I DO IT IN THE AP AN I&#39;M MISSING SOMETHING UQUETTE HAD PREFERRED TO JUST DO IT OVER THE PHONE OF POSSIBLE THINGS&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&#39;HOW DO I FURN A JOINA COUT&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">]</span></span></code></pre></div><p>对于输入较大的大型数据集（如语音或视觉），您需要传递生成器而不是列表以加载内存中的所有输入。有关详细信息，请查看管道 API 参考。</p><h3 id="在管道中使用其他模型和分词器" tabindex="-1">在管道中使用其他模型和分词器 <a class="header-anchor" href="#在管道中使用其他模型和分词器" aria-label="Permalink to &quot;在管道中使用其他模型和分词器&quot;">​</a></h3><p><code>pipeline()</code> 可以容纳来自 Hub 的任何模型，从而可以轻松地使 <code>pipeline()</code> 适应其他用例。 例如，如果您想要一个能够处理法语文本的模型，请使用 Hub 上的标签筛选出合适的模型。 顶部筛选的结果返回一个多语言 BERT 模型，该模型针对可用于法语文本的情绪分析进行了微调：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">model_name </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span></span></code></pre></div><div class="tip custom-block"><p class="custom-block-title">pytorch</p><p>使用 <code>AutoModelForSequenceClassification</code> 和 <code>AutoTokenizer</code> 加载预训练模型及其关联的分词器（下一节将详细介绍 <code>AutoClass</code>）：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> transformers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> AutoTokenizer, AutoModelForSequenceClassification</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> AutoModelForSequenceClassification.from_pretrained(model_name)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">tokenizer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> AutoTokenizer.from_pretrained(model_name)</span></span></code></pre></div><p>输出</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">Downloading</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> (…)lve/main/config.json: 100%</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">953/953</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [00:00&lt;00:00, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">15.0kB/s]</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">Downloading</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> pytorch_model.bin:</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 100%</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">669M/669M</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [00:08&lt;00:00, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">90.9MB/s]</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">Downloading</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> (…)okenizer_config.json: 100%</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">39.0/39.0</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [00:00&lt;00:00, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">1.71kB/s]</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">Downloading</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> (…)solve/main/vocab.txt: 100%</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">872k/872k</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [00:00&lt;00:00, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">1.25MB/s]</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">Downloading</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> (…)cial_tokens_map.json: 100%</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">112/112</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [00:00&lt;00:00, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">4.04kB/s]</span></span></code></pre></div></div><div class="tip custom-block"><p class="custom-block-title">tensorflow</p><p>使用 <code>TFAutoModelForSequenceClassification</code> 和 <code>AutoTokenizer</code> 加载预训练模型及其关联的分词器（下一节将详细介绍 <code>TFAutoClass</code>）：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> transformers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> AutoTokenizer, TFAutoModelForSequenceClassification</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> TFAutoModelForSequenceClassification.from_pretrained(model_name)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">tokenizer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> AutoTokenizer.from_pretrained(model_name)</span></span></code></pre></div></div><p>在 <code>pipeline()</code> 中指定模型和分词器，现在您可以应用 classifier 在法语文本上：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">classifier </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> pipeline(</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;sentiment-analysis&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">model, </span><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">tokenizer</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">tokenizer)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">classifier(</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;Nous sommes très heureux de vous présenter la bibliothèque 🤗 Transformers.&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span></code></pre></div><p>输出</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">[{</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&#39;label&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&#39;5 stars&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&#39;score&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">0.7272651791572571</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">}]</span></span></code></pre></div><p>如果找不到用例的模型，则需要对数据进行微调预训练模型。查看我们的 <a href="https://huggingface.co/docs/transformers/training" target="_blank" rel="noreferrer">微调教程</a>以了解如何操作。 最后，在微调预训练模型后，请考虑在 Hub 上与社区共享模型，以使每个人的机器学习民主化！🤗</p><h2 id="autoclass" tabindex="-1">AutoClass <a class="header-anchor" href="#autoclass" aria-label="Permalink to &quot;AutoClass&quot;">​</a></h2><p>在后台，<code>AutoModelForSequenceClassification</code> 和 <code>AutoTokenizer</code> 类协同工作， 为您上面使用的 <code>pipeline()</code> 提供支持。 <code>AutoClass</code> 是一种快捷方式，可自动从预训练模型的名称或路径中检索其体系结构。 您只需要为您的任务选择合适的 AutoClass 及其关联的预处理类。</p><p>让我们回到上一节中的示例，看看如何使用 AutoClass 来复制 <code>pipeline()</code> 的结果。</p><h3 id="autotokenizer" tabindex="-1">AutoTokenizer <a class="header-anchor" href="#autotokenizer" aria-label="Permalink to &quot;AutoTokenizer&quot;">​</a></h3><p>分词器负责将文本预处理为数字数组作为模型的输入。 有多种规则控制着标记化过程，包括如何拆分单词以及应在什么级别拆分单词（在分词器摘要中了解有关标记化的更多信息）。 要记住的最重要的事情是，您需要实例化具有相同模型名称的分词器，以确保您使用与模型预先训练的相同分词化规则。</p><p>使用自动分词器加载分词器：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> transformers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> AutoTokenizer</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">model_name </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">tokenizer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> AutoTokenizer.from_pretrained(model_name)</span></span></code></pre></div><p>将文本传递给分词器：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">encoding </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> tokenizer(</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;We are very happy to show you the 🤗 Transformers library.&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(encoding)</span></span></code></pre></div><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">{</span><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">&#39;input_ids&#39;</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">:</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [101, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">11312,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 10320,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 12495,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 19308,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 10114,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 11391,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 10855,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 10103,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 100,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 58263,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 13299,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 119,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 102],</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &#39;token_type_ids&#39;:</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [0, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">0,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 0,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 0,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 0,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 0,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 0,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 0,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 0,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 0,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 0,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 0,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 0,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 0],</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &#39;attention_mask&#39;:</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [1, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">1,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 1,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 1,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 1,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 1,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 1,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 1,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 1,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 1,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 1,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 1,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 1,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> 1]}</span></span></code></pre></div><p>分词器返回一个字典，其中包含：</p><ul><li><code>input_ids</code>：token 的数字表示。</li><li><code>attention_mask</code>：指示应关注哪些 token。 分词器还可以接受输入列表，并填充和截断文本以返回具有统一长度的批处理：</li></ul><div class="tip custom-block"><p class="custom-block-title">pytorch</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">pt_batch </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> tokenizer(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">    [</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;We are very happy to show you the 🤗 Transformers library.&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;We hope you don&#39;t hate it.&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">],</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    padding</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    truncation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    max_length</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">512</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    return_tensors</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;pt&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span></code></pre></div></div><div class="tip custom-block"><p class="custom-block-title">tensorflow</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">tf_batch </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> tokenizer(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">    [</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;We are very happy to show you the 🤗 Transformers library.&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;We hope you don&#39;t hate it.&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">],</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    padding</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    truncation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    max_length</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">512</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    return_tensors</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;tf&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span></code></pre></div></div><h3 id="自动建模-automodel" tabindex="-1">自动建模 AutoModel <a class="header-anchor" href="#自动建模-automodel" aria-label="Permalink to &quot;自动建模 AutoModel&quot;">​</a></h3><div class="tip custom-block"><p class="custom-block-title">pytorch</p><p>🤗 转换器提供了一种简单而统一的方式来加载预训练实例。这意味着您可以像加载自动标记器一样加载自动模型。唯一的区别是为任务选择正确的自动模型。对于文本（或序列）分类，应加载 AutoModelForSequenceClassification：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> transformers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> AutoModelForSequenceClassification</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">model_name </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">pt_model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> AutoModelForSequenceClassification.from_pretrained(model_name)</span></span></code></pre></div></div><h3 id="保存模型" tabindex="-1">保存模型 <a class="header-anchor" href="#保存模型" aria-label="Permalink to &quot;保存模型&quot;">​</a></h3><div class="tip custom-block"><p class="custom-block-title">python</p><p>对模型进行微调后，您可以使用 PreTrainedModel.save_pretrained() 使用其分词器保存它：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">pt_save_directory </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &quot;./pt_save_pretrained&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">tokenizer.save_pretrained(pt_save_directory)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">pt_model.save_pretrained(pt_save_directory)</span></span></code></pre></div><p>当您准备好再次使用该模型时，请使用 PreTrainedModel.from_pretrained() 重新加载它：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">pt_model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> AutoModelForSequenceClassification.from_pretrained(</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;./pt_save_pretrained&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span></code></pre></div></div><p>一个特别酷🤗的Transformers功能是能够保存模型并将其重新加载为PyTorch或TensorFlow模型。 <code>from_ptfrom_tf</code> 参数可以将模型从一个框架转换为另一个框架：</p><div class="tip custom-block"><p class="custom-block-title">pytorch</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> transformers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> AutoModel</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">tokenizer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> AutoTokenizer.from_pretrained(tf_save_directory)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">pt_model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> AutoModelForSequenceClassification.from_pretrained(tf_save_directory, </span><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">from_tf</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span></code></pre></div></div><h2 id="自定义模型构建" tabindex="-1">自定义模型构建 <a class="header-anchor" href="#自定义模型构建" aria-label="Permalink to &quot;自定义模型构建&quot;">​</a></h2><p>您可以修改模型的配置类以更改模型的构建方式。该配置指定模型的属性，例如隐藏层或注意头的数量。 从自定义配置类初始化模型时，请从头开始。模型属性是随机初始化的，您需要先训练模型，然后才能使用它来获得有意义的结果。</p><p>首先导入自动配置，然后加载要修改的预训练模型。在 AutoConfig.from_pretrained() 中， 您可以指定要更改的属性，例如 attention heads 的数量：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> transformers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> AutoConfig</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">my_config </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> AutoConfig.from_pretrained(</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;distilbert-base-uncased&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">n_heads</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">12</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span></code></pre></div><div class="tip custom-block"><p class="custom-block-title">pytorch</p><p>使用 AutoModel.from_config() 从自定义配置创建模型：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> transformers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> AutoModel</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">my_model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> AutoModel.from_config(my_config)</span></span></code></pre></div></div><p>有关构建自定义配置的详细信息，请查看创建<a href="https://huggingface.co/docs/transformers/create_a_model" target="_blank" rel="noreferrer">自定义体系结构指南</a>。</p><h2 id="训练器-pytorch-优化的训练循环" tabindex="-1">训练器 - PyTorch 优化的训练循环 <a class="header-anchor" href="#训练器-pytorch-优化的训练循环" aria-label="Permalink to &quot;训练器 - PyTorch 优化的训练循环&quot;">​</a></h2><p>所有模型都是标准的<a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module" target="_blank" rel="noreferrer"><code>torch.nn.Module</code></a>， 因此您可以在任何典型的训练循环中使用它们。虽然您可以编写自己的训练循环， 🤗但 Transformers 为 PyTorch 提供了一个训练器类，其中包含基本的训练循环， 并为分布式<a href="https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/trainer#transformers.Trainer" target="_blank" rel="noreferrer">训练</a>、 混合精度等功能添加了其他功能。</p><p>根据您的任务， 您通常会将以下参数传递给<a href="https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/trainer#transformers.Trainer" target="_blank" rel="noreferrer">训练器</a>：</p><ol><li><p><a href="https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/model#transformers.PreTrainedModel" target="_blank" rel="noreferrer">A PreTrainedModel</a> 或 <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module" target="_blank" rel="noreferrer"><code>torch.nn.Module</code></a>：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">&gt;&gt;&gt;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;"> from</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> transformers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> AutoModelForSequenceClassification</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">&gt;&gt;&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> AutoModelForSequenceClassification.from_pretrained(</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;distilbert-base-uncased&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span></code></pre></div></li><li><p>训练参数包含可以更改的模型超参数，例如学习率、批量大小和要<a href="https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/trainer#transformers.TrainingArguments" target="_blank" rel="noreferrer">训练</a>的周期数。如果未指定任何训练参数，则使用默认值：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">&gt;&gt;&gt;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;"> from</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> transformers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> TrainingArguments</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">&gt;&gt;&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> training_args </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> TrainingArguments(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">     output_dir</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;path/to/save/folder/&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">     learning_rate</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">2e-5</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">     per_device_train_batch_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">8</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">     per_device_eval_batch_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">8</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">     num_train_epochs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> )</span></span></code></pre></div></li><li><p>预处理类，如分词器、图像处理器、特征提取器或处理器：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">&gt;&gt;&gt;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;"> from</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> transformers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> AutoTokenizer</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">&gt;&gt;&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> tokenizer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> AutoTokenizer.from_pretrained(</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;distilbert-base-uncased&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span></code></pre></div></li><li><p>加载数据集：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">&gt;&gt;&gt;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;"> from</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> datasets </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> load_dataset</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">&gt;&gt;&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> dataset </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> load_dataset(</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;rotten_tomatoes&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#768390;"># doctest: +IGNORE_RESULT</span></span></code></pre></div></li><li><p>创建一个函数来标记数据集：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">&gt;&gt;&gt;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;"> def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#DCBDFB;"> tokenize_dataset</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(dataset):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">     return</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> tokenizer(dataset[</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;text&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">])</span></span></code></pre></div><p>然后用<a href="https://huggingface.co/docs/datasets/v2.11.0/en/package_reference/main_classes#datasets.Dataset.map" target="_blank" rel="noreferrer">map</a>将其应用于整个数据集：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">&gt;&gt;&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> dataset </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> dataset.map(tokenize_dataset, </span><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">batched</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span></code></pre></div></li><li><p><a href="https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/data_collator#transformers.DataCollatorWithPadding" target="_blank" rel="noreferrer"> DataCollatorWithPadding</a> 来从数据集创建一批示例：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">&gt;&gt;&gt;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;"> from</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> transformers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> DataCollatorWithPadding</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">&gt;&gt;&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> data_collator </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> DataCollatorWithPadding(</span><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">tokenizer</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">tokenizer)</span></span></code></pre></div></li></ol><p>现在在<a href="https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/trainer#transformers.Trainer" target="_blank" rel="noreferrer">Trainer</a>中收集所有这些类：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span>&gt;&gt;&gt; from transformers import Trainer</span></span>
<span class="line"><span></span></span>
<span class="line"><span>&gt;&gt;&gt; trainer = Trainer(</span></span>
<span class="line"><span>     model=model,</span></span>
<span class="line"><span>     args=training_args,</span></span>
<span class="line"><span>     train_dataset=dataset[&quot;train&quot;],</span></span>
<span class="line"><span>     eval_dataset=dataset[&quot;test&quot;],</span></span>
<span class="line"><span>     tokenizer=tokenizer,</span></span>
<span class="line"><span>     data_collator=data_collator,</span></span>
<span class="line"><span> )  # doctest: +SKIP</span></span></code></pre></div><p>准备好后，调用 <a href="https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/trainer#transformers.Trainer.train" target="_blank" rel="noreferrer">train()</a> 开始训练：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span>&gt;&gt;&gt; trainer.train()</span></span></code></pre></div><div class="tip custom-block"><p class="custom-block-title">TIP</p><p>对于使用序列到序列模型的任务（如翻译或摘要）， 请改用 <a href="https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/trainer#transformers.Seq2SeqTrainer" target="_blank" rel="noreferrer">Seq2SeqTrainer</a> 和 <a href="https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/trainer#transformers.Seq2SeqTrainingArguments" target="_blank" rel="noreferrer">Seq2SeqTrainingArguments</a> 类。</p></div><p>您可以通过对 <a href="https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/trainer#transformers.Trainer" target="_blank" rel="noreferrer">Trainer</a> 中的方法进行子类化来自定义训练循环行为。这允许您自定义损失函数、优化器和调度程序等功能。 查看可以子类化的方法的<a href="https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/trainer#transformers.Trainer" target="_blank" rel="noreferrer">训练器</a>参考。</p><p>自定义训练循环的另一种方法是使用<a href="https://huggingface.co/docs/transformers/main_classes/callbacks" target="_blank" rel="noreferrer">回调</a>。 您可以使用回调与其他库集成，并检查训练循环以报告进度或提前停止训练。回调不会修改训练循环本身中的任何内容。 要自定义类似损失函数的内容，您需要改为对<a href="https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/trainer#transformers.Trainer" target="_blank" rel="noreferrer">训练器</a>进行子类化。</p><hr><ul><li><a href="https://huggingface.co/docs/transformers/quicktour" target="_blank" rel="noreferrer">https://huggingface.co/docs/transformers/quicktour</a></li></ul>`,81)]))}const F=i(e,[["render",h]]);export{g as __pageData,F as default};
