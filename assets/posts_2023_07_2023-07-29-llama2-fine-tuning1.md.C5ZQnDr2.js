import{_ as s,a as i,o as a,aj as n}from"./chunks/framework.Ba_Ek9Jm.js";const t="/assets/4049162902286375.CWxbTlV2.png",l="/assets/4049245625221416.DfhLOSVG.png",h="/assets/4051906528124708.Lj_MoyJ-.png",p="/assets/4028275973410708.oywmmCxz.png",e="/assets/4031006531966791.Dz2VmfQY.png",k="/assets/4028468455528250.BEMoVYJn.png",r="/assets/4028652682305333.Bj9OaGlX.png",b=JSON.parse('{"title":"时隔100天！我再一次微调了 Llama2 模型！","description":"","frontmatter":{"title":"时隔100天！我再一次微调了 Llama2 模型！","date":"2023-07-29T00:00:00.000Z","tags":["ai","ml"],"category":["AI"]},"headers":[],"relativePath":"posts/2023/07/2023-07-29-llama2-fine-tuning1.md","filePath":"posts/2023/07/2023-07-29-llama2-fine-tuning1.md","lastUpdated":1718173059000}'),d={name:"posts/2023/07/2023-07-29-llama2-fine-tuning1.md"},g=n(`<p>!!! abstract</p><p>昨天看了 AgentLM 的微调数据集，于是想也自己微调一下 Llama 2 看看，在 Llama2 刚发布的时候微调过， 当时也是为了实践微调流程。 时隔三个多月，再次微调 Llama 2，跟大家分享下过程和代码，同时介绍下微调的一些基本概念，希望对初次接触微调的读者有所帮助。</p><p>!!!</p><h2 id="llama-2" tabindex="-1">Llama 2 <a class="header-anchor" href="#llama-2" aria-label="Permalink to &quot;Llama 2&quot;">​</a></h2><p><a href="https://ai.meta.com/llama/" target="_blank" rel="noreferrer">Llama2</a> 是 Meta 公司开源的第二代大语言模型，因其卓越的性能， 同时对商业许可的友好支持，被很多公司和组织采纳作为其基础大模型。</p><p>Llama2 有 7B、13B、70B 三个版本，今天我们微调 Hugging Face 的 7B Chat 版本。</p><blockquote><p>Llama-2-Chat 针对对话进行了优化，表现出与 ChatGPT 和 PaLM 等流行的闭源模型类似的性能。 我们甚至可以通过在高质量会话数据集上微调模型来提高模型的性能。</p></blockquote><p>!!! note 微调</p><p>微调是机器学习的一个概念，机器学习中的微调是根据<strong>新数据</strong>调整预训练<strong>模型的权重和参数</strong>以提高其在<strong>特定任务上的性能</strong>的过程。 它涉及在特定于当前任务的新数据集上训练模型，同时更新模型的权重以适应新数据。</p><p>!!!</p><h2 id="微调指南" tabindex="-1">微调指南 <a class="header-anchor" href="#微调指南" aria-label="Permalink to &quot;微调指南&quot;">​</a></h2><p>下面我们将展示微调具有 70 亿个参数的 Llama 2 模型所需的所有步骤。</p><p>整个过程我们将用到 Hugging Face 生态系统中的 LLM 库 ：<code>transformers</code>、<code>accelerate</code>、<code>peft</code>、<code>trl</code> 和 <code>bitsandbytes</code>。</p><h4 id="安装依赖" tabindex="-1">安装依赖 <a class="header-anchor" href="#安装依赖" aria-label="Permalink to &quot;安装依赖&quot;">​</a></h4><p>首先安装需要的 Python 库，可以用想保证环境的隔离，可以使用 Conda 创建一个新环境：</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">conda</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> create</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;"> -n</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> llama2</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> python==</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">3.10</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">source</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> activate</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> llama2</span></span></code></pre></div><p>使用 Pip 工具安装 <code>transformers</code> 等 Python 库：</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> install</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> accelerate</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> peft</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> bitsandbytes</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> transformers</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> trl</span></span></code></pre></div><h4 id="模型下载" tabindex="-1">模型下载 <a class="header-anchor" href="#模型下载" aria-label="Permalink to &quot;模型下载&quot;">​</a></h4><p>我们可以在 <a href="https://huggingface.co/meta-llama/Llama-2-7b-chat-hf" target="_blank" rel="noreferrer">HuggingFace Hub</a> 或者 <a href="https://ai.meta.com/llama/" target="_blank" rel="noreferrer">Llama 官网</a> 进行模型下载，</p><p>Llama2 下载需要进行一下申请，直接在 HuggingFace 或者 <a href="https://ai.meta.com/resources/models-and-libraries/llama-downloads/" target="_blank" rel="noreferrer">Meta 网站</a> 上点击填写表单即可，很快你就会收到回复邮件，告诉你通过授权。</p><p><img src="`+t+'" alt="Hugging Face 审批邮件"></p><p><img src="'+l+'" alt="Meta 审批邮件"></p><p>如果网络不好可以提前下载模型然后加载本地的模型，如果网络比较好可以直接使用 Hugging Face 的下载器。</p><h4 id="数据集" tabindex="-1">数据集 <a class="header-anchor" href="#数据集" aria-label="Permalink to &quot;数据集&quot;">​</a></h4><p>在昨天文章中也讲过，数据集是决定微调效果根本性的东西，但是自己准备一份优秀的数据集也是最花费时间的。 当然没有自己的数据也不是不可以进行微调。</p><p>有很多优秀的开源数据集，比如上次说的：</p><ul><li>清华开源的 <a href="https://huggingface.co/datasets/THUDM/AgentInstruct" target="_blank" rel="noreferrer">AgentInstruct 数据集</a> ，以及</li><li>Databricks 员工制作的 <a href="https://huggingface.co/datasets/databricks/databricks-dolly-15k" target="_blank" rel="noreferrer">Dolly 数据集</a> （超过 15,000 条记录）</li><li>Tatsu Lab 使用 LLM 生成的 <a href="https://huggingface.co/datasets/tatsu-lab/alpaca" target="_blank" rel="noreferrer">Alpaca 数据集</a> （52,000 条指令 ）</li><li><a href="https://huggingface.co/datasets/SirNeural/flan_v2" target="_blank" rel="noreferrer">FLAN（V2）数据集</a> （2,460,000调指令）</li><li><a href="https://huggingface.co/datasets/OpenAssistant/oasst1/tree/main" target="_blank" rel="noreferrer">Open Assistant 数据集</a>（84,400调指令）</li><li>Open Assistant 子集 <a href="https://huggingface.co/datasets/timdettmers/openassistant-guanaco" target="_blank" rel="noreferrer">Guanaco数据集</a>（84,400调指令）</li></ul><p>为了简单起见，我们使用一个较小的数据集 <a href="https://huggingface.co/datasets/mlabonne/guanaco-llama2-1k" target="_blank" rel="noreferrer">guanaco-llama2-1k</a>， 它只有一千条记录，是 Guanaco 数据集的子集。</p><p><img src="'+h+`" alt="guanaco-llama2-1k 数据集"></p><h4 id="模型名称定义" tabindex="-1">模型名称定义 <a class="header-anchor" href="#模型名称定义" aria-label="Permalink to &quot;模型名称定义&quot;">​</a></h4><p>定义模型和数据集的名称，后面会根据这个名称进行数据集的下载</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#768390;"># 从 Hugging Face hub 下载</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">base_model</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> =</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &quot;meta-llama/Llama-2-7b-chat-hf&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#768390;"># 指令数据集</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">guanaco_dataset</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> =</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &quot;mlabonne/guanaco-llama2-1k&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#768390;"># 微调模型名称</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">new_model</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> =</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &quot;llama-2-7b-chat-guanaco&quot;</span></span></code></pre></div><h4 id="加载数据文件" tabindex="-1">加载数据文件 <a class="header-anchor" href="#加载数据文件" aria-label="Permalink to &quot;加载数据文件&quot;">​</a></h4><p>使用如下代码从从 Hugging Face 中心加载「guanaco-llama2-1k」数据集。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">dataset </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> load_dataset(guanaco_dataset, </span><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">split</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;train&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span></code></pre></div><p>如果你是使用本地模型，可以使用目录和文件名称来加载：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">dataset </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> load_dataset(</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&#39;/datasets/&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">data_files</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">[</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&#39;train-00000-of-00001.parquet&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">], </span><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">split</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;train&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span></code></pre></div><h4 id="qlora" tabindex="-1">QLoRA <a class="header-anchor" href="#qlora" aria-label="Permalink to &quot;QLoRA&quot;">​</a></h4><p>使用 QLoRA 的 4 位量化以便在 LLM 模型进行高效微调的时候，节省GPU使用并能保持较高性能。</p><p>BitsAndBytes 创建具有 NF4 类型配置的 4 位量化的代码：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">compute_dtype </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;"> getattr</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(torch, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;float16&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">quant_config </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> BitsAndBytesConfig(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    load_in_4bit</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    bnb_4bit_quant_type</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;nf4&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    bnb_4bit_compute_dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">compute_dtype,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    bnb_4bit_use_double_quant</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span></code></pre></div><ul><li><code>bnb_4bit_use_double_quant</code> 参数可以是第一次量化之后启用第二次量化，以便每个参数额外节省 0.4 位，我们这里暂不开启。</li></ul><h4 id="加载-llama-2-模型" tabindex="-1">加载 Llama 2 模型 <a class="header-anchor" href="#加载-llama-2-模型" aria-label="Permalink to &quot;加载 Llama 2 模型&quot;">​</a></h4><p>使用 Hugging Face 中的计算数据类型 <code>float16</code> 加载 4 位精度的模型，以加快训练速度。如果使用本地模型的话， 将 <code>base_model</code> 指向模型文件夹的位置：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#768390;"># base_model = &quot;~/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/0d52e200fc7ba73089b86c1b5727267dccf65311/&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> AutoModelForCausalLM.from_pretrained(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">    base_model,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    quantization_config</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">quant_config,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    device_map</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">{</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">},</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    local_files_only</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">True</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">model.config.use_cache </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;"> False</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">model.config.pretraining_tp </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;"> 1</span></span></code></pre></div><h4 id="加载分词器" tabindex="-1">加载分词器 <a class="header-anchor" href="#加载分词器" aria-label="Permalink to &quot;加载分词器&quot;">​</a></h4><p>加载分词器设置 <code>padding_side</code>：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">tokenizer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> AutoTokenizer.from_pretrained(base_model, </span><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">trust_remote_code</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">tokenizer.pad_token </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> tokenizer.eos_token</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">tokenizer.padding_side </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &quot;right&quot;</span></span></code></pre></div><h4 id="peft参数" tabindex="-1">PEFT参数 <a class="header-anchor" href="#peft参数" aria-label="Permalink to &quot;PEFT参数&quot;">​</a></h4><p>设置微调参数：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">peft_params </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> LoraConfig(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    lora_alpha</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">16</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    lora_dropout</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">0.1</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    r</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">64</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;none&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    task_type</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;CAUSAL_LM&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span></code></pre></div><p>!!! note PLM 和 PEFT</p><ul><li><strong>预训练语言模型</strong> (PLM) 利用大量的无监督数据（如互联网上的文本）进行训练，以学习语言的通用特征。PLM 需要更新模型的所有参数，这不仅计算成本高，而且需要大量数据。</li><li><strong>参数高效微调</strong> (<a href="https://huggingface.co/docs/peft/conceptual_guides/lora" target="_blank" rel="noreferrer">PEFT</a>) 的工作原理是仅更新模型参数的一小部分，从而使其更加高效。</li></ul><p>!!!</p><h4 id="训练参数" tabindex="-1">训练参数 <a class="header-anchor" href="#训练参数" aria-label="Permalink to &quot;训练参数&quot;">​</a></h4><p>训练参数设置代码如下：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">training_params </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> TrainingArguments(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    output_dir</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;./results&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    num_train_epochs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    per_device_train_batch_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    gradient_accumulation_steps</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    optim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;paged_adamw_32bit&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    save_steps</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">25</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    logging_steps</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">25</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    learning_rate</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">2e-4</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    weight_decay</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">0.001</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    fp16</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    bf16</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    max_grad_norm</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">0.3</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    max_steps</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=-</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    warmup_ratio</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">0.03</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    group_by_length</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    lr_scheduler_type</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;constant&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    report_to</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;tensorboard&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span></code></pre></div><p>下面是一些可用于优化训练过程的参数：</p><ul><li><code>output_dir</code>：输出目录是存储模型预测和检查点的位置</li><li><code>num_train_epochs</code>：训练 epochs 的数量</li><li><code>fp16/bf16</code>：为 False 时禁用 fp16/bf16 训练</li><li><code>per_device_train_batch_size</code>：每个 GPU 训练的批量大小</li><li><code>per_device_eval_batch_size</code>：用于评估的每个 GPU 的批量大小</li><li><code>gradient_accumulation_steps</code>：这是指在更新过程中累积梯度所需的步数</li><li><code>gradient_checkpointing</code>：启用梯度检查点</li><li><code>max_grad_norm</code>：梯度裁剪</li><li><code>learning_rate</code>：初始学习率</li><li><code>weight_decay</code>：权重衰减应用于除偏差/LayerNorm 权重之外的所有层</li><li><code>optim</code>：模型优化器（AdamW 优化器）</li><li><code>lr_scheduler_type</code>：学习率调度</li><li><code>max_steps</code>：训练步骤数</li><li><code>warmup_ratio</code>：线性预热的步骤比率</li><li><code>group_by_length</code>：这可以显着提高性能并加速训练过程</li><li><code>save_steps</code>：每 25 个更新步骤保存检查点</li><li><code>logging_steps</code>：每 25 个更新步骤记录一次</li></ul><h4 id="微调器配置" tabindex="-1">微调器配置 <a class="header-anchor" href="#微调器配置" aria-label="Permalink to &quot;微调器配置&quot;">​</a></h4><p>使用 SFTTrainer 来进行微调，为 SFT Trainer 传入模型、数据集、Lora 配置、分词器和训练参数等参数。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">trainer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> SFTTrainer(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">model,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    train_dataset</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">dataset,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    peft_config</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">peft_params,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    dataset_text_field</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;text&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    max_seq_length</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    tokenizer</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">tokenizer,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    args</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">training_params,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    packing</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span></code></pre></div><p>!!! note 监督微调（SFT） <strong>监督微调（SFT）</strong> 是人类反馈强化学习（RLHF）的关键步骤。 HuggingFace 的 TRL 库提供了一个易于使用的 API， 只需几行代码即可创建 SFT 模型并在数据集上训练它们。 它配备了使用强化学习训练语言模型的工具，从监督微调开始，到奖励建模，以及近端策略优化（PPO）。 !!!</p><h4 id="执行模型微调" tabindex="-1">执行模型微调 <a class="header-anchor" href="#执行模型微调" aria-label="Permalink to &quot;执行模型微调&quot;">​</a></h4><p>调用 <code>.train()</code> 方法进行训练， 整个过程大约 <strong>20 分钟</strong>。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">trainer.train()</span></span></code></pre></div><p>训练的时候可以使用 <code>nvtop</code> 查看 GPU 的使用情况：</p><p><img src="`+p+`" alt="训练时的 GPU 使用"></p><h4 id="保存模型" tabindex="-1">保存模型 <a class="header-anchor" href="#保存模型" aria-label="Permalink to &quot;保存模型&quot;">​</a></h4><p>训练模型后，保存模型：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">trainer.save_model(new_model)</span></span></code></pre></div><p>也可以使用 model 和 tokenizer 接口保存模型和分词器。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">trainer.model.save_pretrained(new_model)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">trainer.tokenizer.save_pretrained(new_model)</span></span></code></pre></div><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">ls</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> llama-2-7b-chat-guanaco/</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;"> -hal</span></span></code></pre></div><p><img src="`+e+`" alt="新的模型文件"></p><h4 id="训练指标" tabindex="-1">训练指标 <a class="header-anchor" href="#训练指标" aria-label="Permalink to &quot;训练指标&quot;">​</a></h4><p>训练完成后可以在 <a href="https://www.tensorflow.org/tensorboard?hl=zh-cn" target="_blank" rel="noreferrer">Tensorboard</a> 的交互式会话中查看训练结果。</p><p>指定日志文件目录，启动 Tensorboard：</p><blockquote><p>如果你是在服务器训练，需要通过外网访问，可使用 <code>--bind_all</code> 参数开启外网访问。</p></blockquote><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> tensorboard </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> notebook</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">log_dir </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &quot;results/runs&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">notebook.start(</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;--logdir </span><span style="--shiki-light:#005CC5;--shiki-dark:#F47067;">{}</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> --bind_all --port 4000&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">.format(log_dir))</span></span></code></pre></div><p><img src="`+k+'" alt="使用 TensorBoard 查看训练指标"></p><p><img src="'+r+`" alt="使用 TensorBoard 查看训练指标"></p><p>!!! note TensorBoard：TensorFlow 的可视化工具包</p><p>TensorBoard 是用于提供机器学习工作流期间所需测量和呈现的工具。它使您能够跟踪实验指标（例如损失和准确率），呈现模型计算图，将嵌入向量投影到较低维度的空间等。 它提供机器学习实验所需的可视化功能和工具：</p><ul><li>跟踪和可视化损失及准确率等指标</li><li>可视化模型图（操作和层）</li><li>查看权重、偏差或其他张量随时间变化的直方图</li><li>将嵌入投射到较低的维度空间</li><li>显示图片、文字和音频数据</li><li>剖析 TensorFlow 程序</li></ul><p>!!!</p><h4 id="验证模型" tabindex="-1">验证模型 <a class="header-anchor" href="#验证模型" aria-label="Permalink to &quot;验证模型&quot;">​</a></h4><p>话说这个是对普通人</p><p>加载新模型：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> torch</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> peft </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> AutoPeftModelForCausalLM</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> transformers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> AutoTokenizer</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> AutoPeftModelForCausalLM.from_pretrained(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">    new_model,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    torch_dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">torch.float16,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    load_in_4bit</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">tokenizer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> AutoTokenizer.from_pretrained(new_model)</span></span></code></pre></div><p>我们先问一个问题：「达芬奇是谁？」</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">logging.set_verbosity(logging.</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">CRITICAL</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">prompt </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &quot;Who is Leonardo Da Vinci?&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">pipe </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> pipeline(</span><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">task</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;text-generation&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">model, </span><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">tokenizer</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">tokenizer, </span><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">max_length</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">200</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">result </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> pipe(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;&lt;s&gt;[INST] </span><span style="--shiki-light:#005CC5;--shiki-dark:#F47067;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">prompt</span><span style="--shiki-light:#005CC5;--shiki-dark:#F47067;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> [/INST]&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">do_sample</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">top_p</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">0.9</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">temperature</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">0.9</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(result[</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">][</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&#39;generated_text&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">])</span></span></code></pre></div><p>可以看到回答还是很不错的，</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">&lt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">s</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">[INST] Who is Leonardo Da Vinci</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">?</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [/INST] </span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">Leonardo</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> da</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> Vinci</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> (1452-1519) was an Italian polymath, artist, inventor, and scientist. </span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">He</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> is</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> widely</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> considered</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> one</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> of</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> the</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> greatest</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> painters</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> of</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> all</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> time,</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> </span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">and</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> his</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> inventions</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> and</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> designs</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> were</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> centuries</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> ahead</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> of</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> his</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> time.</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> </span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">He</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> is</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> known</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> for</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> his</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> famous</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> works</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> of</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> art,</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> </span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">including</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> the</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> Mona</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> Lisa</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> and</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> The</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> Last</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> Supper,</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> </span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">as</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> well</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> as</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> his</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> contributions</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> to</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> engineering,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> anatomy,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> and</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> mathematics.</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> </span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">Da</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> Vinci</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> was</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> a</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;"> true</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> Renaissance</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> man,</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> </span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">and</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> his</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> legacy</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> continues</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> to</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> inspire</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> and</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> influence</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> people</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> around</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> the</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> world.</span></span></code></pre></div><p>然后我们中文问一下：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">&gt;&gt;&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> prompt </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &quot;李奥纳多达芬奇是谁?&quot;</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">&gt;&gt;&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> result </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> pipe(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;&lt;s&gt;[INST] </span><span style="--shiki-light:#005CC5;--shiki-dark:#F47067;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">prompt</span><span style="--shiki-light:#005CC5;--shiki-dark:#F47067;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> [/INST]&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">&gt;&gt;&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;"> print</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(result[</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">][</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&#39;generated_text&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">])</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">&lt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">s</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">[</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">INST</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">] 李奥纳多达芬奇是谁</span><span style="--shiki-light:#B31D28;--shiki-dark:#FF938A;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;">?</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">/</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">INST</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">] </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">李奥纳多达芬奇是一位著名的美国数学家和物理学家，</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">他的姓名是李奥纳多达芬奇。他是美国物理学会的创始人之一，</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">也是美国数学学会的创始人之一。</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">他的贡献包括数学</span></span></code></pre></div><p>虽然我的中文翻译并不对（一般翻译成<code>列奥纳多 达芬奇</code>），但这胡说霸道的程度有点儿离谱。</p><p>接下来我们再问两个训练数据中存在的问题：</p><blockquote><p>&quot;面试的最后，面试官通常会问 “你有什么要问我的吗”，怎样应对算加分？&quot;</p></blockquote><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">&lt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">s</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">[INST] 面试的最后，面试官通常会问 “你有什么要问我的吗”，怎样应对算加分？ [/INST] </span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">在面试的最后，面试官通常会问</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> “你有什么要问我的吗”，这是一个机会，让你表达自己的兴趣和热情，</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">也是一个机会，让面试官了解你的背景和背景知识。</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">您可以根据自己的兴趣和热情，选择一些有趣的问题，例如：</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> 面试官的工作经验和职业发展。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> 面试官的工作背景和工作环境。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> 面试官的职业发展计划和规划。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> 面试官的职业发展和职业发展的机会。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> 面试官的职业发展和职业发展的挑战。</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">您可以根据自己的兴趣和热情，选择一些有趣的问题，例如：</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> 面试官的工作经验和职业发展。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> 面试官的工作背景和工作环境。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> 面试官的职业发展计划和规划。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> 面试官的职业发展和职业发展的机会。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> 面试官的职业发展和职业发展的挑战。</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">您可以根据自己的兴趣和热情，选择一些有趣的问</span></span></code></pre></div><blockquote><p>&quot;你是一位宋词学者，帮助我学习一些宋词相关的知识。&quot;</p></blockquote><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">&lt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">s</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">[INST] 你是一位宋词学者，帮助我学习一些宋词相关的知识。 [/INST] </span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">宋词是中国古代文学中的一种词语，它的出处是《词》，</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">是中国古代文学中的一种重要的词语。宋词的出处是《词》，</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">是中国古代文学中的一种重要的词语。宋词的出处是《词》，</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">是中国古代文学中的一种重要的词语。宋词的出处是《词》，</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">是中国古代文学中的一种重要的词语。宋词的出处是《词》，</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">是中国古代文学中的一种重要的词语。宋词的出处是《词》，</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">是中国古代文学中的一种重要的词语。宋词的出处是《词》，</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">是中国古代文学中的一种重要的词语。宋词的出处是《词》，</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">是中国古代文学中的一种重要的词语。宋词的出处是《词》，。</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">宋词的出处是《词》，是中国古代文学中的一种重要的词语。</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">宋词的出处是《词》，是中国古代文学中的一种重要的词语。</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">宋词的出处是《词》，是中国古代文学中的一种重要的词语。</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">宋词的出处是《��</span></span></code></pre></div><p>但是，同样的问题用英文提问效果会好不少。</p><h2 id="结论" tabindex="-1">结论 <a class="header-anchor" href="#结论" aria-label="Permalink to &quot;结论&quot;">​</a></h2><p>结果显而易见，至少微调的<strong>中文效果并不好</strong>。这也是很多做 AI 项目的人<strong>经常遇到的问题</strong>。</p><p>而经过我的测试，用少量的中文数据训练，或者通过优化微调参数能有一些提升但是， 并不能很好的提升 Llama2 的汉语能力，本文只给大家展示下微聊流程，优化问题不做过多讨论。</p><p>如果大家需要微调中文大模型的话还是使用网上经过大量数据训练的 Llama 2 中文模型， 或者直接使用 ChatGLM、Baichuan 等国产中英双语模型。</p>`,108),o=[g];function F(y,c,D,A,C,u){return a(),i("div",null,o)}const B=s(d,[["render",F]]);export{b as __pageData,B as default};
