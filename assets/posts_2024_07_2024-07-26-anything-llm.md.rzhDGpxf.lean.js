import{_ as i,a as t,af as l,o as s}from"./chunks/framework.C87LdZyP.js";const p="/assets/83195279255625.sPHt8Z-q.png",n="/assets/105293637364500.CG2fs8MI.png",e="/assets/65282913593125.BnwQDxu4.png",o="/assets/65561689132583.IVe0NnYT.png",r="/assets/65324232786416.DVsIN48t.png",h="/assets/65372063080166.O6KhQrhC.png",c="/assets/65460530831208.Dq8ivGS9.png",d="/assets/65812902339750.DY5xXOyP.png",g="/assets/66082760798208.DL1ZTzfV.png",m="/assets/66116436302208.BlsZqPKz.png",u="/assets/114593119910166.Bx7EVrkO.png",L="/assets/119067979534750.QkhGlvUB.png",M="/assets/119152800692875.DDqDOrYz.png",A="/assets/119415169971541.BxC4-nK-.png",b="/assets/119487174808500.CwIy-9Ru.png",_="/assets/119586685992791.9ccGwpQy.png",q="/assets/119688310087958.DvtUjU8Q.png",k="/assets/120222495538708.BuBrQ-2i.png",f="/assets/120765819620666.DidS6Ebr.png",B=JSON.parse('{"title":"《AI打工摸鱼笔记》LLM+本地知识库自动填写售前技术调研表(上)","description":"","frontmatter":{"title":"《AI打工摸鱼笔记》LLM+本地知识库自动填写售前技术调研表(上)","date":"2024-07-26 10:00:00","tags":["llm-local-api"],"category":["AI"]},"headers":[],"relativePath":"posts/2024/07/2024-07-26-anything-llm.md","filePath":"posts/2024/07/2024-07-26-anything-llm.md","lastUpdated":1722246400000}'),y={name:"posts/2024/07/2024-07-26-anything-llm.md"};function x(P,a,S,I,G,v){return s(),t("div",null,a[0]||(a[0]=[l('<div class="admonition abstract"><p class="admonition-title">abstract</p><p>随着AI工具的普及，使用大模型对于普通打工人来说已经没有门槛了。本文介绍如何使用本地大模型工具， <strong>不编写任何代码</strong>，实现基于RAG的对售前技术调研文档的填写功能。</p></div><p>今天和大家讲一下我怎么用 LM Studio、Anything LLM、Streamlit 来实现本地的 RAG 功能， 同时让其帮自己『打工』。打工的内容我只是列举了一个简单场景，大家有类似的工作内容都可以依照 此方法来实现。</p><p>文章内容：</p><ul><li>背景需求和设计思路</li><li>Anything LLM 使用</li><li>基础版AI员工（LM Studio + Anything LLM + 知识库）</li><li>高级版AI员工（Streamlit 程序「下篇」）</li></ul><h2 id="介绍" tabindex="-1">介绍 <a class="header-anchor" href="#介绍" aria-label="Permalink to &quot;介绍&quot;">​</a></h2><p>LLM 大模型如今已经走进了寻常打工人的电脑上，我猜大家用的最多的功能还是在线聊天的文本生成吧。 其实我们可以<strong>尽可能让AI帮我们快速完成工作</strong>，而不仅仅是把应用限制在问答上。</p><p><img src="'+p+'" alt="谷歌 Gemini AI 聊天程序"></p><p>!!! explain 大家可以把日常的工作内容或者场景留言给我， 我们一起讨论下如何让 AI 帮我们打工的可能性。 !!!</p><h2 id="背景" tabindex="-1">背景 <a class="header-anchor" href="#背景" aria-label="Permalink to &quot;背景&quot;">​</a></h2><p>笔者在一家软件公司任职，正常的软件售卖（合同签订之前）过程有一个「<strong>售前</strong>」的过程，</p><h3 id="售前-pre-sales" tabindex="-1">售前（Pre-sales） <a class="header-anchor" href="#售前-pre-sales" aria-label="Permalink to &quot;售前（Pre-sales）&quot;">​</a></h3><p>大致讲一下售前是个啥。</p><p>销售售前（Pre-sales）团队在销售过程中起着关键作用。 他们负责技术支持和咨询，以帮助销售团队赢得新客户和合同。 售前团队的主要职责和工作内容有：</p><ol><li><p>需求分析：售前工程师与潜在客户合作，了解他们的业务需求和技术要求。这有助于确保提供的解决方案能准确满足客户的需求。</p></li><li><p>产品演示：售前团队通常会进行产品演示，展示软件的功能和优势。这些演示通常包括现场演示、网络研讨会或产品试用，以展示产品的实际应用和效果。</p></li><li><p>解决方案设计：基于客户的需求，售前团队设计定制化的解决方案。这可能包括软件配置、集成方案和功能定制，以确保产品能完全符合客户的业务流程和技术环境。</p></li><li><p><strong>技术咨询</strong>：售前工程师提供技术咨询，回答潜在客户关于<strong>产品功能、性能、兼容性等方面的问题</strong>。他们需要深入了解产品的技术细节和行业标准，以便提供准确的信息。</p></li><li><p>编写技术文档：售前团队通常会编写技术文档和提案，包括解决方案建议书、白皮书、技术规格书等。这些文档帮助客户更好地理解解决方案的细节和优势。</p></li><li><p>投标支持：在参与招标项目时，售前团队协助准备投标文件，确保所有技术要求和规范都得到满足。他们可能还会参与投标演示和答辩。</p></li><li><p>客户培训：在客户决定购买产品后，售前团队可能会参与客户培训（小规模小范围），帮助客户熟悉和有效使用软件产品。</p></li><li><p>市场调研：售前团队还需要了解市场动态、竞争产品和行业趋势，以便为公司提供市场情报和反馈，帮助改进产品和销售策略。</p></li><li><p>内部协调：售前团队与销售、产品开发、客户支持等内部团队紧密合作，确保客户需求被准确传达和满足。这种协作有助于提升客户满意度和产品质量。</p></li></ol><p>上面有一项技术咨询，就用到我了。</p><p>我虽然不是售前团队的，但是作为技术产品团队的一员，也经常在客户问到某些专业（也可能不是那么专业） 的技术问题，销售售前团队无法回答时，去支持一下。</p><p>常见的一个任务就是，客户给一个他们的《技术标准项》，或者《供应商产品技术调研表》这样的东西， 让我们去填写，然后由客户初步判断一下我们公司产品在技术层面和他们的匹配度。</p><p>不同客户的技术调研内容不一样，可能涉及架构、功能、安全、性能、运维等五花八门的问题。</p><h2 id="方案" tabindex="-1">方案 <a class="header-anchor" href="#方案" aria-label="Permalink to &quot;方案&quot;">​</a></h2><h3 id="旧的工作方式" tabindex="-1">旧的工作方式 <a class="header-anchor" href="#旧的工作方式" aria-label="Permalink to &quot;旧的工作方式&quot;">​</a></h3><p>每次拿到技术调研表，当然是一条条的去写，如果之前有资料的那么就拷贝一些内容过来。</p><p>不过每家的问题组织方式都不一样，导致很多问题不能直接拷贝，还要组织语言。</p><h3 id="新的工作方式" tabindex="-1">新的工作方式 <a class="header-anchor" href="#新的工作方式" aria-label="Permalink to &quot;新的工作方式&quot;">​</a></h3><p>新的方式当然是让 AI 尽可能帮我们完成工作，我们设定初级和中级两种工作方式：</p><ul><li>初级：输入调研表的一个问题，让AI给出答案</li><li>中级：直接把给定格式的 Excel 丢给AI程序，自动回答所有问题</li></ul><p>由于设计到工作内容和客户隐私，这部分数据（自己公司的技术资料、客户的调研表）肯定不能放到网络上， 这样就需要本地的大模型（LLM）来支持。</p><p>实现上面的功能我们需要如下三个工具：</p><ul><li>LM Studio：本地的大模型</li><li>AnythingLLM：知识库 RAG</li><li>Streamlit：读取和展示 Excel 的界面工具</li></ul><p>前面两个工具直接安装就好了，不需要编码，可以实现咱们提到的初级能力。</p><h2 id="lm-studio" tabindex="-1">LM Studio <a class="header-anchor" href="#lm-studio" aria-label="Permalink to &quot;LM Studio&quot;">​</a></h2><p>LM Studio 是一个可以让你本地运行任意大模型的工具，使用方法可以查看我的上篇文章，这里不再赘述。</p><ul><li><a href="./2024-07-25-lm-studio">《本地 LLM 可视化工具 LM Studio 突破国内网络限制使用》</a></li></ul><h2 id="anything-llm" tabindex="-1">Anything LLM <a class="header-anchor" href="#anything-llm" aria-label="Permalink to &quot;Anything LLM&quot;">​</a></h2><p>Anything LLM 的宣传语是 『The all-in-one AI application』， 也就是<strong>一体化</strong>的 AI 应用程序。 号称支持<strong>任意大模型（LLM）</strong>, <strong>任意文档</strong>, <strong>任意 AI 代理</strong>, <strong>完全私有</strong>。 可以执行 RAG、AI 代理等功能，且无需担心代码或基础设施问题。</p><p><img src="'+n+'" alt="Anything LLM 网站"></p><p>当然 Anything LLM 也可以为企业或组织提供完全可定制的、私有的、一体化的 AI 应用程序， 基本上是一个具有许可的完整 ChatGPT，并且具有任何 LLM、嵌入模型或矢量数据库接入的能力。</p><p>下载安装，打开可以看到程序界面：</p><p><img src="'+e+'" alt="Anything LLM 客户端界面"></p><p>点击设置按钮：</p><p><img src="'+o+'" alt="Anything LLM 设置按钮"></p><h3 id="llm-设置" tabindex="-1">LLM 设置 <a class="header-anchor" href="#llm-设置" aria-label="Permalink to &quot;LLM 设置&quot;">​</a></h3><p>首先设置 LLM ，我们再「大模型供应商」里面选择 「LM Studio」，以及对应的模型。</p><p><img src="'+r+'" alt="Anything LLM 设置界面"></p><div class="admonition note"><p class="admonition-title">LM Studio 端口</p><p>如果是用默认端口启动 LM Studio，那么直接选择 「LM Studio」这个供应商就可以了， 如果是改了端口运行的 LM Studio，那么选择供应商之后，还需要修改 <code>LM Studion Base URL</code> 的地址端口才可以选择到模型。</p></div><h3 id="向量数据库设置" tabindex="-1">向量数据库设置 <a class="header-anchor" href="#向量数据库设置" aria-label="Permalink to &quot;向量数据库设置&quot;">​</a></h3><p>接着设置向量数据库，使用默认的 LanceDB，这样就不用安装向量数据库了。</p><p><img src="'+h+'" alt="Anything LLM 设置向量库"></p><h2 id="嵌入模型" tabindex="-1">嵌入模型 <a class="header-anchor" href="#嵌入模型" aria-label="Permalink to &quot;嵌入模型&quot;">​</a></h2><p>嵌入模型同样使用 LM Studio 的，前提是要在 LM Studio 先下载好嵌入模型啊。</p><p><img src="'+c+'" alt="Anything LLM 嵌入项设置"></p><p>余下的设置使用默认即可。</p><h2 id="工作区" tabindex="-1">工作区 <a class="header-anchor" href="#工作区" aria-label="Permalink to &quot;工作区&quot;">​</a></h2><p>Anything LLM 有工作区的概念， 工作区使用允许的聊天方法设置聊天机器人的运行方式。有两个选项：</p><ul><li>聊天：聊天机器人将回答所有问题，无论其上下文如何。</li><li>查询：聊天机器人只会响应与工作区中的文档相关的聊天。</li></ul><p>以及这个工作区使用的 LLM 配置，</p><ul><li>大模型是哪个（可以继承全局设置）</li><li>聊天的历史记录数</li><li>聊天系统提示词：定义 AI 生成响应的上下文和指令</li><li>LLM 的温度</li></ul><p>每个工作区有独立的向量存储和配置：</p><ul><li>当前存储库的标识和向量数量</li><li>向量库的最大上下文片段：控制每次聊天或查询将发送到 LLM 的上下文片段的最大数量。</li><li>文档相似性阈值：文档与聊天相关所需的最低相似度分数。数字越高，来源与聊天就越相似。</li></ul><p>我们创建一个工作区：</p><p><img src="'+d+'" alt="创建新的工作区"></p><p>设置查询模式：</p><p><img src="'+g+'" alt="设置聊天模式为「查询」"></p><p>记得保存配置，不然不生效哦：</p><p><img src="'+m+'" alt="更新工作区，保存设置"></p><h2 id="知识准备" tabindex="-1">知识准备 <a class="header-anchor" href="#知识准备" aria-label="Permalink to &quot;知识准备&quot;">​</a></h2><p>我们先看一下调研表大概长什么样（内容当然是我虚构的了 🌈），</p><p><img src="'+u+'" alt="技术调研表"></p><blockquote><p>上面这个调研表是用 GPT 生成的，看描述其实回答是否就行了，我们暂且那这个做例子。</p></blockquote><p>为了自动填写技术调研表，肯定要有知识储备了，总不能让我们的大模型随便答吧。</p><p>我们都知道，对于大模型来说，越优秀的训练数据越能训练出高性能的大模型。 对于我们的知识问答一样，知识数据的质量好坏也直接决定了我们程序给出答案的质量。</p><p>构建技术数据我们遵从如下几个原则：</p><ul><li>数据尽量采用标题-内容的模式（问答） <ul><li>当然您也可以直接使用公司内的产品设计、技术设计文档</li></ul></li><li>所有数据都由人工确认</li><li>数据需要跟随使用人工增加和更新</li></ul><p>由于基础资料不会太多，而且企业要求「<strong>不能出错</strong>」，所以人工检查和人工维护是必须的。</p><p>为了方便起见，我们每个类型维护一个 Markdown 文件。</p><p><img src="'+L+'" alt="架构设计说明（内容也是虚构演示用的哦）"></p><blockquote><p>Anything LLM 目前本地版本只支持文本格式的文件，不支持 Excel、PDF 啥的。</p></blockquote><h3 id="上传文档" tabindex="-1">上传文档 <a class="header-anchor" href="#上传文档" aria-label="Permalink to &quot;上传文档&quot;">​</a></h3><p>我们点击工作区旁边的上传按钮：</p><p><img src="'+M+'" alt="工作区上传文档按钮"></p><p>打开上传界面之后，</p><ol><li>上传文件 <code>it-01.md</code></li><li>选中上传的文件</li><li>点击<code>移动到工作区按钮</code></li></ol><p><img src="'+A+'" alt="上传文件并添加到工作区"></p><p>然后点击保存和嵌入按钮：</p><p><img src="'+b+'" alt="保存和嵌入"></p><p>AnythingLLM 就会把选择的文档构建向量（嵌入），存储到向量数据库中。</p><p>顺便提一句，AnythingLLM 也支持一些连接器，比如 Github 仓库。</p><p><img src="'+_+'" alt="AnythingLLM 对连接器的支持"></p><p>文档嵌入成功之后，我们打开工作区的设置，查看「向量数据库」页签，可以看到「向量数量」发生了变化。</p><p><img src="'+q+`" alt="查看嵌入成功的向量数量"></p><h3 id="系统提示语" tabindex="-1">系统提示语 <a class="header-anchor" href="#系统提示语" aria-label="Permalink to &quot;系统提示语&quot;">​</a></h3><p>为了更好的生成答案，我们确认把聊天模式设置为「<code>查询</code>」，不然 LLM 回答的问题大概率和你自家的系统无关。</p><p>然后我们设置「聊天提示词」，这个根据你的需要定制，可以参考之前写的标准答案。我这里简答定制下：</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">你是WMS厂商的资深售前顾问，请根据上下文来回答客户关于我们产品的问题。</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">不仅要回答是否满足，还要回答我们如何实现的，以及有什么优势。</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">以如下格式来回答。</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">满足。我们的产品采用....</span></span></code></pre></div><p><img src="`+k+'" alt="更好的RAG：工作区聊天设置"></p><h3 id="验证" tabindex="-1">验证 <a class="header-anchor" href="#验证" aria-label="Permalink to &quot;验证&quot;">​</a></h3><p>为了方便起见，我们直接在系统提示词里面指定了回答产品问题，所以直接讲调研表的内容粘贴进来即可：</p><p><img src="'+f+'" alt="Anything LLM RAG 的结果"></p><p>基本像模像样，</p><div class="admonition note"><p class="admonition-title">文档的重要性</p><p>再次强调一下，文档的重要，RAG 不是凭空而来的，而且企业核心问题是不能出错， 而不是小作文写的多好。所以严格依赖文档知识，以及对结果必要的检查， 同时对文档进行升级是一个必不可少而且极其重要的步骤。</p><p>大模型能不能「<strong>越用越好</strong>」的重点就在这里。</p></div><h2 id="大模型的选择" tabindex="-1">大模型的选择 <a class="header-anchor" href="#大模型的选择" aria-label="Permalink to &quot;大模型的选择&quot;">​</a></h2><p>对于本文提到的这类 RAG 问题，我觉得 7B 大小左右的大模型就足够胜任了，而且对个人电脑比较友好， 太大的一般电脑可能跑不起来了，太小的可能效果不太好（不过 7B 左右已经是PC端最小的模型了，2B 的模型一般是针对移动设备等场景的）。</p><p>我一般选用国产的模型（比如 GLM4、Qwen2、Baichuan2等）， 因为国外模型（Llama3、Gemma、Phi等）训练资料库中文占比不大， 而且小尺寸也决定了其双语、多语能力不会十分出色，使用的时候会有奇奇怪怪的问题。</p><h2 id="下一步" tabindex="-1">下一步 <a class="header-anchor" href="#下一步" aria-label="Permalink to &quot;下一步&quot;">​</a></h2><p>好了，今天就到这里。没有写一句代码，就是点点鼠标，就完成了<strong>基于知识库</strong>的技术调研问答。</p><p>现在已经可以针对技术问题一个个进行回答了（其实也可以多个问题也可以一起回答，是具体情况效果可能不一定特别好）。 下一步我们使用 Streamlit 实现：输入 Excel 技术调研表，直接输出填写好的 Excel 文件。</p><p>!!! article 相关文章阅读</p><ul><li><a href="./2024-07-25-lm-studio">本地 LLM 可视化工具 LM Studio 突破国内网络限制使用</a></li><li><a href="./2024-07-24-ollama-full-guide">Ollama 本地运行大模型(LLM)完全指南</a></li><li><a href="./../06/2024-06-14-agentscope-intro">AgentScope 可视化的多智能体平台</a></li><li><a href="./2024-07-23-supersonic-intro">腾讯音乐开源的 Chat BI 平台</a></li><li><a href="./../06/2024-06-13-vanna-ai">VannaAI：RAG+AI 生成 SQL 使用和Prompt解析</a></li><li><a href="./../06/2024-06-14-vanna-ai-training">训练 Vanna RAG-to-SQL 模型来适配企业级数据库</a> !!!</li></ul>',107)]))}const C=i(y,[["render",x]]);export{B as __pageData,C as default};
