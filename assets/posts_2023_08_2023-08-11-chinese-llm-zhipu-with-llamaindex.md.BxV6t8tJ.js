import{_ as i,a,af as n,o as t}from"./chunks/framework.C87LdZyP.js";const l="/assets/118336253151500.BHdjxtRv.png",p="/assets/118304028620500.DLYwoEU_.png",h="/assets/131170679363625.C3nqGelx.png",e="/assets/131266455168875.YRlx76XS.png",k="/assets/8312611366666.z1vczK0y.png",d="/assets/9932586531041.Bjh1CCyv.png",r="/assets/12408711147875.C5a6SFR2.png",m=JSON.parse('{"title":"国产AI崛起：Streamlit 和智谱AI 实现 PDF 对话","description":"","frontmatter":{"title":"国产AI崛起：Streamlit 和智谱AI 实现 PDF 对话","date":"2023-08-11T00:00:00.000Z","tags":["ai","llm"],"category":["ai"]},"headers":[],"relativePath":"posts/2023/08/2023-08-11-chinese-llm-zhipu-with-llamaindex.md","filePath":"posts/2023/08/2023-08-11-chinese-llm-zhipu-with-llamaindex.md","lastUpdated":1718173059000}'),g={name:"posts/2023/08/2023-08-11-chinese-llm-zhipu-with-llamaindex.md"};function o(y,s,F,A,c,C){return t(),a("div",null,s[0]||(s[0]=[n('<div class="admonition abstract"><p class="admonition-title">abstract</p><p>经历了一年的发展，国产 AI 已经慢慢地走向成熟，今天和大家一起看一下人如何把国内的明星产品 智谱AI 和 LlamaIndex 这个数据框架结合起来，处理日常任务。</p></div><h2 id="国产-ai-产品" tabindex="-1">国产 AI 产品 <a class="header-anchor" href="#国产-ai-产品" aria-label="Permalink to &quot;国产 AI 产品&quot;">​</a></h2><p>大家都知道，今天一整年 AI 和 大模型圈子都是火热非常，几年 8 月份，随着《生成式人工智能服务管理暂行办法》的正式实施， 也为中国自己的生成式人工智能之路，从政策上给出了要求和肯定，让 AIGC 行业发展不再迷茫。</p><p>十一月份的时候，我觉得国产AI已经具备了产业应用场景落地的基本条件（主要是指B端）， 想要把人工智能和自己公司的产品结合起来需求的同学们可以动起来了。 不过最近工作原因关注国内商业/企业应用较少，各种会议也没关注关注，实在不知道我们 B 端玩家们是否正在撸起袖子热火朝天的干活。 今天就从我自己入手，抛弃 OpenAI，使用我们国内的 AI 平台，展示一下如何使用 LlamaIndex 框架和智谱 AI 结合起来处理常见的应用场景。</p><h3 id="国内有哪些大模型" tabindex="-1">国内有哪些大模型 <a class="header-anchor" href="#国内有哪些大模型" aria-label="Permalink to &quot;国内有哪些大模型&quot;">​</a></h3><p>不论开源闭源，我这里随便列几个常见的大模型（排名不分先后）：</p><table tabindex="0"><thead><tr><th>机构/公司</th><th>模型名称</th></tr></thead><tbody><tr><td>百度</td><td>文心大模型</td></tr><tr><td>抖音</td><td>云雀大模型</td></tr><tr><td>智谱</td><td>GLM大模型</td></tr><tr><td>中国科学院</td><td>紫东太初大模型</td></tr><tr><td>百川智能</td><td>百川大模型</td></tr><tr><td>商汤</td><td>日日新大模型</td></tr><tr><td>MiniMax</td><td>ABAB大模型</td></tr><tr><td>上海人工智能实验室</td><td>书生通用大模型</td></tr><tr><td>科大讯飞</td><td>星火认知大模型</td></tr><tr><td>腾讯</td><td>混元大模型</td></tr><tr><td>阿里巴巴</td><td>通义千问大模型</td></tr></tbody></table><h3 id="有哪些产品" tabindex="-1">有哪些产品 <a class="header-anchor" href="#有哪些产品" aria-label="Permalink to &quot;有哪些产品&quot;">​</a></h3><p>同样的我们国内看看有哪些类似 ChatGPT 一样的生成式人工智能产品呢？</p><table tabindex="0"><thead><tr><th>百度</th><th>文心一言</th></tr></thead><tbody><tr><td>抖音</td><td>豆包</td></tr><tr><td>科大讯飞</td><td>讯飞星火</td></tr><tr><td>百川智能</td><td>百川大模型</td></tr><tr><td>智谱 AI</td><td>智谱清言</td></tr><tr><td>阿里巴巴</td><td>通义千问</td></tr></tbody></table><p>当然上面的列表不是很全，只是一些我比较熟悉的。</p><h3 id="大模型选择和使用" tabindex="-1">大模型选择和使用 <a class="header-anchor" href="#大模型选择和使用" aria-label="Permalink to &quot;大模型选择和使用&quot;">​</a></h3><p>国内大模型或平台的选择大家可以根据自己的需求来，毕竟上面无论那一家都是有非常强大的实力， 且发展迅速。</p><p>这些 AI 厂商一般有三种提供服务的方式：</p><ul><li>模型私有部署：直接部署开源或者闭源的模型（需要显卡）；</li><li>AI开发平台：很多平台提供了 LLM 服务，可以在线进行模型测试、开发、部署、微调等服务（直接付费即可）；</li><li>API调用：这个就和 OpenAI 早期的服务模式一样，提供 API 的调用。</li></ul><p>本文为了方便起见我们直接使用 API 的方式，选择 <strong>智谱 AI</strong> 作为这次的代表。</p><div class="admonition note"><p class="admonition-title">为什么是智谱 AI</p><p>并不是说 智谱AI 一定比其他的大模型好（虽然有不少粉丝这样觉得）。 选择智谱AI 的主要原因还是因为我比较熟悉， 从最初开源 ChatGLM 到 VisualGLM，以及后来 ChatGLM2 和 ChatGLM3，我都有关注。 正好智谱AI 也开放了 API 调用。</p></div><h2 id="智谱-ai" tabindex="-1">智谱 AI <a class="header-anchor" href="#智谱-ai" aria-label="Permalink to &quot;智谱 AI&quot;">​</a></h2><p><strong><a href="https://www.zhipuai.cn/" target="_blank" rel="noreferrer">智谱 AI</a></strong> 由<strong>清华大学</strong>计算机系技术成果转化而来的公司，致力于打造新一代认知智能通用模型。 大家可以自行去其官网了解：</p><p><img src="'+l+'" alt="智谱 AI 首页"></p><p>当然我们今天的主角是他的<a href="https://open.bigmodel.cn/" target="_blank" rel="noreferrer">开放平台</a>：</p><p><img src="'+p+'" alt="智谱 AI 开放平台"></p><p>注册之后登录进入控制台就可以看到模型、文档、账单等模块：</p><p><img src="'+h+'" alt="智谱 AI 开放平台控制台"></p><p>查看 <strong>API Key</strong> 可以看到默认的 API Key，直接拷贝使用，或者创建新的 API Key：</p><p><img src="'+e+`" alt="智谱 AI API Key"></p><h3 id="api-使用" tabindex="-1">API 使用 <a class="header-anchor" href="#api-使用" aria-label="Permalink to &quot;API 使用&quot;">​</a></h3><p>从控制台的首页点击 API 文档，进入 <a href="https://open.bigmodel.cn/dev/api" target="_blank" rel="noreferrer">API 的使用指南</a>：</p><p>快速安装：</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> install</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> zhipuai</span></span></code></pre></div><p>然后写一个例子测试下：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> zhipuai</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">zhipuai.api_key </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &quot;xxx&quot;</span><span style="--shiki-light:#6A737D;--shiki-dark:#768390;"> # 你的 api key</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#DCBDFB;"> invoke_prompt</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(prompt):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">    response </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> zhipuai.model_api.invoke(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">        model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;chatglm_turbo&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">        prompt</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">[</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">            {</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;role&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;user&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;content&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">: prompt},</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">        ],</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">        top_p</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">0.7</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">        temperature</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">0.9</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">    )</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">    if</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> response[</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&#39;code&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">==</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;"> 200</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">:</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> response[</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&#39;data&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">][</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&#39;choices&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">][</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">][</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&#39;content&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">]</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">    return</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &#39;LLM not worked&#39;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">    </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">    </span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">if</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;"> __name__</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;"> ==</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &#39;__main__&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">   response </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> invoke_prompt(</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&#39;简单介绍下人工智能是什么&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">   print</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(response)</span></span></code></pre></div><p>回答如下：</p><blockquote><p>人工智能（Artificial Intelligence，简称AI）是一门研究、开发模拟、延伸和扩展人类智能的理论、方法、技术及应用系统的新兴技术科学。 人工智能领域的研究涵盖了多个方面，如机器人、语言识别、图像识别、自然语言处理和专家系统等。其目标是使计算机能够模拟和实现人类智能的功能， 从而在某些领域达到甚至超过人类的智能水平。\\n\\n人工智能专业是一门多学科交叉的新兴学科，旨在培养掌握人工智能基础理论、 基本方法和应用技术的人才。专业课程包括人工智能概论、认知科学、机器学习、模式识别、深度学习、知识工程、数据挖掘、 物联网等系列课程。\\n\\n人工智能的发展包括多个阶段，如启蒙、繁荣、低谷等。从20世纪50年代开始，人工智能逐渐成为一门独立的学科。 随着计算机技术、网络技术和大数据技术的快速发展，人工智能进入了一个新的黄金时期。 在我国，人工智能专业的发展也得到了政府和企业的大力支持，被视为未来科技创新的重要驱动力。&quot;</p></blockquote><h3 id="智谱-ai-的提示参数" tabindex="-1">智谱 AI 的提示参数 <a class="header-anchor" href="#智谱-ai-的提示参数" aria-label="Permalink to &quot;智谱 AI 的提示参数&quot;">​</a></h3><p>上面代码我们注意到，<code>prompt</code> 参数是一个数组，其设计是天然针对<strong>对话</strong>、以及<strong>少样本提示</strong>的。</p><p>比如：</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">prompt</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> =</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">    {</span><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">&quot;role&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">:</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &quot;user&quot;,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &quot;content&quot;:</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &#39;提问1&#39;},</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">    {</span><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">&quot;role&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">:</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &quot;assistant&quot;,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &quot;content&quot;:</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &#39;回答1&#39;},</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">    {</span><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">&quot;role&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">:</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &quot;user&quot;,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &quot;content&quot;:</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &#39;提问2&#39;},</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">    {</span><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">&quot;role&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">:</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &quot;assistant&quot;,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &quot;content&quot;:</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &#39;回答2&#39;},</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">    {</span><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">&quot;role&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">:</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &quot;user&quot;,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &quot;content&quot;:</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> prompt},</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">]</span></span></code></pre></div><p>AI 会跟去前面的对话历史，对最后的 <code>prompt</code> 进行回答。</p><p>!!! explain 少样本提示 <strong>少样本提示</strong> 虽然是提示工程中最简单的一个技术，但这种方法其实有很大的威力， 在一个<strong>优秀的 LLM</strong> 之上进行少样本提示甚至可以在很多场景下<strong>代替模型微调</strong>， 达到意想不到的效果。 !!!</p><p>好了，现在基本调用是可以了。我们再来实现一个 AI 的常用场景，知识库检索。</p><h2 id="llama-index" tabindex="-1">Llama Index <a class="header-anchor" href="#llama-index" aria-label="Permalink to &quot;Llama Index&quot;">​</a></h2><p>我们这次实现知识库，已然使用 <a href="https://www.llamaindex.ai/" target="_blank" rel="noreferrer">LlamaIndex</a>， LlamaIndex 是一个简单灵活且强大的数据框架，用于将自定义数据源连接到大型语言模型。 感兴趣的朋友可以去查看 <a href="https://docs.llamaindex.ai/en/stable/" target="_blank" rel="noreferrer">LlmaIndex 文档</a> 或者去我 LlamaIndex 的合集去了解更多信息。</p><p><img src="`+k+`" alt="llamaindex.ai"></p><h3 id="安装" tabindex="-1">安装 <a class="header-anchor" href="#安装" aria-label="Permalink to &quot;安装&quot;">​</a></h3><p>先用 Pip 简单安装一下 Llama Index：</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> install</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> llama-index</span></span></code></pre></div><p>然后我们导入下测试是否安装成功：</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">import</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> llama_index</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">llama_index.__version__</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#768390;"># 0.9.10</span></span></code></pre></div><p>接下来让 Llama Index 使用 智谱AI 作为大模型。</p><h3 id="支持的-llm" tabindex="-1">支持的 LLM <a class="header-anchor" href="#支持的-llm" aria-label="Permalink to &quot;支持的 LLM&quot;">​</a></h3><p>我们到 LlamaIndex 的文档「<a href="https://docs.llamaindex.ai/en/stable/module_guides/models/llms/modules.html" target="_blank" rel="noreferrer">Available LLM integrations</a>」看下它现在支持哪些大模型。</p><p>我们看到，虽然他支持了很多的商业模型和开源项目，但是并没有 「智谱 AI」 以及国内的一众 AI 产品。</p><blockquote><p>国产AI 崛起之路还真是任重而道远啊。</p></blockquote><p><img src="`+d+`" alt="Llama Index 现有的 LLM 集成"></p><p>前面我们提到，Llama Index 是一个简单<strong>灵活</strong>的数据框架，既然官方还没有集成，我们就自己集成一下好了。</p><h3 id="集成智谱ai" tabindex="-1">集成智谱AI <a class="header-anchor" href="#集成智谱ai" aria-label="Permalink to &quot;集成智谱AI&quot;">​</a></h3><p>LlamaIndex 提供了一个叫做 <code>CustomLLM</code> 的抽象类来让我们方便的集成自己的大模型产品：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;"> CustomLLM</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">LLM</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">):</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">    &quot;&quot;&quot;Simple abstract base class for custom LLMs.</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">    Subclasses must implement the \`__init__\`, \`complete\`,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">        \`stream_complete\`, and \`metadata\` methods.</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">    &quot;&quot;&quot;</span></span></code></pre></div><p>从注释就能看到，实现一个自己的 LLM 其实很简单，只需要实现 <code>__init__</code>, <code>complete</code>, <code>stream_complete</code> 以及 <code>metadata</code> 这几个方法即可。</p><h4 id="metadata-方法" tabindex="-1">metadata 方法 <a class="header-anchor" href="#metadata-方法" aria-label="Permalink to &quot;metadata 方法&quot;">​</a></h4><p>!!! explain 什么是元数据 元数据稍微正式的解释是描述数据的数据。比较绕口，需要仔细体会。 简单说就是记录的属性、表的结构、界面的布局、数据的特征、程序的参数。 !!!</p><p>上面四个方法中我们比较陌生的应该是 <code>metadata</code> 了，metadata 翻译一下就是元数据， 而 LLM 的元数据是什么， 比较通用的有如下一些：</p><ul><li><code>model_name: str = &quot;chatglm_turbo&quot;</code></li><li><code>top_p = 0.7</code></li><li><code>temperature = 0.9</code></li><li><code>num_output: int = 256</code></li><li><code>context_window: int = 3900</code></li></ul><p>像「模型名称」、「温度」、「top p」这些参数\\属性大家想必已经很了解了， 我们简单实现一下：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;"> ZhipuLLM</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#6CB6FF;">CustomLLM</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">    model_name: </span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">str</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;"> =</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &quot;chatglm_turbo&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">    top_p </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;"> 0.7</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">    temperature </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;"> 0.9</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#DCBDFB;">    @</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">property</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#DCBDFB;"> metadata</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(self) -&gt; LLMMetadata:</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">        &quot;&quot;&quot;Get LLM metadata.&quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> LLMMetadata(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">            context_window</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">.context_window,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">            num_output</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">.num_output,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">            model_name</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">.model_name,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">        )</span></span></code></pre></div><p>因为 智谱AI 的API 也没有太多的参数，我们把 <code>top_p</code> 和 <code>temperature</code> 取一个比较合理的值， 直接放到调用程序里面，其实可以不需要设计 Metadata，实现一个空方法即可：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;"> ZhipuLLM</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#6CB6FF;">CustomLLM</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">):</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#DCBDFB;">    @</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">property</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#DCBDFB;"> metadata</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(self) -&gt; LLMMetadata:</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> LLMMetadata()</span></span></code></pre></div><h4 id="complete-方法" tabindex="-1">complete 方法 <a class="header-anchor" href="#complete-方法" aria-label="Permalink to &quot;complete 方法&quot;">​</a></h4><p>接下来就是实现 <code>complete</code> 方法，前面我们有一个 <code>invoke_prompt</code> 方法来实现 智谱AI 的调用，这里直接拿来用， 也不去实例化或者过多设置参数，越简单越好：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#DCBDFB;">@llm_completion_callback</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">()</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#DCBDFB;"> complete</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(self, prompt: </span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">**</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">kwargs: Any) -&gt; CompletionResponse:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">    response </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> invoke_prompt(prompt)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> CompletionResponse(</span><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">text</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">response)</span></span></code></pre></div><div class="admonition note"><p class="admonition-title">stream_complete</p><p>流式返回官方也有例子，我这里就不实现了。</p></div><h3 id="文本嵌入-embedding" tabindex="-1">文本嵌入 Embedding <a class="header-anchor" href="#文本嵌入-embedding" aria-label="Permalink to &quot;文本嵌入 Embedding&quot;">​</a></h3><p>智谱 AI 也提供了文本嵌入接口，那我们当然也是直接拿来用了，这样子就彻底摆脱了了 OpenAI 和自己搭建模型了。</p><p>LlamaIndex 的嵌入式基于 <code>BaseEmbedding</code> 实现的，我们也写一个 智谱AI 的实现，来不及做过多解释了，直接看代码：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;"> ZhipuEmbedding</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#6CB6FF;">BaseEmbedding</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">    _model: </span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">str</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;"> =</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> PrivateAttr()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">    _instruction: </span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">str</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;"> =</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> PrivateAttr()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">            self,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">            instructor_model_name: </span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">str</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;"> =</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &quot;text_embedding&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">            instruction: </span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">str</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;"> =</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &quot;Represent a document for semantic search:&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">,</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">            **</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">kwargs: Any,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">    ) -&gt; </span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">:</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">._model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &#39;text_embedding&#39;</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">._instruction </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> instruction</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">().</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">**</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">kwargs)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#DCBDFB;">    @</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">classmethod</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#DCBDFB;"> class_name</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(cls) -&gt; </span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">:</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">        return</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> &quot;zhipu_embeddings&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">    async</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;"> def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#DCBDFB;"> _aget_query_embedding</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(self, query: </span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">) -&gt; List[</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">float</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">]:</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">        return</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">._get_query_embedding(query)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">    async</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;"> def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#DCBDFB;"> _aget_text_embedding</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(self, text: </span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">) -&gt; List[</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">float</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">]:</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">        return</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">._get_text_embedding(text)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#DCBDFB;"> _get_query_embedding</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(self, query: </span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">) -&gt; List[</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">float</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">]:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">        embeddings </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> invoke_embedding(query)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> embeddings</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#DCBDFB;"> _get_text_embedding</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(self, text: </span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">) -&gt; List[</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">float</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">]:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">        embeddings </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> invoke_embedding(text)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> embeddings</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#DCBDFB;"> _get_text_embeddings</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(self, texts: List[</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">]) -&gt; List[List[</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">float</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">]]:</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> [</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">._get_text_embedding(text) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> text </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> texts]</span></span></code></pre></div><h2 id="llamaindex-结合-智谱-ai" tabindex="-1">LlamaIndex 结合 智谱 AI <a class="header-anchor" href="#llamaindex-结合-智谱-ai" aria-label="Permalink to &quot;LlamaIndex 结合 智谱 AI&quot;">​</a></h2><p>现在让我们把前面的成果合在一起，写一个简单的程序看看，能不能行得通：</p><p>首先我们再目录下放置一个文本文件，当前 PDF、Excel、Docx 都行，我这里还是用之前亚运会奖牌设计的文案：</p><p><img src="`+r+`" alt="亚运会奖牌设计文案"></p><p>然后直接运行程序：</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#768390;"># define our LLM</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">llm</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> =</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> ZhipuLLM</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">()</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">embed_model</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> =</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> ZhipuEmbedding</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">service_context</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> =</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> ServiceContext.from_defaults</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">    llm</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">llm,</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> embed_model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">embed_model</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#768390;"># Load the your data</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">documents</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> =</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> SimpleDirectoryReader</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">doc_path</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">.load_data</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">()</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">index</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> =</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> VectorStoreIndex.from_documents</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">documents,</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> service_context=service_context</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#768390;"># Query and print response</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">query_engine</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> =</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> index.as_query_engine</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">()</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">response</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> =</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> query_engine.query</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">&quot;杭州亚运会奖牌的工艺和设计理念?，请用中文回答。&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">response</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span></code></pre></div><p>来看下回答：</p><div class="language-markdown vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">markdown</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">杭州亚运会奖牌的工艺和设计理念如下：</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">1.</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> 工艺：奖牌采用了一系列复杂的工艺，包括压印成型、</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">   数铣外形及槽坑、修整刷拋、镀金镀银、表面防护等。</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">   绶带采用织锦提花工艺、环保印花技术，双面手工缝合。</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">   此外，奖牌正面采用了江南传统工艺——打鏨雕，</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">   将四种书法（真、草、隶、篆）的杭州与亚奥理事会</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">   的英文缩写有机结合。</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">2.</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> 设计理念：奖牌设计融合了杭州三大世界文化遗产</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">   ——西湖、大运河、良渚古城遗址，</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">   展现了杭州山水景观和江南文化。</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">   奖牌正面勾勒出“三面云山一面城”的杭城画卷，</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">   背面形似方形印章，寓意运动员在杭州亚运会上</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">   留下美好印记。整体设计别具一格，</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">   具有高度辨识度，体现了美美与共、和而不同的含义。</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">此外，奖牌设计还展现了杭州生态文明之都的气质，</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">湖光山色，绿水青山，铸就了金山银山，</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">也体现了勇攀高峰的体育精神。</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">奖牌直径70毫米，厚度6毫米，</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">正面圆形渐变色，背面采用杭州江南丝绣技艺呈现的篆刻图案。</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">整体奖牌设计充满东方意蕴之美，</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">将深厚底蕴的南宋文化与杭州地域特色相结合，</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">表达独特的美学理念。</span></span></code></pre></div><p>回答均来源于文案，但是进行了重新组织，我只想说中文<strong>表达如此流畅</strong>！远胜我自己。</p><h2 id="结语" tabindex="-1">结语 <a class="header-anchor" href="#结语" aria-label="Permalink to &quot;结语&quot;">​</a></h2><p>Llama Index 里使用大模型的地方主要是上面两处。这两个点对接之后，余下的各种玩法也均和使用 OpenAI 无异。 更多的场景以及可落地的 AI 玩法，后面再和大家分享。</p>`,87)]))}const u=i(g,[["render",o]]);export{m as __pageData,u as default};
