import{_ as e,a as t,af as r,o as n}from"./chunks/framework.C87LdZyP.js";const u=JSON.parse('{"title":"关于大模型微调的方法和概念","description":"","frontmatter":{"title":"关于大模型微调的方法和概念","date":"2023-07-30T00:00:00.000Z","tags":["ai","ml"],"category":["AI"]},"headers":[],"relativePath":"posts/2023/07/2023-07-31-llm-fine-tuning-methods.md","filePath":"posts/2023/07/2023-07-31-llm-fine-tuning-methods.md","lastUpdated":1718173059000}'),o={name:"posts/2023/07/2023-07-31-llm-fine-tuning-methods.md"};function i(l,a,s,h,g,d){return n(),t("div",null,a[0]||(a[0]=[r('<p><a href="https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/images/trl_banner_dark.png" target="_blank" rel="noreferrer">https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/images/trl_banner_dark.png</a></p><p>!!! explain TRL (Transformer 强化学习)</p><p><a href="https://huggingface.co/docs/trl/index" target="_blank" rel="noreferrer">TRL</a> 是一个全栈库， 我们提供了一组工具来通过强化学习训练 Transformer 语言模型， 从监督微调步骤 (SFT)、奖励建模步骤 (RM) 到近端策略优化 (PPO) 步骤。</p><p>!!!</p><p>有监督（Supervised Fine-tuning，<strong>SFT</strong>）。 奖励/偏好建模（Reward/preference modelling，<strong>RM</strong>）。 基于人类反馈的强化学习（<strong>RLHF</strong>）。</p><h2 id="peft" tabindex="-1">PEFT <a class="header-anchor" href="#peft" aria-label="Permalink to &quot;PEFT&quot;">​</a></h2><p><strong><a href="https://huggingface.co/docs/peft/index" target="_blank" rel="noreferrer">PEFT</a></strong>，或<strong>参数高效微调</strong>（PEFT），是一个库， 用于有效地将预训练的语言模型（PLM）适应各种下游应用程序，而无需微调所有模型的参数。 PEFT 方法仅微调少量（额外）模型参数，从而显着降低计算和存储成本， 因为微调大规模 PLM 的成本过高。 最近最先进的 PEFT 技术实现了与完全微调相当的性能。</p><h3 id="lora" tabindex="-1">LoRA <a class="header-anchor" href="#lora" aria-label="Permalink to &quot;LoRA&quot;">​</a></h3><h3 id="prefix-tuning" tabindex="-1">Prefix Tuning <a class="header-anchor" href="#prefix-tuning" aria-label="Permalink to &quot;Prefix Tuning&quot;">​</a></h3><h3 id="p-tuning" tabindex="-1">P-Tuning <a class="header-anchor" href="#p-tuning" aria-label="Permalink to &quot;P-Tuning&quot;">​</a></h3><h3 id="prompt-tuning" tabindex="-1">Prompt Tuning <a class="header-anchor" href="#prompt-tuning" aria-label="Permalink to &quot;Prompt Tuning&quot;">​</a></h3><h3 id="adalora" tabindex="-1">AdaLoRA <a class="header-anchor" href="#adalora" aria-label="Permalink to &quot;AdaLoRA&quot;">​</a></h3><h3 id="llama-adapter" tabindex="-1">LLaMA-Adapter <a class="header-anchor" href="#llama-adapter" aria-label="Permalink to &quot;LLaMA-Adapter&quot;">​</a></h3><h3 id="ia3" tabindex="-1">IA3 <a class="header-anchor" href="#ia3" aria-label="Permalink to &quot;IA3&quot;">​</a></h3><ul><li><a href="https://huggingface.co/blog/zh/stackllama" target="_blank" rel="noreferrer">https://huggingface.co/blog/zh/stackllama</a></li><li></li></ul>',15)]))}const c=e(o,[["render",i]]);export{u as __pageData,c as default};
